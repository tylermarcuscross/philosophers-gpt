Counterfactuals
First published Fri Jan 18, 2019
Modal discourse concerns alternative ways things can be, e.g., what
might be true, what isn’t true but could have been, what should
be done. This entry focuses on
counterfactual
modality
which concerns what is not, but could or would have
been. What if Martin Luther King had died when he was stabbed in 1958
(Byrne 2005: 1)
? What if the Americas
had never been colonized? What if I were to put that box over here and
this one over there? These modes of thought and speech have been the
subject of extensive study in philosophy, linguistics, psychology,
artificial intelligence, history, and many other allied fields. These
diverse investigations are united by the fact that counterfactual
modality crops up at the center of foundational questions in these
fields.
In philosophy, counterfactual modality has given rise to difficult
semantic, epistemological, and metaphysical questions:
Semantic
How do we communicate and
reason about possibilities which are remote from the way things
actually are?
Epistemic
How can our experience in
the actual world justify thought and talk about remote
possibilities?
Metaphysical
Do these remote
possibilities exist independently from the actual world, or are they
grounded in things that actually exist?
These questions have attracted significant attention in recent
decades, revealing a wealth of puzzles and insights. While other
entries address the
 epistemic—
the epistemology of modality
—and
 metaphysical
 questions—
possible worlds
and
the possibilism-actualism debate
—this
 entry focuses on the semantic question. It will aim to refine this
question, explain its central role in certain philosophical debates,
and outline the main semantic analyses of counterfactuals.
Section 1
begins with a working definition of counterfactual conditionals
 (
§1.1
),
 and then surveys how counterfactuals feature in theories of agency,
mental representation, and rationality
 (
§1.2
),
 and how they are used in metaphysical analysis and scientific
explanation
 (
§1.3
).
Section 1.4
then details several ways in which the logic and
truth-conditions of counterfactuals are puzzling. This sets the stage
for the sections
2
and
3
,
 which survey semantic analyses of counterfactuals that attempt to
explain this puzzling behavior.
Section 2
focuses on two related analyses that were primarily developed to
study the
logic
of counterfactuals: strict conditional
analyses and similarity analyses. These analyses were not originally
concerned with saying what the truth-conditions of particular
counterfactuals are. Attempts to extend them to that domain, however,
have attracted intense criticism.
Section 3
surveys more recent analyses that offer more explicit models of when
counterfactuals are true. These analyses include premise semantics
 (
§3.1
),
 conditional probability analyses
 (
§3.2
)
 and structural equations/causal models
 (
§3.3
).
 They are more closely connected to work on counterfactuals in
psychology, artificial intelligence, and the philosophy of
science.
Sections
2
and
3
of this entry employ some basic tools from set theory and logical
semantics. But these sections also provide intuitive characterizations
alongside formal definitions, so familiarity with these tools is not a
pre-requisite. Readers interested in more familiarity with these tools
will find
basic set theory
,
 as well as
Gamut (1991)
and
Sider
(2010)
useful.
1. Counterfactuals and Philosophy
1.1 What are Counterfactuals?
1.2 Agency, Mind, and Rationality
1.2.1 Agency, Choice, and Free Will
1.2.2 Rationality
1.2.3 Mental Representation, Content, and Knowledge
1.3 Metaphysical Analysis and Scientific Explanation
1.4 Semantic Puzzles
2. The Logic of Counterfactuals
2.1 Introducing Strict and Similarity Analyses
2.2 Strict Conditional Analyses
2.2.1 Second Wave Strict Conditional Analyses
2.3 Similarity Semantics
2.4 Comparing the Logics
2.5 Truth-Conditions Revisited
2.5.1 Truth-Conditions and Similarity
2.5.2 Truth-Conditions and the Strict Analysis
2.6 Philosophical Objections
2.7 Summary
3. Semantic Theories of Counterfactual Dependence
3.1 Premise Semantics
3.2 Conditional Probability Analyses
3.3 Bayesian Networks, Structural Equations, and Causal Models
3.4 Summary
4. Conclusion
Bibliography
Academic Tools
Other Internet Resources
Related Entries
1. Counterfactuals and Philosophy
This section begins with some terminological issues
 (
§1.1
).
 It then provides two broad surveys of research that places
counterfactuals at the center of key philosophical issues.
Section 1.2
covers the role of counterfactuals in theories of rational agency,
mental representation, and knowledge.
Section 1.3
focuses on the central role of counterfactuals in metaphysics and the
philosophy of science.
Section 1.4
will then bring a bit of drama to the narrative by explaining how
counterfactuals are deeply puzzling from the perspective of classical
and modal logics alike.
1.1 What are Counterfactuals?
In philosophy and related fields, counterfactuals are taken to be
sentences like:
(1)
If
colonial powers hadn’t invaded, the Americas
would be very different.
This entry will follow this widely used terminology to avoid
confusion. However, this usage also promotes a confusion worth
dispelling. Counterfactuals are not really conditionals with
contrary-to-fact antecedents. For example
 (
2
)
 can be used as part of an argument that the antecedent is true
(Anderson
1951)
:
(2)
If
there had been intensive agriculture in the
Pre-Columbian Americas, the natural environment would have been
impacted in specific ways. That is exactly what we find in many
watersheds.
On these grounds, it might be better to speak instead of
subjunctive conditionals
, and reserve the term
counterfactual
for subjunctive conditionals whose antecedent
is assumed to be false in the
 discourse.
[
1
]
While slightly more enlightened, this use of the term does not match
the use of
counterfactuals
in the sprawling philosophical and
interdisciplinary literature surveyed here, and has its own drawbacks
that will be discussed shortly. This entry will use
counterfactual
conditional
and
subjunctive conditional
interchangeably,
hoping to now have dispelled the suggestion that all counterfactuals,
in that sense, have contrary-to-fact antecedents.
The terminology of indicative and subjunctive conditionals is also
vexed, but it aims to get at a basic contrast which begins between two
different forms of conditionals that can differ in truth value.
(3)
and
(4)
can differ in truth-value while holding fixed the world they are
being evaluated
 in.
[
2
]
(3)
If
Oswald didn’t kill Kennedy, someone else did.
(Indicative)
(4)
If
Oswald hadn’t killed Kennedy, someone else
would’ve.
(Subjunctive)
It is easy to imagine a world where
(3)
is true, and
(4)
false. Consider a world like ours where Kennedy was assassinated.
Further suppose Oswald didn’t do it, but some lone fanatic did
for deeply idiosyncratic reasons. Then
(3)
is true and
(4)
false. Another aspect of the contrast between indicative and
subjunctive conditionals is illustrated in
(5)
and
(6)
.
(5)
# Bob never danced. If Bob danced,
Leland danced.
(6)
Bob never danced. If Bob had danced,
Leland would have danced.
(7)
Bob never danced. If Bob were to
dance, Leland would dance.
Indicatives like
(5)
are infelicitous when their antecedent has been denied, unlike the
subjunctives like
(6)
and
(7)
(
Stalnaker 1975; Veltman 1986
).
The indicative and subjunctive conditionals above differ from each
other only in particular details of their linguistic form. It is
therefore plausible to explain their contrasting semantic behavior in
terms of the semantics of those linguistic differences. Indicatives,
like
(3)
and
(5)
,
 feature verbs in the simple past tense form, and no modal auxiliary
in the consequent. Subjunctives, like
(4)
and
(6)
,
 feature verbs in the past perfect (or “pluperfect”) with
a modal
would
in the consequent. Something in the
neighborhood of these linguistic and semantic differences constitutes
the distinction between
indicative and subjunctive
conditionals
—summarized in
Figure 1
.
[
3
]
Examples
Antecedents
Consequents
Deny Ante­ce­dent?
Indicative
(3)
,
(5)
V-ed
, …
V-ed
, …
Not felicitous
Subjunctive
(4)
,
(6)
had V-ed
,
were to V
,
V-ed
, …
would have V
,
would V
,
would have V-ed
, …
Can be felicitous
Figure 1:
Rough Guide to Indicative and
Subjunctive Conditionals
As with most neighborhoods, there are heated debates about the exact
boundaries and the names—especially when future-oriented
conditionals are included. These debates are surveyed in the
supplement
Indicative and Subjunctive Conditionals
.
 The main entry will rely only on the agreed-upon paradigm examples
like
(3)
and
(4)
.
 The labels
indicative
and
subjunctive
are also
flawed since these two kinds of conditionals are not really
distinguished on the basis of whether they have indicative or
subjunctive mood in the antecedent or
 consequent.
[
4
]
But the terminology is sufficiently entrenched to permit this
distortion of linguistic reality.
Much recent work has been devoted to explaining how the semantic
differences between indicative and subjunctive conditionals can be
derived from their linguistic differences—rather than treating
them as semantically unrelated. Much of this work has been done in
light of Kratzer’s (
1986, 2012
)
general approach to modality according to which all conditionals are
treated as two-place modal operators. This approach is also discussed
in the supplement
Indicative and Subjunctive Conditionals
.
[
5
]
This entry will focus on the basic logic and truth-conditions of
subjunctive conditionals as a whole, and will use the following
notation for them (following
Stalnaker
 1968
).
[
6
]
Subjunctive Conditionals
(Notation)
\(\phi>\psi\) symbolizes
if it had been the case that \(\phi\)
then it would have been the case that \(\psi\)
This project and notation has an important limitation that should be
highlighted: it combines the meaning of the modal
would
and
if…then…
into a single connective
“\(>\)”. This makes it difficult to adequately
represent subjunctive conditionals like:
(8)
a.
If Maya had run, she might have
been elected.
b.
If Maya had run, she
might have been elected and would have been an excellent Senator.
c.
“Mr. Taft never asked my advice in the matter,
but if he had asked it, I should have emphatically advised him against
thus stating publicly his religious belief.” (Theodore
Roosevelt)
d.
If
Maya had run, she probably would have won and she might have won big.
Conditionals like
(8a)
have figured in debates about the semantics of counterfactuals and
have been modeled either as a related connective
(D.
Lewis 1973b: §1.5)
or a normal
would
-subjunctive conditional embedded under
might
(
Stalnaker 1980, 1984: Ch.7
). But the
more complex examples
(8b)
–
(8d)
highlight the need for a more refined compositional analysis, like
those surveyed in
Indicative and Subjunctive Conditionals
.
 So, while this notation will be used in
§1.4
and throughout
§2
and
§3
,
 it should be regarded as an analytic convenience rather than a
defensible assumption.
1.2 Agency, Mind, and Rationality
Counterfactuals have played prominent and interconnected roles in
theories of rational agency. They have figured prominently in views of
what agency and free will amount to, and played important roles in
particular theories of mental representation, rational decision
making, and knowledge. This section will outline these uses of
counterfactuals and begin to paint a broader picture of how
counterfactuals connect to central philosophical questions.
1.2.1 Agency, Choice, and Free Will
A defining feature of agents is that they make choices. Suppose a
citizen votes, and in doing so chooses to vote for
X
rather
than
Y
. It is hard to see how this act can be a choice without
a corresponding counterfactual being true:
(9)
If the
citizen had wanted to vote for
Y
, they could have.
The idea that choice entails the ability to do otherwise has been
taken by many philosophers to underwrite our practice of holding
agents responsible for their choices. But understanding the precise
meaning of the counterfactual
could have
claim in
(9)
requires navigating the classic problem of free will: if we live in a
universe where the current state of the universe is determined (or
near enough) by the prior state of the universe and the physical laws,
then it seems like every action of every agent, including their
“choices”, are predetermined. So interpreting this
intuitively plausible counterfactual
(9)
leads quite quickly to a deep philosophical dilemma. One can
maintain, with some Incompatibilists, that
(9)
is a false claim about what’s physically possible, and revisit
the understanding of agency, choice, and responsibility
above—the entry
incompatibilist theories of free will
explores this
 further.
[
7
]
Alternatively, one can maintain that
(9)
is a true claim about some non-physical sense of possibility, and
explain how that is appropriate to our understanding of choice and
responsibility—the entry
compatibilism
explores this further. It is wrong to construe debates about free
will as
just
debates about the meaning of counterfactuals.
But, the semantics of counterfactuals can have a substantive impact on
delimiting the space of possible solutions, and perhaps even deciding
between them. The same is true for research on counterfactual thinking
in psychology.
Experiments in social psychology suggest that belief in free will is
linked to increased counterfactual thinking
(Alquist
et al. 2015)
. Further, they have
shown that counterfactually reflecting on past events and choices is
one significant way humans imbue life experiences with meaning and
create a sense of self
(Galinsky et al. 2005;
Heintzelman et al. 2013; Kray et al. 2010)
. Incompatibilists
might be able to cite this result as an explanation for why so many
people believe they have free will. It is a specific form of wishful
thinking: it is interwoven with the practices of counterfactual
reflection that give our lives meaning.
Seto et
al. (2015)
support this idea by showing that variation in
subjects’ belief in free will predicts how much meaning they
derive from relevant instances of counterfactual reflection. This
might even be used as part of a pragmatic argument for believing in
free will: roughly, belief in free will is so practically important,
and our knowledge of the world so incomplete, that it is rational to
believe that it
 exists.
[
8
]
1.2.2 Rationality
Counterfactual reflection is not just used for the
“sentimental” purposes discussed above, but as part of
what
Byrne (2005)
calls
rational
imagination
. This capacity is implicated in many philosophical
definitions of rational agency. According to the standard model,
agency involves intentional action—see entries
agency
and
action
.
 While choices are intentional actions, intentional actions are a more
general class of actions which, on most views, are in part caused by
intentions—see entry
intention
.
 One prominent understanding of intentions is that they are
prospective (forward looking) mental states that play a crucial role
in planning actions.
Byrne (2005, 2016:
138)
details psychological evidence showing that counterfactual
thinking is central to forming rational intentions. People use
counterfactual thinking after particular events to formulate plans
that will improve the outcome of their actions in related scenarios.
Examples include aviation pilots thinking after a near-accident
“if I had understood the controller’s words accurately, I
wouldn’t have initiated the inappropriate landing
attempt”, and blackjack players thinking “If I’d
gotten the 2, I would have beaten the dealer”. People who reason
in this way show more persistence and improved performance in related
tasks, while those who dwell on how things could have been worse, or
do not counterfactually reflect at all, show less persistence and no
improvement in performance. Finally, human rationality can become
disordered when counterfactual thinking goes astray, e.g., in
depression, anxiety, and schizophrenia
(Byrne
2016: 140–143)
.
This psychological research shows that rational
human
agents
do
learn from the past and plan for the future engaging in
counterfactual thinking. Many researchers in artificial intelligence
have voiced similar ideas
(Ginsberg 1985; Pearl
1995; Costello & Mccarthy 1999)
. But, this view is distinct
from a stronger philosophical claim: that the nature of rational
agency consists, in part, in the ability to perform counterfactual
thinking. Some versions of causal decision theory make precisely this
claim, and do so to capture similar patterns of rational behavior.
Newcomb’s Problem
(Nozick 1969)
consists of a decision problem which challenges the standard way of
articulating the idea that rational agents maximize expected utility,
and, according to some philosophers
(Stalnaker
1972 [1980]; Gibbard & Harper 1978)
, shows that causal or
counterfactual reasoning must be included in rational decision
procedures—see the entry
causal decision theory
for further details. In a similar vein, work on belief revision
theory explores how a rational agent should revise their beliefs when
they are inconsistent with something they have just learned—much
like a counterfactual antecedent demands—and uses structures
that formally parallel those used in the semantics of counterfactuals
(Harper 1975; Gärdenfors 1978, 1982; Levi
1988)
. See
formal representations of belief
for further discussion of this literature.
1.2.3 Mental Representation, Content, and Knowledge
The idea that counterfactual reasoning is central to rational agency
has surfaced in another way in cognitive science and artificial
intelligence, where encoding counterfactual-supporting relationships
has emerged as a major theory of mental representation
(Chater
et al. 2010)
. These disciplines also
study how states of mind like belief, desire, and intention explain
rational agency. But they are not satisfied with just showing that
certain states of mind can explain certain choices and actions. They
aim to explain
how
those particular states of mind lead to
those choices and actions. They do so by characterizing those states
of mind in terms of representations, and formulating particular
algorithms for using those representations to learn, make choices and
perform
 actions.
[
9
]
Many recent advances in cognitive science and artificial intelligence
share a starting point with Bayesian epistemology: agents must learn
and decide what to do despite being uncertain what exactly the world
is like, and these processes can be modeled in the probability
calculus. On a simple Bayesian approach, an agent represents the world
with a probability distribution over binary facts or variables that
represent what the world is like. But even for very simple domains the
probability calculus does not provide computationally tractable
representations and algorithms for implementing Bayesian intelligence.
The tools of
Bayesian networks
,
structural equations
and
causal models
, developed by
Spirtes,
Glymour, and Scheines (1993, 2000)
and
Pearl (2000, 2009)
address this
limitation, and also afford simple algorithms for causal and
counterfactual reasoning, among other cognitive processes. This
framework represents an agent’s knowledge in a way that puts
counterfactuals and causal connections at the center, and the tools it
provides have been influential beyond cognitive science and AI. It has
also been applied to topics covered later in this entry: the semantic
analyses of counterfactuals
 (
§3.2
)
 and metaphysical dependence, causation and scientific explanation
 (
§1.3
).
 For this reason, it will be useful to describe its basics now, though
still focusing on its applications to mental representation. What
follows is a simplified version of the accessible introduction in
Sloman (2005: Ch.4)
. For a more thorough
introduction, see
Pearl (2009:
Ch.1)
.
In a Bayesian framework, probabilities are real numbers between 0 and
1 assigned to propositional variables
A
,
B
,
C
,…. These probabilities reflect an agent’s
subjective credence, e.g., \(P(A)=0.6\) reflects that they think
A
is slightly more likely than not to be
 true.
[
10
]
At the heart of Bayesian Networks are the concepts of
conditional
probability
and two variables being
probabilistically
independent
. \(P(B \mid A)\) is the credence in
B
conditional on
A
being true and is defined as follows:
Definition 1 (Conditional
Probability)
\(\displaystyle P(B\mid A)\dequal
\frac{P(A\land B)}{P(A)}\)
Conditional probabilities allow one to say when
B
is
probabilistically independent of
A
: when an agent’s
credence in
B
is the same as their credence in
B
conditional on
A
and conditional on \(\neg A\).
Definition 2 (Probabilistic
Independence)
B
is probabilistically
independent of
A
just in case \(P(B)=P(B\mid A)=P(B\mid\neg
A)\).
Bayesian networks represent relations of probabilistic dependence. For
example, an agent’s knowledge about a system containing eight
variables could be represented by the directed acyclic graph and
system of structural equations between those variables in
Figure 2
.
Figure 2:
Bayesian Network and
Structural Equations. [An
extended description of figure 2
is in the supplement.]
While the arrows mark relations of probabilistic dependence, the
equations characterize the nature of the dependence, e.g.,
“\(H\dequal F\lor G\)” means that the value of
H
is
determined by the value of \(F\lor G\) (but not vice
versa).
[
11
]
This significantly reduces the number of values that must be
 stored.
[
12
]
But it also stores information that is useful to agents. It
facilitates counterfactual reasoning—e.g., if
C
had been
true then
G
would have been true—reasoning about
actions—e.g., if we do
A
then
C
will be
true—and explanatory reasoning—e.g.,
H
is true in
part because
C
is true
(Pearl
2002)
.
The usefulness of Bayesian networks is evidenced by their many
applications in psychology (e.g.,
Glymour 2001;
Sloman 2005
) and artificial intelligence (e.g.,
Pearl
2009, 2002)
). They are among the key
representations employed in autonomous vehicles
(Thrun
et al. 2006; Parisien & Thagard
2008)
, and have been applied to a wide range of cognitive
phenomena:
Applications of Bayesian Networks
Causal learning and reasoning in AI
(Pearl
2009: Chs 1–4)
and humans
(Glymour
2001; Gopnik et al. 2004; Sloman 2005:
Chs.6–12)
Counterfactual reasoning in AI
(Pearl
2009: Ch.7)
and humans
(Sloman
& Lagnado 2005; Sloman 2005; Rips 2010;
Lucas & Kemp:2015)
Conceptual categorization and action
planning
(Sloman 2005: Chs.9,10)
Learning and cognitive development
(Gopnik
& Tenenbaum 2007)
As
Sloman (2005: 177)
highlights, this
form of representation fits well with a guiding idea of embodied
cognition: mental representations in biological agents are constrained
by the fact that their primary function is to facilitate successful
action despite uncertain information and bounded computational
resources. Bayesian networks have also been claimed to address a deep
and central issue in artificial intelligence called the frame problem
(e.g.,
Glymour 2001: Ch. 3
). For the
purposes of this entry, it is striking how fruitful this approach to
mental representation has been, since counterfactual dependence is at
its core.
Counterfactual dependence has also featured prominently in theories of
mental content, which explain how a mental representation like the
concept
dog
comes to represent dogs.
Informational theories take their inspiration from natural
representations like tree rings, which represent, in some sense, how
old the tree is
(Dretske 2011)
. While
some accounts in this family are called “causal theories of
mental content”, it is somewhat limiting to formulate the view
as:
X
represents
Y
just in case
Y
causes
X
. Even for the tree rings, it is metaphysically controversial
to claim that the tree rings are caused by the age of the tree, rather
than thinking they have a common cause or are merely causally related
via a number of laws and factors, e.g., rainfall, seasons, growth
periods. For this and other reasons,
Dretske
(1981, 1988, 2002)
formulates the relationship in terms of
conditional probabilities:
Definition 3 (Dretske’s Probabilistic Theory of
Information)
State
s
carries the
information that
a
is
F
, given background conditions
g
, just in case \(P(a\text{ is }F\mid s, g)=1\).
On this view, the state of the tree rings carries the information that
the tree is a certain age, since given the background conditions in
our world the relevant conditional probability is 1. As argued by
Loewer (1983: 76)
and
Cohen
and Meskin (2006)
, this formulation
introduces problematic issues in how to interpret the probabilities
involved and these problems are avoided by a counterfactual
formulation:
Definition 4 (Loewer’s Counterfactual Theory of
Information)
State
s
carries the
information that
a
is
F
, given background conditions
g
, just in case, given
g
, if
s
were to obtain,
a
would have to have been
F
.
Even this theory of information requires several elaborations to
furnish a plausible account of mental content. For example,
Dretske
(1988, 2002)
holds that a mental
representation
r
represents that
a
is
F
just in
case
r
has the function of indicating that
a
is
F
. The teleological (“function”) component is added
to explain how a deer on a dark night can cause tokens of the concept
dog
without being part of the information
carried by thoughts that token
dog
.
Fodor
(1987, 1990)
pursues another,
non-teleological solution, the asymmetric dependence theory.
Counterfactuals feature here in another way:
Definition 5 (Fodor’s Asymmetric Dependence
Theory)
r
represents that
a
is
F
, just in case:
“
a
being
F
causes
r
” is a law.
For any other cause
c
of
r
,
c
would not have caused
r
if
a
being
F
had
not caused
r
. (
c
’s causing
r
asymmetrically
depends on
a
being
F
causing
r
.)
This approach also appeals to laws, which are another key
philosophical concept connected to counterfactuals—see
§1.3
below.
Counterfactuals are not just used to analyze how a given mental state
represents reality, but also when a mental state counts as knowledge.
Numerous counterexamples, like Gettier cases, make the identification
of knowledge with justified true belief problematic—for further
details see
the analysis of knowledge
.
 But some build on this analysis by proposing further conditions to
address these counterexamples. Two counterfactual conditions are
prominent in this literature:
Sensitivity
If
p
were false,
S
would not believe that
p
.
Safety
If
S
were to believe
that
p
,
p
would not be false.
Both concepts are ways of articulating the idea that
S
’s
beliefs must be formed in a way that is responsive to
p
being
true. The semantics of counterfactuals have interacted with this
project in a number of ways: in establishing their non-equivalence,
refining them, and adjudicating putative counterexamples.
1.3 Metaphysical Analysis and Scientific Explanation
Counterfactuals have played an equally central role in metaphysics and
the philosophy of science. They have featured in metaphysical theories
of causation, supervenience, grounding, ontological dependence, and
dispositions. They have also featured in issues at the intersection of
metaphysics and philosophy of science like laws of nature and
scientific explanation. This section will briefly overview these
applications, largely linking to related entries that cover these
applications in more depth. But, this overview is more than just a
list of how counterfactuals have been applied in these areas. It helps
identify a cluster of inter-related concepts (and/or properties) that
are fruitfully studied together rather than in isolation.
Many philosophers have proposed to analyze causal concepts in terms of
counterfactuals (e.g.,
D. Lewis 1973a
,
Mackie 1974
). The basic idea is that
(10)
can be understood in terms of something like
(11)
(see
counterfactual theories of causation
for further discussion).
(10)
A
caused
C
.
(11)
If
A
had not
occurred,
C
would not have occurred.
This basic idea has been elaborated and developed in several ways.
D. Lewis (1973a, c)
refines it using his
similarity semantics for counter­factuals—see
§2.3
.
 The resulting counterfactual analysis of causation faces a number of
challenges—see
counterfactual theories of causation
for discussion and references. But this has simply inspired a new
wave of counterfactual analyses that use different tools.
Hitchcock (2001, 2007)
and
Woodward
(2003: Ch.5)
develop counterfactual
analyses of causation using the tools of Bayesian networks (or
“causal models”) and structural equations described back
in
§1.2.3
.
 The rough idea of the analysis is as follows. Given a graph like the
one in
Figure 2
,
X
can be said to be a cause of
Y
just in case there is
a path from
X
to
Y
and changing just the value of
X
changes the value of
Y
. According to
Hitchcock
(2001)
and
Woodward
(2002, 2003)
, this analysis of
causation counts as a counterfactual analysis because the basic
structural equations, e.g., \(C\dequal A\land B\), are best understood
as primitive counterfactual claims, e.g., if
A
and
B
had
been true,
C
would have been true. While not all theories of
causation that employ structural equations are counterfactual
theories, structural equations are central to many of the contemporary
counterfactual theories of
 causation.
[
13
]
See
counterfactual theories of causation
for further developments and critical reactions to this account of
causation.
Recently,
Schaffer (2016)
and
Wilson
(2018)
have also used structural
equations to articulate a counterfactual theory of metaphysical
grounding.
[
14
]
Metaphysical grounding is a concept widely employed in metaphysics
throughout its history, but has been the focus of intense attention
only recently—see entry
metaphysical grounding
for further details. As
Schaffer (2016)
puts it, the fact that Koko the gorilla lives in California is not a
fundamental fact because it is grounded in more basic facts about the
physical world, perhaps facts about spacetime and certain physical
fields. Statements articulating these grounding facts constitute
distinct metaphysical explanations. So conceived, metaphysical
grounding is among the most central concepts in metaphysics. The key
proposals in
Schaffer (2016)
and
Wilson
(2018)
are to use structural equations
to model grounding relations, and not just causal relations, and in
doing so capture parallels between causation and grounding. Indeed,
they define grounding in terms of structural equations in the same way
as the authors above defined causation in terms of structural
equations. The key difference is that the equations articulate what
grounds what. While this approach to grounding has its critics (e.g.,
Koslicki 2016
), it is worth noting here
since it places counterfactuals at the center of metaphysical
explanations.
[
15
]
Counterfactuals have been implicated in other key metaphysical
debates. Work on dispositions is a prominent example. A glass’s
fragility is a curious property: the glass has it in virtue of
possibly
shattering in certain conditions, even if those
conditions are never manifested in the actual world, unlike say, the
glass’s shape. This dispositional property is quite naturally
understood in terms of a counterfactual claim:
(12)
A
glass is fragile if and only if it would break if it
were struck in the right way.
Early analyses of this form were pursued by
Ryle
(1949)
,
Quine
(1960)
, and
Goodman (1955)
, and
have remained a major position in the literature on dispositions. See
dispositions
for further discussion and references.
It is not just
metaphysical
explanation where counterfactuals
have been central. They also feature prominently in accounts of
scientific
explanation and laws of nature. Strict empiricists
have attempted to characterize scientific explanation without reliance
on counterfactuals, despite the fact that they tend to creep
in—for further background on this see
scientific explanation
.
 Scientific explanations appeal to laws of nature, and laws of nature
are difficult to separate from counterfactuals. Laws of nature are
crucially different from accidental generalizations, but how? One
prominent idea is that they “support counterfactuals”. As
Chisholm (1955: 97)
observed, the
counterfactual
(14)
follows from the corresponding law
(13)
but the counterfactual
(16)
does not follow from the corresponding accidental generalization
(15)
.
(13)
All gold is malleable.
(14)
If that metal were gold, it would be malleable.
(15)
Every Canadian parent of quintuplets in
the first half of the 20th century is named “Dionne”.
(16)
If Jones, who is Canadian, had been
parent of quintuplets during the first half of the 20th century, he
would have been named “Dionne”.
A number of prominent views have emerged from pursuing this
connection.
Woodward (2003)
argues that
the key feature of an explanation is that it answers
what-if-things-had-been-different
questions, and integrates
this proposal with a structural equations approach to causation and
 counterfactuals.
[
16
]
Lange (1999, 2000, 2009)
proposes an
anti-reductionist account of laws according to which they are
identified by their invariance under certain counterfactuals.
Maudlin
(2007: Ch.1)
also proposes an
anti-reductionist account of laws, but instead uses laws to define the
truth-conditions of counterfactuals relevant to physical explanations.
For more on these views see
laws of nature
.
1.4 Semantic Puzzles
It should now be clear that a wide variety of central philosophical
topics rely crucially on counterfactuals. This highlights the need to
understand their semantics: how can we systematically specify what the
world must be like if a given counterfactual is true and capture
patterns of valid inference involving them? It turns out to be rather
difficult to answer this question using the tools of classical logic,
or even modal logic. This section will explain why.
Logical semantics
(Frege 1893; Tarski 1936;
Carnap 1948)
provided many useful analyses of English
connectives like
and
and
not
using Boolean
truth-functional connectives like \(\land\) and \(\neg\).
Unfortunately, such an analysis is not possible for counterfactuals.
In truth-functional semantics, the truth of a complex sentence is
determined by the truth of its parts because a connective’s
meaning is modeled as a truth-function—a function from one or
more truth-values to another. Many counterfactuals have false
antecedents and consequents, but some are true and others false.
(17a)
is false—given Joplin’s critiques of
consumerism—and
(17b)
is true.
(17)
a.
If Janis Joplin were alive today,
she would drive a Mercedes-Benz.
b.
If Janis Joplin were alive today, she
would metabolize food.
It may be useful to state the issue a bit more precisely.
In truth-functional semantics, the truth-value (True/False: 1/0) of a
complex sentence is determined by the truth-values of its parts and
particular truth-function expressed by the connective. This is
illustrated by the truth-tables for negation \(\neg\), conjunction
\(\land\), and the material conditional \(\supset\) in
Figure 3
.
\(\phi\)
\(\neg\phi\)
1
0
0
1
\(\phi\)
\(\psi\)
\(\phi\land\psi\)
1
1
1
1
0
0
0
1
0
0
0
0
\(\phi\)
\(\psi\)
\(\phi\supset\psi\)
1
1
1
1
0
0
0
1
1
0
0
1
Figure 3:
Negation (\(\neg\)),
Conjunction (\(\land\)), Material Conditional (\(\supset\))
Truth-functional logic is inadequate for counterfactuals not just
because the material conditional \(\supset\) does not capture the fact
that some counterfactuals with false antecedents like
(17a)
are false. It is inadequate because there is, by definition, no
truth-functional connective whatsoever that simultaneously combines
two false sentences to make a true one like
(17b)
and combines two false ones to make a false one like
(17a)
.
 In contemporary philosophy, this is overwhelmingly seen as a failing
of classical logic. But there was a time at which it fueled skepticism
about whether counterfactuals really make true or false claims about
the world at all. Quine (
1960: §46, 1982:
Ch.3
) voices this skepticism and supports it by highlighting
puzzling pairs like
(18)
and
(19)
:
(18)
a.
If Caesar had been in charge [in Korea], he would have used the atom bomb.
b.
If Caesar had been in charge [in Korea], he would have used catapults.
(19)
a.
If Bizet and Verdi had been compatriots, Bizet would have been Italian.
b.
If Bizet and Verdi had been compatriots, Verdi would have been French.
Quine (1982: Ch.3)
suggests that no
state of the world could settle whether
(19a)
or
(19b)
is true. Similarly he contends that it is not the world, but
sympathetically discerning the speaker’s imagination and purpose
in speaking that matters for the truth of
(18b)
versus
(18a)
(Quine 1960: §46)
. Rather than
promoting skepticism about a semantic analysis of counterfactuals,
Lewis (1973b: 67)
took these examples as
evidence that their truth-conditions are
context-sensitive
: the possibilities that are
considered when evaluating the antecedent are constrained by the
context in which the counterfactual is asserted, including the
intentions and practical ends of the speaker. All contemporary
accounts of counterfactuals incorporate some version of this
 idea.
[
17
]
Perhaps the most influential semantic puzzle about counterfactuals was
highlighted by
Goodman (1947)
, who
noticed that adding more information to the antecedent can actually
turn a true counterfactual into a false one. For example,
(20a)
could be true, while
(20b)
is false.
(20)
a.
If I had struck this match, it would have lit.
\(\mathsf{S > L}\)
b.
If I had struck this match and done so in a room without oxygen, it would have lit.
\(\mathsf{(S\land \neg O)> L}\)
Lewis (
1973c: 419; 1973b: 10
) dramatized
the problem by considering sequences such as
(21)
,
 where adding more information to the antecedent repeatedly flips the
truth-value of the counterfactual.
(21)
a.
If I had shirked my duty, no harm would have ensued.
\(\mathsf{I > \neg H}\)
b.
Though, if I had shirked my duty and you had too, harm would
	have ensued.
\(\mathsf{(I \land U)> H}\)
c.
Yet, if I had shirked my duty, you had shirked your duty and
	a third person done more than their duty, then no harm would have
	ensued.
\(\mathsf{(I\land U\land T) > \neg H}\)
\(\vdots\)
The English discourse
(21)
is clearly consistent: it is nothing like saying
I shirked my
duty
and
I did not shirk my duty
. This property of
counterfactual antecedents is known by a technical name,
non-monotonicity
, and is one of the features all contemporary
accounts are designed to capture. As will be discussed in
§2.2
,
 even modal logic does not have the resources to capture semantically
non-monotonic operators.
Goodman (1947)
posed another influential
problem. Examples
(20a)
and
(20b)
show that the truth-conditions of counterfactuals depend on assumed
background facts like the presence of oxygen. However, a
moment’s reflection reveals that specifying all of these
background facts is quite difficult. The match must be dry, oxygen
must be present, wind must be below a certain threshold, the friction
between the striking surface and the match must be sufficient to
produce heat, that heat must be sufficient to activate the chemical
energy stored in the match head, etc. Further, counterfactuals like
(20a)
also rely for their truth on physical laws specific to our world,
e.g., the conservation of energy. Goodman’s problem is this: it
is difficult to adequately specify these background conditions and
laws without further appealing to counterfactuals. This is clearest
for laws. As discussed in
§1.3
,
 some have aimed to distinguish laws from accidental generalizations
by noting that only the former support counterfactuals. But if this is
a defining feature of laws, and laws are part of the definition of
when a counterfactual is true, circularity becomes a concern. Explicit
analyses of laws in terms of counterfactuals, like
Lange
(2009)
, would make an analysis of
counterfactuals in terms of laws circular.
The potential circularity for background conditions takes a bit more
explanation. Suppose one claims to have specified all of the
background conditions relevant to the truth of
(20a)
,
 as in
(22a)
.
 Then it is tempting to say that
(20a)
is true because
(22c)
follows from
(22a)
,
(22c)
, and the physical laws.
(22)
a.
The match was dry, oxygen was present, wind was below a
	certain threshold, the potential friction between the striking
	surface and the match was sufficient to produce heat, that
	heat was sufficient to activate the chemical energy stored in
	the match head …
b.
The match was struck.
c.
The match lit.
But now suppose there is an agent seeing to it that a fire is not
started, and will only strike the match if it is wet. In this case the
counterfactual
(20a)
is intuitively false. However, unless one adds the counterfactual,
if the match were struck, it would have to be wet
, to the
background conditions,
(22c)
still follows from
(22a)
,
(22c)
, and the physical laws. That would incorrectly predict
the counterfactual to be true. In short, it seems that the background
conditions must themselves consist of counterfactuals. Any analysis of
counterfactuals that captures their sensitivity to background facts
must either eliminate these appeals to counterfactuals, or show how
this appeal is non-circular, e.g., part of a recursive, non-reductive
analysis.
To summarize, this section has identified three key theses about the
semantics of counterfactuals and a central problem:
Key Semantic Theses about Counterfactuals
Counterfactuals are not
truth-functional.
Counterfactuals have context-sensitive
truth-conditions.
Counterfactual antecedents are interpreted
non-monotonically.
Goodman’s Problem
The
truth-conditions of counterfactuals depend on background facts and
laws. It is challenging to specify these facts and laws in general,
but particularly difficult to specify them in non-counterfactual
terms.
These theses, along with Goodman’s Problem, were once grounds
for skepticism about the coherence of counterfactual discourse. But
with advances in semantics and pragmatics, they have instead become
the central features of counterfactuals that contemporary analyses aim
to capture.
2. The Logic of Counterfactuals
This section will survey two semantic analyses of counterfactuals: the
strict conditional
analysis and the
similarity
analysis. These conceptually related
analyses also have a shared explanatory goal: to capture logically
valid inferences involving counterfactuals, while treating them
non-truth-functionally, leaving room for their context dependence, and
addressing the non-monotonic interpretation of counterfactual
antecedents. Crucially, these analyses abstract away Goodman’s
Problem because they are not primarily concerned with the
truth-conditions of particular counterfactuals—just as classical
logic does not take a stand on which atomic sentences are actually
true. Instead, they say only enough about truth-conditions to settle
matters of logic, e.g., if \(\phi\) and \(\phi>\psi\) are true,
then \(\psi\) is true. Sections
2.5
and
2.6
will revisit questions about the truth-conditions of particular
counterfactuals, Goodman’s Problem and the philosophical
projects surveyed in
§1
.
The following subsections will detail strict conditional and
similarity analyses. But it is useful at the outset to consider
simplified versions of these two analyses alongside each other. This
will clarify their key differences and similarities. Both analyses are
also stated in the framework of possible world semantics developed in
Kripke (1963)
for modal logics. The
following subsection provides this background and an overview of the
two analyses.
2.1 Introducing Strict and Similarity Analyses
The two key concepts in possible worlds semantics are possible worlds
and accessibility spheres (or relations). Intuitively, a possible
world
w
is simply a way the world could be or could have been.
Formally, they are treated as primitive points in the set of all
possible worlds
W
. But their crucial role comes in assigning
truth-conditions to sentences: a sentence \(\phi\) can only said to be
true given a possible world
w
, but since
w
is genuinely
possible, it cannot be the case that both \(\phi\) and \(\neg\phi\)
are true at
w
. Accessibility spheres provide additional
structure for reasoning about what’s possible: for each world
w
, \(R(w)\) is the set of worlds accessible from
w
.
[
18
]
This captures the intuitive idea that given a possible world
w
, a certain range of other worlds \(R(w)\) are possible, in a
variety of senses. \(R_1(w)\) might specify what’s nomologically
possible in
w
by including only worlds where
w
’s
natural laws hold, while \(R_2(w)\) specifies what’s
metaphysically possible in
w
.
These tools furnish truth-conditions for a formal language including
non-truth-functional necessity (\({{\medsquare}}\)) and possibility
(\({{\meddiamond}}\))
 operators:
[
19
]
Definition 6 (Kripkean Semantics)
\[
	\begin{align}
		{\llbracket A\rrbracket}^{R}_v				& =\set{w\mid v(w,A)=1} 						& \tag*{1.}\\
		{\llbracket\neg\phi\rrbracket}^{R}_v		& = W-{\llbracket\phi\rrbracket}^{R}_v						& \tag*{2.}\\
		{\llbracket\phi\land\psi\rrbracket}^{R}_v	& ={\llbracket\phi\rrbracket}^{R}_v\cap{\llbracket\psi\rrbracket}^{R}_v 		& \tag*{3.}\\
		{\llbracket\phi\lor\psi\rrbracket}^{R}_v	& ={\llbracket\phi\rrbracket}^{R}_v\cup{\llbracket\psi\rrbracket}^{R}_v 		& \tag*{4.}\\
		{\llbracket\phi\supset\psi\rrbracket}^{R}_v	& =(W-{\llbracket\phi\rrbracket}^{R}_v)\cup{\llbracket\psi\rrbracket}^{R}_v 	& \tag*{5.}\\
		{\llbracket\medsquare\phi\rrbracket}^{R}_v		& =\set{w\mid R(w)\subseteq{\llbracket\phi\rrbracket}^{R}_v}	& \tag*{6.}\\
		{\llbracket\meddiamond\phi\rrbracket}^{R}_v		& =\set{w\mid R(w)\cap{\llbracket\phi\rrbracket}^{R}_v\neq\emptyset}	& \tag*{7.}
	\end{align}

    \]
In classical logic, the meaning of \(\phi\) is simply its truth-value.
But in modal logic, it is the set of possible worlds where \(\phi\) is
true: \({\llbracket}\phi{\rrbracket}\). So \(\phi\) is true in
w
, relative to
v
and
R
, just in case
\(w\in{\llbracket}\phi{\rrbracket}^R_v\):
Definition 7
(Truth)
\(w,v,R\vDash \phi \iff
w\in{\llbracket}\phi{\rrbracket}^R_v\)
Only clauses 6 and 7 rely crucially on this richer notion of meaning.
\({{\medsquare}}\phi\) says that in all accessible worlds \(R(w)\),
\(\phi\) is true. \({{\meddiamond}}\phi\) says that there are some
accessible worlds where \(\phi\) is true. Logical concepts like
consequence are also defined in terms of relations between sets of
possible worlds. The intersection of the premises must be a subset of
the conclusion (i.e., every world where the premises are true, the
conclusion is true):
Definition 8 (Logical Consequence)
\(\phi_1,{\ldots},\phi_n\vDash\psi \iff \forall
R,v{{:\thinspace}}({\llbracket}\phi_1{\rrbracket}^R_v\cap\cdots\cap{\llbracket}\phi_n{\rrbracket}^R_v)\subseteq{\llbracket}\psi{\rrbracket}^R_v\)
Given this framework, the strict analysis can be formulated very
simply: \(\phi > \psi\) should be analyzed as
\({{\medsquare}}(\phi\supset\psi)\). This says that all accessible
\(\phi\)-worlds are \(\psi\)-worlds. This analysis can be depicted as
in
Figure 4
.
[
20
]
Figure 4:
Truth in \(w_0\) relative to
R
. [An
extended description of figure 4
is in the supplement.]
The red circle delimits the worlds accessible from \(w_0\), the
x
-axis divides \(\phi\) and \(\neg\phi\)-worlds, and the
y
-axis \(\psi\) and \(\neg\psi\)-worlds.
\({{\medsquare}}(\phi\supset\psi)\) says that there are no worlds in
the blue shaded region.
It is crucial to highlight that this semantics
does not
capture the non-monotonic interpretation of counterfactual
antecedents. For example, \({\llbracket}\mathsf{A}\land
\mathsf{B}{\rrbracket}^R_v\) is a subset of
\({\llbracket}\mathsf{A}{\rrbracket}\), and this means that any time
\({{\medsquare}}(\mathsf{A\supset C})\) is true, so is
\({{\medsquare}}(\mathsf{(A\land B)\supset C})\). After all, if all
\(\mathsf{A}\)-worlds are in the red quadrant of
Figure 4
,
 so are all of the \(\mathsf{A\land B}\)-worlds, since the
\(\mathsf{A\land B}\)-worlds are just a subset of the
\(\mathsf{A}\)-worlds. A crucial point here is that on this semantics
the domain of worlds quantified over by a counterfactual is constant
across counterfactuals with different antecedents. As will be
discussed in
§2.2
,
 advocates of strict conditional analyses aim to instead capture the
non-monotonic behavior of antecedents pragmatically by incorporating
it into a model of their context-sensitivity. The most important
difference between strict analyses and similarity analyses is that
similarity analyses capture this non-monotonicity semantically.
On the similarity analysis, \(\phi >\psi\) is true in \(w_0\),
roughly, just in case all the \(\phi\)-worlds most similar to \(w_0\)
are \(\psi\)-worlds. To model this notion of similarity, one needs
more than a simple accessibility sphere. One way to capture it is with
with a nested system of spheres \(\mathcal{R}\) around a possible
world \(w_0\)
(D. Lewis 1973b:
§1.3)
—this is just a particular kind of set of
accessibility spheres. As one goes out in the system, one gets to less
and less similar worlds. This analysis can be depicted as in
Figure 5
.
[
21
]
Figure 5:
Truth in \(w_0\) relative to
\(\mathcal{R}\). [An
extended description of figure 5
is in the supplement.]
The most similar \(\phi\)-worlds are in the innermost gray region. So,
this analysis excludes any worlds from being in the
shaded
innermost blue region. Comparing Figures
4
and
5
,
 one difference stands out: the similarity analyses does not require
that there be no \(\phi\land\neg\psi\)-worlds in
any
sphere,
just in the innermost sphere. For example, world \(w_1\) does not
prevent the counterfactual \(\phi >\psi\) from being true. It is
not in the \(\phi\)-sphere most similar to
w
. This is the key
to semantically capturing the non-monotonic interpretation of
antecedents. The truth of \(\mathsf{A > C}\) does not guarantee the
truth of \(\mathsf{(A\land B)> C}\) precisely because the most
similar \(\mathsf{A}\)-worlds may be in the innermost sphere, and the
most similar \(\mathsf{A\land B}\) may be in an intermediate sphere,
and include worlds like \(w_1\) where the consequent is false. In this
sense, the domain of worlds quantified over by a similarity-based
counterfactual varies across counterfactuals with different
antecedents, though it does express a strict conditional over this
varying domain. For this reason,
D. Lewis
(1973b)
and many others call the similarity analysis a
variably-strict
analysis.
Since antecedent monotonicity is the key division between strict and
similarity analyses, it is worthwhile being a bit more precise about
what it is, and what its associated inference patterns are.
Definition 9 (Antecedent
Monotonicity)
If \(\phi_1>\psi\) is true at
some \(w,R,v\) and
\({\llbracket}\phi_2{\rrbracket}^R_v\subseteq{\llbracket}\phi_1{\rrbracket}^R_v\),
then \(\phi_2 >\psi\) is true at \(w,R,v\).
The crucial patterns associated with antecedent monotonicity are:
Antecedent Strengthening
(AS)
\(\phi_1>\psi\vDash
(\phi_1\land\phi_2)>\psi\)
Simplification of Disjunctive Antecedents
(SDA)
\((\phi_1\lor\phi_2)>\psi\vDash
(\phi_1>\psi)\land(\phi_2>\psi)\)
Transitivity
\(\phi_2>\phi_1,\phi_1 > \psi\vDash \phi_2>\psi\)
Contraposition
\(\phi>\psi\,\leftmodels\vDash \neg\psi>\neg\phi\)
AS and SDA clearly follow from antecedent monotonicity. By contrast,
Transitivity and a plausible auxiliary assumption entail antecedent
 monotonicity,
[
22
]
and the same is true for
 Contraposition.
[
23
]
With these basics in place, it is possible to focus in on each of
these analyses in more detail. In doing so, it will become clear that
there are important differences even among variants of the similarity
analysis and variants of the strict analysis. This entry will focus on
what these analyses predict about valid inferences involving
counterfactuals.
2.2 Strict Conditional Analyses
The strict conditional analysis has a long history, but its
contemporary form was first articulated by
 Peirce:
[
24
]
“If
A
is true then
B
is true”… is
expressed by saying, “In any possible state of things,
[
w
], either \([A]\) is not true [in
w
], or \([B]\) is
true [in
w
]”.
(Peirce 1896:
33)
C.I. Lewis (1912, 1914)
defended the
strict conditional analysis of subjunctives and developed an axiomatic
system for studying their logic, but offered no semantics. A precise
model-theoretic semantics for the strict conditional was first
presented in
Carnap (1956: Ch. 5)
.
However, that account did not appeal to accessibility relations, and
ranged only over logically possible worlds. Since counterfactuals are
often non-logical, it it was only after
Kripke
(1963)
introduced a semantics for modal logic featuring an
accessibility relation, that the modern form of the strict analysis
was precisely
 formulated:
[
25
]
Basic Strict Conditional
Analysis
\({\llbracket\phi>\psi\rrbracket}^R_v=
{\llbracket\medsquare(\phi\supset\psi)\rrbracket}^R_v\)
\(\medsquare(\phi\supset\psi)\) is true in
w
, relative to
R
and
v
, just in case
\(\phi\supset\psi\) is true at all worlds accessible from
w
,
namely all worlds in \(R(w)\)
I.e., all
\(\phi\)-worlds in \(R(w)\) are \(\psi\)-worlds
\( \begin{align*}
\llbracket\medsquare(\phi\supset\psi)\rrbracket^{R} & =\{w\mid
R(w)\subseteq\llbracket\phi\supset\psi\rrbracket^{R}_v\} & \\

																&	=\{w\mid (R(w)\cap\llbracket\phi\rrbracket^{R}_v)\subseteq\llbracket\psi\rrbracket^{R}_v\}& \\[-18px]
\end{align*}
\)
\(\phi\strictif\psi\mathbin{:=}\medsquare(\phi\supset\psi)\)
Just as the logic of \({{\medsquare}}\) will vary with constraints
 that can be placed on
R
, so too will the logic of strict
 conditionals.
[
26
]
For example, if one does not assume that
\(w\in R(w)\) then modus ponens will not hold for the strict
conditional: \(\psi\) will not follow from \(\phi\) and
\({{\medsquare}}(\phi\supset\psi)\). But even without settling these
constraints, some basic logical properties of the analysis can be
 established. The discussion to follow is by no means
 exhaustive.
[
27
]
Instead, it will highlight the logical
patterns which are central to the debates between competing
analyses.
The core idea of the
basic strict analysis
leads to the following validities.
Fact 1 (‘Paradoxes’ of Strict Implication)
\(\vDash(\phi\land\neg\phi)\strictif\psi\)
\(\vDash\psi\strictif(\phi\lor\neg\phi)\)
\(\neg{{\meddiamond}}\phi\vDash\phi\strictif\psi\)
\({{\medsquare}}\psi\vDash\phi\strictif\psi\)
In these validities, some see a plausible and attractive
  logic
(C.I. Lewis 1912, 1914)
. Others
  see them as “so utterly devoid of rationality [as to be]
  a
reductio ad absurdum
of any view which involves
  them” (
Nelson 1933: 271)
,
  earning them the title
paradoxes of strict
  implication
. Patterns 3 and 4 are more central to debates about
  counterfactuals, so they will be the focus here. Pattern 3 clearly
  follows from the core idea of the
basic
  strict analysis
: the premise guarantees that there are no
  accessible \(\phi\)-worlds, from which it vacuously follows that all
  accessible \(\phi\)-worlds are \(\psi\)-worlds. Much the same is
  true of pattern 4: if all the accessible worlds are \(\psi\)-worlds
  then all the accessible \(\phi\)-worlds are \(\psi\)-worlds. Both 3
  and 4 are seem incorrect for English counterfactuals.
(23)
a.
JFK couldn’t have passed universal healthcare.
b.
If JFK had passed universal healthcare, he would have granted insects coverage.
Contrary to pattern 3, the false
(23b)
does not intuitively follow from the true
(23a)
. Similarly, for pattern 4. Suppose one’s origin from a particular sperm and egg is an essential feature of oneself. Then
(24a)
is true.
(24)
a.
Joplin had to have come from the particular sperm and egg she in fact came from.
b.
If there had been no life on Earth, then Joplin would have come from the particular sperm and egg she in fact came from.
And, yet, many would hesitate to
infer
(24b)
on the basis
of
(24a)
. Each of these patterns follow
from the core idea of the strict analysis. While these counterexamples
may not constitute a conclusive objection, they do present a problem
for the basic strict analysis. The second wave strict analyses
surveyed in
§2.2.1
are
designed to solve it, however. They are also designed to address
another suite of validities that are even more problematic.
The strict analysis is widely criticized for validating antecedent
monotonic patterns. It is worth saying a bit more precisely,
using
Definition 9
and
Figure 6
,
why
antecedent monotonicity
holds for the strict
conditional.
Figure 6:
Strict Conditionals are Antecedent Monotonic. [An
extended description of figure 6
is in the supplement.]
If \(\phi_1\strictif\psi\) is true, then the shaded blue region is empty, and the position of \(\phi_2\) reflects the fact that \({\llbracket}\phi_2{\rrbracket}^R_v\subseteq{\llbracket}\phi_1{\rrbracket}^R_v\)—recall that all worlds above the
x
-axis are \(\phi_1\)-worlds. Since the shaded blue region within \(\phi_2\) is also empty, all \(\phi_2\) worlds in \(R(w)\) are \(\psi\)-worlds. That is, \(\phi_2\strictif \psi\) is true.
Recall that
Transititivity
and
Contraposition
entail
antecedent monotonicity
, so it remains to show that both hold for the strict conditional. To see why
Contraposition
holds for the strict conditional, note again that if \(\phi\strictif\psi\) is true in
w
, then all \(\phi\)-worlds in \(R(w)\) are \(\psi\)-worlds, as depicted in the left Venn diagram in
Figure  7
. Now suppose
w
is a \(\neg\psi\)-world in \(R(w)\). As the diagram makes clear,
w
has to be a \(\neg\phi\)-world, and so \(\neg\psi\strictif\neg\phi\) must be true in
w
. Similarly, if \(\neg\psi\strictif\neg\phi\) is true in
w
, then all \(\neg\psi\)-worlds in \(R(w)\) are \(\neg\phi\)-worlds, as depicted in the right Venn diagram in
Figure  7
. Now suppose
w
is a \(\phi\)-world in \(R(w)\). As depicted,
w
has to be a \(\psi\)-world, and so \(\phi\strictif\psi\) must be true in
w
.
Figure 7:
\(w\in {\llbracket\phi\strictif\psi\rrbracket}^R_v \iff w\in {\llbracket\neg\psi\strictif\neg\phi\rrbracket}^R_v\) (Contraposition).  [An
extended description of figure 7
is in the supplement.]
The validity of
Transititivity
for the strict conditional is also easy to see with a Venn diagram.
Figure 8:
\(w\in{\llbracket\phi_2\strictif\phi_1\rrbracket}^R_v\cap{ \llbracket\phi_1\strictif\psi\rrbracket}^R_v\Leftrightarrow w\in{\llbracket\phi_2\strictif\psi\rrbracket}^R_v\) (Transitivity). [An
extended description of figure 8
is in the supplement.]
The premises guarantee that all \(\phi_2\)-worlds in \(R(w)\) are
\(\phi_1\)-worlds, and that all \(\phi_1\)-worlds in \(R(w)\) are
 \(\psi\)-worlds. That gives one the relationships depicted
 in
Figure 8
. To show that
 \(\phi_2\strictif\psi\) follows, suppose that
w
is a
 \(\phi_2\)-world in \(R(w)\). As
Figure 8
makes evident,
w
must then be a \(\psi\)-world.
Antecedent monotonic patterns are an ineliminable part of a strict
conditional logic. Examples of them often sound compelling. For
 example, the transitive inference
(25)
sounds perfectly reasonable, as does the antecedent strengthening
 inference
(26)
.
(25)
a.
If the switch had been flipped, the light would be on.
b.
If the light had been on, it would not have been dark.
c.
So, if the switch had been flipped, it would not have been dark.
(26)
a.
If the switch had been flipped, the light would be on.
b.
So, if the switch had been flipped and I had been in the room, the light would be on.
Similar examples for
SDA
are easy to find. However,
 counterexamples to each of the four patterns have been offered.
Counterexamples to
Antecedent Strengthening
were already discussed back in
§1.4
.
 Against
Transititivity
,
Stalnaker (1968: 48)
points out that
(27c)
does not intuitively follow from
(27a)
and
(27b)
.
(27)
a.
If J. Edgar Hoover were today a communist, then he would be a traitor.
b.
If J. Edgar Hoover had been born a Russian, then he would today be a communist.
c.
If J. Edgar Hoover had been born a Russian, he would be a traitor.
Contra
Contraposition
,
D. Lewis
(1973b: 35)
presents
(28)
.
(28)
a.
If Boris had gone to the party, Olga would still have gone.
b.
If Olga had not gone, Boris would still not have gone.
Suppose Boris wanted to go, but stayed away to avoid
Olga. Then
(28b)
is false. Further suppose
that Olga would have been even more excited to attend if Boris had. In
that case
(28a)
is
true. Against
SDA
,
Mckay
& van Inwagen (1977: 354)
offer:
(29)
a.
If Spain had fought for the Axis or the Allies, she would have fought for the Axis.
b.
If Spain had fought for the Allies, she would have fought for the Axis.
(29b)
does not intuitively follow
 from
(29a)
.
These counterexamples have been widely taken to be conclusive evidence
against the strict analysis (e.g.,
D. Lewis
1973b; Stalnaker 1968
), since they follow from the core
assumptions of that analysis. As a
result,
D. Lewis (1973b)
and
Stalnaker (1968)
developed
similarity analyses which build the non-monotonicity of antecendents
into the semantics of
counterfactuals—see
§2.3
. However,
there was a subsequent wave of strict analyses designed to
systematically address these counterexamples. In fact, they do so by
unifying two features of counterfactuals: the non-monotonic
interpretation of their antecedents and their context-sensitivity.
2.2.1 Second Wave Strict Conditional Analyses
Beginning with
Daniels and Freeman
(1980)
and
Warmbrōd
(1981a,b)
, there was a second wave of strict analyses developed
explicitly to address the non-monotonic interpretation of
counterfactual antecedents.
Warmbrōd
(1981a,b)
,
Lowe (1983, 1990)
,
and
Lycan (2001)
account for the
counterexamples to antecedent monotonic patterns within a systematic
theory of how counterfactuals are context-sensitive. More
recently,
Gillies (2007)
has argued that
a strict analysis along those lines is actually preferable to an
account that builds the non-monotonicity of counterfactual antecedents
into their semantics, i.e., similarity analyses. This section will
outline the basic features of these second wave strict conditional
analyses.
The key idea in
Warmbrōd (1981a,b)
is that the accessibility sphere in the basic strict analysis should
be viewed as a parameter of the context. Roughly, the idea is that
\(R(w)\) corresponds to background facts assumed by the participants
of a discourse context. For example, if they are assuming propositions
(modeled as sets of possible worlds)
A
,
B
, and
C
then \(R(w)=A\cap B\cap C\). The other key idea is that trivial strict
conditionals are not pragmatically useful in conversation. If a strict
conditional \(\mathsf{A\strictif C}\) is asserted in a context with
background facts \(R(w)\) and \(\mathsf{A}\) is inconsistent with
\(R(w)\)—\({\llbracket}\mathsf{A}{\rrbracket}^R_v\cap
R(w)={\emptyset}\), then asserting \(\mathsf{A\strictif C}\) does not
provide any information. If there are no \(\mathsf{A}\)-worlds in
\(R(w)\), then, trivially, all \(\mathsf{A}\)-worlds in \(R(w)\) are
\(\mathsf{C}\)-worlds.
Warmbrōd
(1981a,b)
proposes that conversationalists adapt a pragmatic
rule of charitable interpretation to avoid trivialization:
(P)
If the antecedent \(\phi\) of a conditional is itself consistent,
    then \(R(w)\cap{\llbracket}\phi{\rrbracket}^R_v\) should be consistent.
On this view, \(R(w)\) may very well change over the course of a
discourse as a result of conversationalists adhering
to
(P)
. This part of the view is central to
explaining away counterexamples to antecedent monotonic
validities.
Consider again the example from
Goodman
1947
that appeared to be a counterexample
to
Antecedent Strengthening
.
(30)
a.
If I had struck this match, it would have lit.
b.
If I had struck this match and done so in a room without oxygen, it would have lit.
Now note that if
(30a)
is going to come out
true, the proposition that there is oxygen in the room
O
must
be true in all worlds in the initial accessibility sphere
\(R_0(w)\). However, if
(30b)
is interpreted
against \(R_0(w)\), the antecedent will be inconsistent with
\(R_0(w)\) and so express a trivial, uninformative
proposition.
Warmbrōd (1981a,b)
proposes that in interpreting
(30b)
we are
forced by to adopt a new, modified accessibility sphere \(R_1(w)\)
where
O
is no longer assumed. But if this is
right,
(30a)
and
(30b)
don’t constitute a counterexample to
Antecedent
Strengthening
because they are interpreted against different
accessibility spheres. It’s like saying
All current
U.S. presidents are intelligent
doesn’t entail
All
current U.S. presidents are unintelligent
because this sentence
before Donald Trump was sworn in was true, but uttering it afterwards
was false. There is an equivocation of context, or
so
Warmbrōd (1981a,b)
contends.
Warmbrōd (1981a,b)
outlines
parallel explanations of the counterexamples presented
to
SDA
,
Contraposition
,
and
Transititivity
. This significantly
complicates the issue of whether antecedent monotonicity is the key
issue in understanding the semantics of counterfactuals. It appears
that the non-monotonic interpretation of counterfactual antecedents
can either be captured pragmatically in the way that accessibility
spheres change in context
(Warmbrōd
1981a,b)
, or it can be captured semantically as we will see
from similarity analyses in
§2.3
. There
are significant limitations to Warmbrōd’s
(
(1981a,b)
) analysis: it does not
capture nested conditionals, and does not actually predict how
\(R(w)\) evolves to
satisfy
(P)
.
Fintel
(2001)
and
Gillies (2007)
offer
accounts that remove these limitations, and pose a challenge for
traditional similarity analyses.
Fintel (2001)
and
Gillies (2007)
propose analyses
where counterfactuals have strict truth-conditions, but they also have
a dynamic meaning which effectively changes \(R(w)\)
non-monotonically. They argue that such a theory can better explain
particular phenomena. Chief among them is reverse Sobel
sequences. Recall the sequence of
counterfactuals
(21)
presented by Lewis
(
1973b, 1973c: 419
), and attributed to
Howard Sobel. Reversing these sequences is not felicitous:
(31)
a.
If I had shirked my duty and you had too, harm would have ensued.
\(\mathsf{(I \land U)> H}\)
b.
# If I had shirked my duty, no harm would have ensued.
\(\mathsf{I > \neg H}\)
Fintel (2001)
and
Gillies (2007)
observe that
similarity analyses render sequences
like
(31)
semantically
consistent. Their theories predict this infelicity by providing a
theory of how counterfactuals in context can change
\(R(w)\). Unlike
Fintel
(2001)
,
Gillies (2007)
does not
rely essentially on a similarity ordering over possible worlds to
compute these changes to \(R(w)\), and so clearly counts as a second
wave strict analysis.
[
28
]
The debate over whether counterfactuals are
best given a strict or similarity analysis is very much
ongoing.
Moss
(2012)
,
Starr (2014)
,
and
K. Lewis (2018)
have proposed three
different ways of explaining reverse Sobel sequences within a
similarity analysis. But
Willer (2015, 2017,
2018)
has argued on the basis of other data that a dynamic
second wave strict analysis is preferable. This argument takes one
into a logical comparison of strict and similarity analyses, which
will be taken up in
§2.4
after the
similarity analysis has been presented in more detail.
2.3 Similarity Semantics
Recall the rough idea of the similarity analysis sketched
in
§2.1
: worlds can be ordered by
their similarity to the actual world, and counterfactuals say that the
most similar—or least different—worlds where the
antecedent is true are worlds where the consequent is also true. This
idea is commonly attributed to David Lewis and Robert Stalnaker, but
the actual history is a bit more nuanced. Although publication dates
do not tell the full story, the approach was developed roughly
contemporaneously by
Stalnaker
(1968)
,
Stalnaker and Thomason
(1970)
,
D. Lewis
(1973b)
,
Nute (1975b)
,
and
Sprigge
(1970)
.
[
29
]
And, there is an even earlier statement of
the view:
When we allow for the possibility of the antecedent’s being true
in the case of a counterfactual, we are hypothetically substituting a
different world for the actual one. It has to be supposed that this
hypothetical world is as much like the actual one as possible so that
we will have grounds for saying that the consequent would be realized
in such a world.
(Todd 1964: 107)
Recall the major difference between this proposal and
the
basic strict analysis
: the similarity
analysis uses a graded notion of similarity instead of an absolute
notion of accessibility. It also allows most similar worlds to vary
between counterfactuals with different antecedents. These differences
invalidate antecedent monotonic inference patterns. This section will
introduce similarity analyses in a bit more formal detail and describe
the differences between analyses within this family.
The similarity analysis has come in many varieties and formulations,
including the system of spheres approach informally described
in
§2.1
. That formulation is
easiest for comparison to strict analyses. But there is a different
formulation that is more intuitive and better facilitates comparison
among different similarity analyses. This formulation appeals to a
(set) selection function
f
, which takes a world
w
, a
proposition
p
, and returns the set of
p
-worlds most
similar to
w
: \(f(w,p)\).
[
30
]
\(\phi>\psi\) is then said to be true
when the most
f
-similar \(\phi\)-worlds to
w
are
\(\psi\)-worlds, i.e., every world in
\(f(w,{\llbracket}\phi{\rrbracket}^f_v)\) is in
\({\llbracket}\psi{\rrbracket}^f_v\). The basics of this approach can
be summed up thus.
Similarity Analysis
\(\phi > \psi\) is true at
w
just in case all \(\phi\)-worlds most
similar
to
w
are \(\psi\)-worlds
Most similar according to the
selection function
f
f
takes a proposition
p
and a world
w
and returns the
p
-worlds most similar to
w
\(\llbracket\phi > \psi\rrbracket^{f}_v=\{w\mid f(w,\llbracket\phi\rrbracket^{f}_v)\subseteq\llbracket\psi\rrbracket^{f}_v\}\)
Making “limit assumption”: \(\phi\)-worlds do not get indefinitely more and more similar to
w
(Stalnaker 1968; D. Lewis 1973b; Nute 1975a; Pollock 1976)
As noted, this formulation makes the limit assumption: \(\phi\)-worlds
do not get indefinitely more and more similar
to
w
. While
D. Lewis (1973b)
rejected this assumption, adopting it will serve exposition. It is
discussed at length in the supplement
Formal
Constraints on Similarity
. The logic of counterfactuals generated
by a similarity analysis will depend on the constraints imposed
on
f
. Different theorists have defended different
constraints.
Table 1
lists them, where
\(p,q\subseteq W\) and \(w\in W\):
(a)
\(f(w,p)\subseteq p\)
success
(b)
\(f(w,p)=\{w\}\), if \(w\in p\)
strong centering
(c)
\(f(w,p)\subseteq q\) & \(f(w,q)\subseteq p \; {\Longrightarrow}\; f(w,p)=f(w,q)\)
uniformity
(d)
\(f(w,p)\) contains
at most
one world
uniqueness
Table 1:
Candidate Constraints on Selection Functions
Modulo the limit assumption,
Table
2
provides an overview of which analyses have adopted which
constraints.
Similarity Analysis
Constraints Adopted
Pollock (1976)
success, strong centering
D. Lewis (1973b)
,
Nute (1975a)
success, strong centering, uniformity
Stalnaker (1968)
success, strong centering, uniformity, uniqueness
Table 2:
Similarity Analyses, modulo Limit Assumption
simply enforces that \(f(w,p)\) is indeed a set
of
p
-worlds. Recall that \(f(w,p)\) is supposed to be the set
of most similar
p
-worlds to
w
. The other constraints
correspond to certain logical validities, as detailed in the
supplement
Formal Constraints on
Similarity
. This means that
Pollock
(1976)
endorses the weakest logic for counterfactuals
and
Stalnaker (1968)
the strongest. It
is worth seeing how, independently of constraints (b)–(d), this
semantics invalidates an
antecedent monotonicity
pattern like
Antecedent Strengthening
.
Consider an instance of
Antecedent Strengthening
involving \(\mathsf{A > C}\) and \(\mathsf{(A\land B)>C}\), and
where the space of worlds is that given in
Table
3
.
World
\(\mathsf{A}\)
\(\mathsf{B}\)
\(\mathsf{C}\)
\(w_{0}\)
1
1
1
\(w_{1}\)
1
1
0
\(w_{2}\)
1
0
1
\(w_{3}\)
1
0
0
\(w_{4}\)
0
1
1
\(w_{5}\)
0
1
0
\(w_{6}\)
0
0
1
\(w_{7}\)
0
0
0
Table 3:
A space of worlds
W
, and truth-values at each world
Now evaluate \(\mathsf{A > C}\) and \(\mathsf{(A\land B)>C}\) in \(w_{5}\) using a selection function \(f_1\) with the following features:
\(f_1(w_{5},{\llbracket}\mathsf{A}{\rrbracket}^{f_1}_v)=\{w_{2}\}\)
\(f_1(w_{5},{\llbracket}\mathsf{A}\land\mathsf{B}{\rrbracket}^{f_1}_v)=\{w_{1}\}\)
Since \(\mathsf{C}\) is true in \(w_{2}\), \(\mathsf{A > C}\) is
true in \(w_{5}\) according to \(f_1\). But, since \(\mathsf{C}\) is
false in \(w_{1}\), \(\mathsf{(A\land B) > C}\) is false in
\(w_{5}\) according to \(f_1\). No constraints are needed here other
than
success
. While \(f_1\)
satisfies
uniqueness
, the
counterexample works just as well if, say,
\(f_1(w_{5},{\llbracket}\mathsf{A}{\rrbracket}^{f_1}_v)=\{w_{2},w_0\}\). Accordingly,
all similarity analyses allow for the non-monotonic interpretation of
counterfactual antecedents.
While
Stalnaker (1968)
and
D. Lewis (1973b)
remain the most
popular similarity analyses, there are substantial logical issues
which separate similarity analyses. These issues, and the constraints
underlying them, are detailed in the
supplement
Formal Constraints on
Similarity
.
Table 4
summarizes
which validities go with which constraints.
Constraint
Validity
Strong Centering
Modus Ponens
\(\phi>\psi, \phi\vDash \psi\)
Conjunction Conditionalization
\(\phi\land\psi \vDash \phi>\psi\)
Uniformity
Substitution of Subjunctive Equivalents (SSE)
\(\phi_1>\phi_2,\phi_2>\phi_1,\phi_1>\psi\vDash \phi_2>\psi\)
Limited Transitivity (LT)
\(\phi_1>\phi_2,(\phi_1\land\phi_2)>\psi\vDash \phi_1>\psi\)
Limited Antecedent Strengthening (LAS)
\(\phi_1>\phi_2,\neg(\phi_1>\neg\psi)\vDash(\phi_1\land\phi_2)>\psi\)
Uniqueness
Conditional Excluded Middle
\(\vDash (\phi>\psi)\lor(\phi>\neg\psi)\)
Conditional Negation (CN)
\({\Diamond}\phi\land\neg(\phi>\psi)\,\leftmodels\vDash {\Diamond}\phi\land\phi>\neg\psi\)
Consequent Distribution (CD)
\(\phi>(\psi_1\lor\psi_2)\vDash(\phi>\psi_1)\lor(\phi>\psi_2)\)
Limit Assumption
Infinite Consequent Entailment
If \(\Gamma={\{\phi_2,\phi_3,{\ldots}\}}\), \(\phi_1>\phi_2,\phi_1>\phi_3,{\ldots}\) are true and \(\Gamma\vDash\psi\) then \(\phi_1>\psi\)
Table 4:
Selection Constraints & Associated Validities
A few comments are in order here, though.  Strong centering is
sufficient but not necessary for Modus Ponens, weak centering would
do: \(w\in f(w,p)\) if \(w\in p\). LT and LAS follow from SSE, and
allow similarity theorists to say why some instances
of
Transititivity
and
Antecedent Strengthening
are intuitively
compelling.
2.4 Comparing the Logics
The issue of whether a second wave strict analysis
(
§2.2.1
) or a similarity
analysis provides a better logic of counterfactuals is very much an
open and subtle issue. As
sections
2.2.1
and
2.3
detailed, both analyses have their own
way of capturing the non-monotonic interpretation of antecedents. Both
analyses also have their own way of capturing instances of monotonic
inferences that do sound good. Perhaps this issue is destined for a
stalemate.
[
31
]
But before declaring it such, it is important to investigate two
patterns that are potentially more
decisive:
Simplification of Disjunctive
Antecedents
, and a pattern not yet discussed
called
Import-Export
.
Both
SDA
and
Import-Export
are valid in a strict
analyses and invalid on standard similarity analyses. Crucially, the
counterexamples to them that have been offered by similarity theorists
are significantly less compelling than those offered to patterns
like
Antecedent Strengthening
. Import-Export
relates counterfactuals like
(33a)
and
(33b)
.
(33)
a.
If Jean-Paul had danced and Simone had drummed, there would have been a groovy party.
b.
If Jean-Paul had danced, then if Simone had drummed, there would have been a groovy party.
It is hard to imagine one being true without the
other. The
basic strict analysis
agrees:
it renders them equivalent.
Import-Export
\((\phi_1\land\phi_2)>\psi\,\leftmodels\vDash \phi_1>(\phi_2>\psi)\)
But it is not valid on a
similarity analysis
.
[
32
]
While
Import-Export
is generally regarded
as a plausible principle, some have challenged
it.
Kaufmann (2005: 213)
presents an
example involving indicative conditionals which can be adapted to
subjunctives. Consider a case where there is a wet match which will
light if tossed in the campfire, but not if it is struck. It has not
been lit. Consider now:
(34)
a.
If this match had been lit, it would have been lit if it had been struck.
b.
If this match had been struck and it had been lit, it would have been lit.
One might then deny
(34a)
. This match would
not have lit if it had been struck, and if it had lit it would have to
have been thrown into the campfire.
(34b)
,
on the other hand, seems like a straightforward logical
truth. However, it is worth noting that this intuition
about
(34a)
is very fragile. The slight
variation of
(34a)
in
(35)
is easy to hear as
true.
(35)
If this match had been lit, then if it had been struck it (still) would have been lit.
This subtle issue may be moot, however.
Starr
(2014)
shows that a dynamic semantic implementation of the
similarity analysis can
validate
Import-Export
, so it may not be
important for settling between strict and similarity analyses.
As for the
Simplification of Disjunctive Antecedents (SDA)
,
Fine
(1975)
,
Nute
(1975b)
,
Loewer (1976)
,
and
Warmbrōd (1981)
each object to
the similarity analysis predicting that this pattern is
invalid. Counterexamples like
(29)
from
Mckay & van Inwagen 1977: 354)
have a suspicious feature.
(29)
a.
If Spain had fought for the Axis or the Allies, she would have fought for the Axis.
b.
If Spain had fought for the Allies, she would have fought for the Axis.
Starr (2014: 1049)
and
Warmbrōd (1981a: 284)
observe
 that
(29a)
seems to be another way of saying
that Spain would never have fought for the
Allies. While
Warmbrōd (1981a: 284)
uses this to pragmatically explain-away this counterexample to his
strict analysis,
Starr (2014: 1049)
makes a further critical point: it sounds inconsistent to
 say
(29a)
after asserting that Spain could have fought for the Allies.
(36)
Spain didn’t fight for either the Allies or the Axis.
She really could have fought for the Allies.
# But, if she had fought for the Axis or the Allies, she would have fought for the Axis.
Starr (2014: 1049)
argues that this
makes it inconsistent for a similarity theorist to regard this as a
 counterexample to
SDA
. On a similarity analysis
of the
could
claim, it follows that there are no worlds in
which Spain fought for the Allies most similar to the actual world:
\(f(w_@,{\llbracket}\mathsf{Allies}{\rrbracket})={\emptyset}\). But if
 that’s the case, then
(29b)
is vacuously
true on a similarity analysis, and so a similarity theorist cannot
consistently claim that this is a case where the premise is true and
conclusion false. It is, however, too soon for the strict theorist to
declare victory.
Nute
(1980a)
,
Alonso-Ovalle (2009)
,
and
Starr (2014: 1049)
each develop
similarity analyses where disjunction is given a non-Boolean
 interpretation to validate
SDA
without validating
the other antecedent monotonic patterns. But even this is not the end
 of the
SDA
debate.
Nute (1980b: 33)
considers a similar
antecedent simplification pattern involving negated conjunctions:
Simplification of Negated Conjunctive Antecedents (SNCA)
\(\neg(\phi_1\land \phi_2)>\neg \psi\vDash (\neg\phi_1>\psi)\land(\neg\phi_2>\psi)\)
Nute (1980b: 33)
presents
(37)
in favor of SNCA.
(37)
a.
If Nixon and Agnew had not both resigned, Ford would never have become President.
\(\mathsf{\neg(N\land A)>\neg F}\)
b.
If Nixon had not resigned, Ford would never have become President.
\(\mathsf{\neg N>\neg F}\)
c.
If Agnew had not resigned, Ford would never have become President.
\(\mathsf{\neg A>\neg F}\)
Note that \(\mathsf{\neg(N\land A)}\) and 
\(\mathsf{\neg N\lor\neg A}\) are Boolean equivalents. However, 
non-Boolean analyses like
Nute (1980a)
,
Alonso-Ovalle (2009)
,
and
Starr (2014: 1049)
designed to
 capture
SDA
break this equivalence, and so fail
 to predict that
SNCA
is valid.
Willer (2015, 2017)
develops a
dynamic strict analysis which validates both
SDA
and SNCA.
Fine (2012a,b)
advocates for a
departure from possible worlds semantics altogether in order to
capture both
SDA
and SNCA. However, these
 accounts also face counterexamples.
Fine
(2012a,b)
and
Willer (2015, 2017)
render \((\neg\phi_1\lor\neg\phi_2)>\psi\) and
\(\neg(\phi_1\land\phi_2)>\psi\) equivalent,
while
Champollion, Ciardelli, and Zhang
(2016)
present a powerful counterexample to this
equivalence.
Champollion, Ciardelli, and Zhang (2016)
consider a light which is on when switches
A
and
B
are
both up, or both down. Currently, both switches are up, and the light
is on. Consider
(38a)
and
(38b)
whose antecedents are Boolean equivalents:
(38)
a.
If Switch
A
or Switch
B
were down, the light would be off.
\(\mathsf{(\neg A\lor\neg B)>\neg L}\)
b.
If Switch
A
and Switch
B
were not both up, the light would be off.
\(\mathsf{\neg (A\land B)>\neg L}\)
While
(38a)
is intuitively true,
(38b)
is
 not.
[
33
]
This is not a counterexample to
SNCA
,
 since the premise of that pattern is false. But such a counterexample 
is not hard to think
 up.
[
34
]
Suppose the baker’s apprentice completely failed at baking our
cake. It was burnt to a crisp, and the thin, lumpy frosting came out
puke green. The baker planned to redecorate it to make it at least
look delicious, but did not have time. We may explain our extreme
dissatisfaction by asserting
(39a)
.
 But the
baker should not infer
(39b)
and assume that his redecoration plan would have worked.
(39)
a.
If the cake had not been burnt to a crisp and ugly, we would have been happy.
\(\mathsf{\neg(B\land U)>H}\)
b.
If the cake had not been ugly, we would have been happy.
\(\mathsf{\neg U>H}\)
Willer (2017: §4.2)
suggests that
 such a counterexample trades on interpreting 
\(\mathsf{\neg(B\land U)>H}\) 
as 
\(\mathsf{\neg B\land\neg U)>H}\), 
and provides an
independent explanation of this on the basis of how negation and
conjunction interact. If this is right, then an analysis which
 validates
SDA
and
SNCA
without rendering \(\neg(\phi_1\land\phi_2)>\psi\) and
\(\neg\phi_1\lor\neg\phi_2>\psi\) equivalent is what’s
needed.
Ciardelli, Zhang, and Champollion
(forthcoming)
develop just such an
analysis. As
Ciardelli, Zhang, and Champollion
(forthcoming: §6.4)
explain,
SDA
and
SNCA
turn out to be valid for very different
reasons.
Champollion, Ciardelli, and Zhang
(2016) and Ciardelli, Zhang, and Champollion (forthcoming)
also argue that the falsity of
(38b)
cannot be predicted on a similarity analysis. This example must be
added to a long list of examples which have been presented not as
counterexamples to the logic of the similarity analysis, but to what
it predicts (or fails to predict) about the truth of particular
counterfactuals in particular contexts. This will be the topic
 of
§2.5
,
 where it will also be
explained why the strict analysis faces similar challenges.
Where does this leave us in logical the debate between strict and
similarity analyses of counterfactuals?
Even
Import-Export
and
SDA
fail to clearly identify one analysis as
superior. It is possible to capture
SDA
on either
analysis. Existing similarity analyses that
validate
SDA
, however, also
invalidate
SNCA
(Alonso-Ovalle
2009; Starr 2014)
. By contrast existing strict analyses that
validate
SDA
also
validate
SNCA
(Willer 2015,
2017)
. However, this is far from decisive. The validity of SNCA
is still being investigated, and it is far from clear that it is
impossible to have a similarity analysis that validates
both
SDA
and SNCA, or a strict analysis that
validates only
SDA
(perhaps using a non-Boolean
semantics for disjunction). So even SNCA may fail to be the conclusive
pattern needed to separate these analyses.
2.5 Truth-Conditions Revisited
In their own ways,
Stalnaker (1968,
1984)
and
D. lewis (1973b)
are
candid that the similarity analysis is not a complete analysis of
counterfactuals. As should be clear
from
§2.3
, the formal constraints they
place on similarity are quite minimal and only serve to settle matters
of logic. There are, in general, very many possible selection
functions—and corresponding conceptions of similarity—for
any given counterfactual. To explain how a given counterfactual
like
(40)
expresses a true proposition, a
similarity analysis must specify which particular conception of
similarity informs it.
(40)
If my computer were off, the screen would be blank.
Of course, the strict analysis is in the same position. It cannot
predict the truth of
(40)
without specifying
a particular accessibility relation. In turn, the same question
arises: on what basis do ordinary speakers determine some worlds to be
accessible and others not? This section will overview attempts to
answer these questions, and the many counterexamples those attempts
have invited. These counterexamples have been a central motivation for
pursuing alternative semantic analyses, which will be covered
in
§3
. While this section follows
the focus of the literature on the similarity analysis
(
§2.5.1
),
§2.5.2
will briefly detail how parallel criticisms apply to strict
analyses.
2.5.1 Truth-Conditions and Similarity
What determines which worlds are counted as most similar when
evaluating a counterfactual?
Stalnaker
(1968)
explicitly sets this issue aside,
but
D. Lewis (1973b: 92)
makes a clear
proposal:
Lewis’ (1973b: 92) Proposal
Our familiar, intuitive concept of comparative overall similarity, just applied to possible worlds, is employed in assessing counterfactuals.
Just as counterfactuals are context-dependent and vague, so is our
intuitive notion of overall similarity. In comparing cost of living,
New York and San Francisco may count as similar, but not in comparing
topography. And yet,
Lewis’ (1973b: 92)
Proposal
has faced a barrage of counterexamples. Lewis and
Stalnaker parted ways in their responses to these counterexamples,
though both grant that
Lewis’ (1973b: 92)
Proposal
was not viable.
Stalnaker (1984:
Ch.7)
proposes
the projection strategy
: similarity is
determined by the way we “project our epistemic policies onto
the world”.
D. Lewis 1979)
proposes a new system of weights that amounts to a kind of
curve-fitting: we must first look to which counterfactuals are
intuitively true, and then find ways of weighting respects of
similarity—however complex—that support the truth of
counterfactuals. Since
Lewis’ (1973b: 92)
Proposal
and Lewis’ (
1979
)
system of weights are more developed, and have received extensive
critical attention, they will be the focus of this
section.
[
35
]
It will begin with the objections to
Lewis’
(1973b: 92) Proposal
that motivated Lewis’
(
1979
) system of weights, and then some
objections to that approach.
Fine (1975: 452)
presents
the
future similarity objection
to
Lewis’ (1973b: 92)
Proposal
.
(41)
is plausibly a true
statement about world history.
(41)
If Nixon had pressed the button there would have a been a nuclear holocaust
(\(\mathsf{B>H}\))
Suppose, optimistically, that there never will be a nuclear
holocaust. Then, for every \(\mathsf{B\land H}\)-world, there will be
a more similar \(\mathsf{B\land\neg H}\)-world, one where a small
difference prevents the holocaust, such as a malfunction in the
electrical detonation system. In short, a world where Nixon presses
the button and a malfunction prevents a nuclear holocaust is more like
our own than one where there is a nuclear holocaust that changes the
face of the planet. But then
Lewis’ (1973b: 92)
Proposal
incorrectly predicts
that
(41)
is false.
Tichý (1976: 271)
offers a
similar
counterexample. Given
(42a)
–
(42c)
,
(42d)
sounds false.
(42)
a.
Invariably, if it is raining, Jones wears his hat.
b.
If it is not raining, Jones wears his hat at random.
c.
Today, it is raining and so Jones is wearing his hat.
d.
But, even if it had not been raining, Jones would have been wearing his hat.
Lewis’ (1973b: 92) Proposal
does not seem to predict the falsity of
(42d)
. After all, Jones is wearing his hat in the actual world, so isn’t a world where it’s not raining and he’s wearing his hat more similar to the actual one than one where it’s not raining and he isn’t wearing his hat?
(1979: 472)
responds to these examples by proposing a ranked system of weights that give what he calls
the standard resolution of similarity
, which may be further modulated in context:
Lewis’ (1979) System of Weights
Avoid big, widespread, diverse violations of law. (“big miracles”)
Maximize the spatio-temporal region throughout which perfect match of particular fact 
				prevails.
Maximize the time period over which the worlds match exactly in matters of fact
Avoid even small, localized, simple violations of law. (“little miracles”)
It is of little or no importance to secure approximate similarity of particular fact, even in matters that concern us greatly.
While weight 2 gives high importance to keeping particular facts fixed up to the change required by the counterfactual, weight 4 makes clear that particular facts after that point need not be kept fixed. In the case of
(42d)
the fact that Jones is wearing his hat need not be kept fixed. It was a post-rain fact, so when one counterfactually supposes that it had not been raining, there is no reason to assume that Jones is still wearing his hat. Similarly, with example
(41)
. A world where Nixon pushes the button, a small miracle occurs to short-circuit the equipment and the nuclear holocaust is prevented will count as less similar than one where there is no small miracle and a nuclear holocaust results. A small-miracle and no-holocaust world is similar to our own only in one insignificant respect (particular matters of fact) and dissimilar in one important respect (the small miracle).
It is clear, however, that
Lewis’ (1979) System of Weights
is insufficiently general. Particular matters of fact often
are
held fixed.
(43)
[You’re invited to bet heads on a coin-toss. You decline. The coin comes up heads.] See, if you had bet heads you would have won!
(Slote 1978: 27 fn33)
(44)
If we had bought one more artichoke this morning, we would have had one for everyone at dinner tonight. (Sanford 1989: 173)
Example
(43)
crucially holds fixed the outcome of a highly contingent particular fact: the coin outcome. Cases of this kind are discussed extensively by
Edgington (2004)
. Example
(44)
shows that a chancy outcome is not an essential feature of these cases. Noting the existence of recalcitrant cases,
(1979: 472)
simply says he wishes he knew why they came out differently. Additional counterexamples to the
Lewis’ (1979) System of Weights
have been proposed by
Bowie (1979)
,
Kment (2006)
, and
Wasserman (2006)
.
[
36
]
Kment (2006: 458)
proposes a new similarity metric to handle this example which is sensitive to the way particular facts are explained, and is integrated into a general account of metaphysical modality in
Kment (2014)
.
Ippolito (2016)
proposes a new theory of how context determines similarity for counterfactuals which aims to make the correct predictions about many of the above cases.
Another response to these counterexamples has been to develop alternative semantic analyses of counterfactuals such as premise semantics
(Kratzer 1989, 2012; Veltman 2005)
and causal models
(Schulz 2007 2011;  Briggs 2012; Kaufmann 2013)
. These accounts start from the observation that the counterexamples can be easily explained in a model where matters of fact depend on each other. In
(42)
, when we counterfactually retract the fact that it rained, we don’t keep the fact that the man was wearing his hat because that fact depended on it raining. Hence,
(42d)
is false. In
(43)
, when we counterfactually retract that you didn’t bet on heads, we keep the fact that the coin came up heads because it is independent of the fact that you didn’t bet on heads. These accounts offer models of how laws, and law-like generalizations, make facts dependent on each other, and argue that once this is done, there is no work left for similarity to do in the semantics of counterfactuals. While these accounts are the focus of
§3
, it is worth presenting one of the additional counterexamples to the similarity analysis that has emerged from this literature.
Recall
(38)
from
§2.4
.
Champollion, Ciardelli, and Zhang (2016)
and
Ciardelli, Zhang, and Champollion (forthcoming)
argue on the basis of this example that any similarity analysis will make incorrect predictions about the truth-conditions of counterfactuals. In this example a light is on either when Switch A and B are both up, or they are both down. Otherwise the light is off. Suppose both switches are up and the light is on.
(38)
a.
If Switch
A
or Switch
B
were down, the light would be off.
\(\mathsf{(\neg A\lor\neg B)>\neg L}\)
b.
If Switch
A
and Switch
B
were not both up, the light would be off.
\(\mathsf{\neg (A\land B)>\neg L}\)
Intuitively,
(38a)
is true, as are \(\mathsf{\neg A >\neg L}\) and \(\mathsf{\neg B >\neg L}\), but
(38b)
is false.
Champollion, Ciardelli, and Zhang (2016: 321)
argue that a similarity analysis cannot predict \(\mathsf{\neg A >\neg L}\) and \(\mathsf{\neg B >\neg L}\) to be true, while
(38b)
is false. In order for \(\mathsf{\neg A >\neg L}\) to be true, the particular fact that Switch B is up must count towards similarity. Similarly, for \(\mathsf{\neg B >\neg L}\) to be true, the particular fact that Switch A is up must count towards similarity. But then it follows that
(38b)
is true on a similarity analysis: the most similar worlds where A and B are not both up have to either be worlds where Switch B is down but Switch A is still up, or Switch A is down and Switch B is still up. In those worlds, the light would be off, so the similarity analysis incorrectly predicts
(38b)
to be true.
Champollion, Ciardelli, and Zhang (2016)
instead pursue a semantics in terms of causal models where counterfactually making \(\neg \mathsf{(A\land B)}\) true and making \(\mathsf{\neg A\lor\neg B}\) true come apart.
2.5.2 Truth-Conditions and the Strict Analysis
Do strict analyses avoid the troubles faced by similarity analyses when it comes to truth-conditions? This question is difficult to answer, and has not been explicitly discussed in the literature. Other than the theory of
Warmbrōd (1981a,b)
, strict theorists have not made proposals for the accessibility relation analogous to
Lewis’ (1973b: 92) Proposal
for similarity. And, Warmbrōd’s proposal about the pragmatics of the accessibility relation is this:
Warmbrōd’s (1981b: 280) Proposal
In the normal case of interpreting a conditional with a nonabsurd antecedent
p
, the worlds accessible from
w
will be those that are as similar to
w
as the most similar
p
-worlds.
All subsequent second wave strict analyses have ended up in similar
territory. The dynamic analyses developed
by
Fintel
(2001)
,
Gillies (2007)
,
and
Willer (2015, 2017, 2018)
assign
strict truth-conditions to counterfactuals, but have them induce
changes in an evolving space of possible worlds. These changes must
render the antecedent consistent with an evolving body of
discourse. While
Fintel (2001)
and
Willer (2018)
explicitly appeal to a
similarity ordering for this purpose,
Gillies
(2007)
and
Willer (2017)
do
not. Nevertheless, the formal structures used
by
Gillies (2007)
and
Willer (2017)
for this purpose give
rise to the same question: which facts stay and which facts go when
rendering the counterfactual antecedent consistent? Accordingly, at
present, it does not appear that the strict analysis avoids the kinds
of concerns raised for the similarity analysis
in
§2.5.1
.
2.6 Philosophical Objections
Recall
Goodman’s Problem
from
§1.4
: the truth-conditions of
counterfactuals intuitively depend on background facts and laws, but
it is difficult to specify these facts and laws in a way that does not
itself appeal to counterfactuals. Strict and similarity analyses make
progress on the logic of conditionals without directly confronting
this problem. But the discussion
of
§ 2.5
makes salient a
related problem.
Lewis’ (1979) System of
Weights
amounts to reverse-engineering a similarity relation to
fit the intuitive truth-conditions of counterfactuals. While
Lewis’ (
1979
) approach avoids
characterizing laws and facts in counterfactual
terms,
Bowie (1979: 496–497)
argues that it does not explain why certain counterfactuals are true
without appealing to counterfactuals. Suppose one asks why certain
counterfactuals are true and the similarity theorist replies with
Lewis’ (
1979
) recipe for
similarity. If one asks why those facts about similarity make
counterfactuals true, the similarity theorist cannot reply that they
are basic self-evident truths about the similarity of worlds. Instead,
they must say that those similarity facts make those counterfactuals
true. Bowie’s (
1979:
496–497
) criticism is that this is at best uninformative,
and at worst circular.
A related concern is voiced by
Horwich (1987:
172)
who asks “why we should have evolved such a baroque
notion of counterfactual dependence”, namely that captured
by
Lewis’ (1979) System of
Weights
. The concern has two components: why would humans find it
useful, and why would human psychology ground counterfactuals in this
concept of similarity rather than our ready-at-hand intuitive concept
of overall similarity? These questions are given more weight given the
centrality of counterfactuals to human rationality and scientific
explanation outlined in
§1
. Psychological
theories of counterfactual reasoning and representation have found
tools other than similarity more fruitful
(
§1.2
). Similarly, work on
scientific explanation has not assigned any central role for
similarity (
1.3
), and
as
Hájek (2014: 250)
puts it:
Science has no truck with a notion of similarity; nor does
Lewis’ (
1979
) ordering of what
matters to similarity have a basis in science.
Morreau (2010)
has recently argued on
 formal grounds that similarity is poorly suited to the task assigned
 to it by the similarity analysis. The similarity analysis, especially
 as elaborated by
D. Lewis (1979)
, tries
 to weigh some similarities between worlds against their differences
 to arrive at a notion of overall comparative similarity between those
 worlds.
Morreau (2010: 471)
argues
 that:
[w]e cannot add up similarities or weigh them against differences. Nor
can we combine them in any other way… No useful comparisons of
overall similarity result.
(Morreau 2010:
§4)
articulates this argument formally via a reinterpretation of
Arrow’s Theorem in social choice theory. Arrow’s Theorem
shows that it is not possible to aggregate individuals’
preferences regarding some alternative outcomes into a coherent
“collective preference” ordering over those outcomes,
given minimal assumptions about their rationality and autonomy. As
summarized in §6.3
of
Arrow’s
theorem
,
Morreau (2010)
argues that
the same applies to aggregating respects of similarity and difference:
there is no way to add them up into a coherent notion of overall
similarity.
2.7 Summary
Strict and similarity analyses of counterfactuals showed that it was
possible to address the semantic puzzles described
in
§1.4
with formally explicit
logical models. This dispelled widespread skepticism of
counterfactuals and established a major area of interdisciplinary
research. Strict analyses have been revealed to provide a stronger,
more classical, logic, but must be integrated with a pragmatic
explanation of how counterfactual antecedents are interpreted
non-monotonically. Similarity analyses provide a much weaker, more
non-classical, logic, but capture the non-monotonic interpretation of
counterfactual antecedents within their core semantic model. It is now
a highly subtle and intensely debated question which analysis provides
a better logic for counterfactuals, and which version of each kind of
analysis is best. This intense scrutiny and development has also
generated a wave of criticism focused on their treatment of
truth-conditions,
Goodman’s Problem
, and
integration with thinking about counterfactuals in psychology and the
philosophy of science
(
§2.5
,
§2.6
). None
of these criticisms are absolutely conclusive, and these two analyses,
particularly the similarity analysis, remain standard in philosophy
and linguistics. However, the criticisms are serious enough to merit
exploring alternative analyses. These alternative accounts take
inspiration from a particular diagnosis of the counterexamples
discussed in
§2.5
: facts
depend on each other, so counterfactually assuming
p
involves
not just giving up
not-p
, but any facts which depended
on
not-p
. The next section will examine analyses of this
kind.
3. Semantic Theories of Counterfactual Dependence
Similarity and strict analyses nowhere refer to facts, or
propositions, depending on each
other. Indeed,
1979
was primarily
concerned with explaining which true counterfactuals, given a
similarity analysis, manifest a relation of counterfactual
dependence. Other analyses have instead started with the idea that
facts depend on each other, and then explain how these relations of
dependence make counterfactuals true. As will become clear, none of
these analyses endorse the naive idea that \(\mathsf{A > B}\) is
true only when
B
counterfactually depends on
A
. The
dependence can be more complex, indirect, or
B
could just be
true and independent of
A
. Theories in this family differ
crucially in how they model counterfactual dependence. In premise
semantics (
§3.1
) dependence is modeled in
terms of how facts, which are modeled as parts of worlds, are
distributed across a space of worlds that has been constrained by
laws, or law-like generalizations. In probabilistic semantics
(
§3.2
), this dependence is modeled as
some form of conditional probability. In Bayesian networks, structural
equations, and causal models
(
§3.3
), it is modeled in
terms of the Bayesian networks discussed at the beginning
of
§1.2.3
. Because theories of
these three kinds are very much still in development and often involve
even more sophisticated formal models than those covered
in
§2
, this section will have to be more
cursory than
§2
to ensure breadth and
accessibility.
3.1 Premise Semantics
Veltman (1976)
and
Kratzer (1981b)
approached
counterfactuals from a perspective closer
to
Goodman (1947)
: counterfactuals
involve explicitly adjusting a body of premises, facts or propositions
to be consistent with the counterfactual’s antecedent, and
checking to see if the consequent follows from the revised premise
set—in a sense of “follow” to be articulated
carefully. Since facts or premises hang together, changing one
requires changing others that depend on it. The function of
counterfactuals is to allow us to probe these connections between
facts. While
D. Lewis (1981)
proved that
the
Kratzer (1981b)
analysis was a
special case of similarity semantics, subsequent refinements of
premise semantics in
Kratzer (1989, 1990, 2002,
2012)
and
Veltman (2005)
evidenced important differences.
Kratzer (1989:
626)
nicely captures the key difference:
[I]t is not that the similarity theory says anything false about [particular] examples… It just doesn’t say enough. It stays vague where our intuitions are relatively sharp. I think we should aim for a theory of counterfactuals that is able to make more concrete predictions with respect to particular examples.
From a logical point of view, premise semantics and similarity semantics do not diverge. They diverge in the concrete predictions made about the truth-conditions of counterfactuals in particular contexts without adding additional constraints to the theory like
Lewis’ (1979) System of Weights
.
How does premise semantics aim to improve on the predictions of similarity semantics? It re-divides the labor between context and the semantics of counterfactuals to more accurately capture the intuitive truth-conditions of counterfactuals, and intuitive characterizations of how context influences counterfactuals. In premise semantics, context provides facts and law-like relations among them, and the counterfactual semantics exploits this information. By contrast, the similarity analysis assumes that context somehow makes a similarity relation salient, and has to make further stipulations like
Lewis’ (1979) System of Weights
about how facts and laws enter into the truth-conditions of counterfactuals in particular contexts. This can be illustrated by considering how Tichý’s (
1976
) example
(42)
is analyzed in premise semantics. This illustration will use the
Veltman (2005)
analysis because it is simpler than
Kratzer (1989, 2012)
—that is not to say it is preferable. The added complexity in
Kratzer (1989, 2012)
provides more flexibility and a broader empirical range including quantification and modal expressions other than
would
-counterfactuals.
Recall Tichý’s (
1976
) example, with the intuitively false counterfactual
(42d)
:
(42)
a.
Invariably, if it is raining, Jones wears his hat.
b.
If it is not raining, Jones wears his hat at random.
c.
Today, it is raining and so Jones is wearing his hat.
d.
But, even if it had not been raining, Jones would have been wearing his hat.
Veltman (2005)
models how the sentences leading up to the counterfactual
(42d)
determine the facts and laws relevant to its interpretation. The law-like generalization in
(42a)
is treated as a strict conditional which places a hard constraint on the space of worlds relevant to evaluating the counterfactual.
[
37
]
The particular facts introduced by
(42c)
provide a soft constraint on the worlds relevant to interpreting the counterfactual.
Figure  9
illustrates this model of the context and its evolution, including a third atomic sentence \(\mathsf{H}\) for reasons that will become clear shortly.
\(C_0\)
\(\mathsf{R}\)
\(\mathsf{W}\)
\(\mathsf{H}\)
\(\boldsymbol{w_0}\)
0
0
0
\(\boldsymbol{w_1}\)
0
0
1
\(\boldsymbol{w_2}\)
0
1
0
\(\boldsymbol{w_3}\)
0
1
1
\(\boldsymbol{w_4}\)
1
0
0
\(\boldsymbol{w_5}\)
1
0
1
\(\boldsymbol{w_6}\)
1
1
0
\(\boldsymbol{w_7}\)
1
1
1
\(\hspace{15px}\underrightarrow{\medsquare(\mathsf{R\supset W})}\)
\(C_1\)
\(\mathsf{R}\)
\(\mathsf{W}\)
\(\mathsf{H}\)
\(\boldsymbol{w_0}\)
0
0
0
\(\boldsymbol{w_1}\)
0
0
1
\(\boldsymbol{w_2}\)
0
1
0
\(\boldsymbol{w_3}\)
0
1
1
\(\xcancel{w_4}\)
\(\xcancel{1}\)
\(\xcancel{0}\)
\(\xcancel{0}\)
\(\xcancel{w_5}\)
\(\xcancel{1}\)
\(\xcancel{0}\)
\(\xcancel{1}\)
\(\boldsymbol{w_6}\)
1
1
0
\(\boldsymbol{w_7}\)
1
1
1
\(\quad\underrightarrow{\mathsf{R\land W}}\)
\(C_2\)
\(\mathsf{R}\)
\(\mathsf{W}\)
\(\mathsf{H}\)
\(w_0\)
0
0
0
\(w_1\)
0
0
1
\(w_2\)
0
1
0
\(w_3\)
0
1
1
\(\xcancel{w_4}\)
\(\xcancel{1}\)
\(\xcancel{0}\)
\(\xcancel{0}\)
\(\xcancel{w_5}\)
\(\xcancel{1}\)
\(\xcancel{0}\)
\(\xcancel{1}\)
\(\boldsymbol{w_6}\)
1
1
0
\(\boldsymbol{w_7}\)
1
1
1
Figure 9:
Context for
(42)
, Facts in Bold, Laws Crossing out Worlds
On this model a context provides a set of worlds compatible with the facts, in \(C_2\) \(\textit{Facts}_{C_2}={\{w_6,w_7\}}\), and the set of worlds compatible with the laws, in \(C_2\) \(\textit{Universe}_{C_2}={\{w_0,w_1,w_2,w_3,w_6,w_7\}}\). This model of context is one essential component of the analysis, but so too is the way
Veltman (2005)
models worlds, situations, and dependencies between facts. These further components allow
Veltman (2005)
to offer a procedure for “retracting” the fact that \(\mathsf{R}\) holds from a world.
Veltman’s (
2005
) analysis of counterfactuals identifies possible worlds with atomic valuations (functions from atomic sentences to truth-values) like those depicted in
Figure  9
. So \(w_6={\{{\langle \mathsf{R},1\rangle},{\langle \mathsf{W},1\rangle},{\langle \mathsf{H},0\rangle}\}}\). This makes it possible to offer a simple model of
situations
, which are parts of worlds: any subset of a world.
[
38
]
It is now easy to think about one fact (sentence having a truth-value) as determining another fact (sentence having a truth value). In context \(C_3\), \(\mathsf{R}\) being 1 determines that \(\mathsf{W}\) will be 1. Once you know that \(\mathsf{R}\) is assigned to 1, you know that \(\mathsf{W}\) is too. Veltman’s (
2005
) proposal is that speakers evaluate a counterfactual by retracting the fact that the antecedent is false from the worlds in the context, which gives you some situations, and then consider all those worlds that contain those situations, are compatible with the laws, and make the antecedent true. If the consequent is true in all of those worlds, then we can say that the counterfactual is true in (or supported by) the context. So, to evaluate \(\neg \mathsf{R>W}\), one first retracts the fact that \(\mathsf{R}\) is true, i.e., that \(\mathsf{R}\) is assigned to 1, then one finds all the worlds consistent with the laws that contain those situations and assign \(\mathsf{R}\) to 0. If all of those worlds are also \(\mathsf{W}\) worlds, then the counterfactual is true in (or supported by) the context. For
Veltman (2005)
, the characterization of this retraction process relies essentially on the idea of facts determining other facts.
According to
Veltman (2005)
, when you are “retracting” a fact from the facts in the context, you begin by considering each \(w\in \textit{Facts}_C\) and find the smallest situations in
w
which contain only undetermined facts—he calls such a situation a
basis
for
w
. This is a minimal situation which, given the laws constraining \(\textit{Universe}_C\), determines all the other facts about that world. For example, \(w_6\) has only one basis, namely \(s_0={\{{\langle \mathsf{R},1\rangle},{\langle \mathsf{H},0\rangle}\}}\), and \(w_7\) has only one basis, namely \(s_1={\{{\langle \mathsf{R},1\rangle},{\langle \mathsf{H},1\rangle}\}}\). Once you have the bases for a world, you can retract a fact by finding the smallest change to the basis that no longer forces that fact to be true. So retracting the fact that \(\mathsf{R}\) is true from \(s_0\) produces \(s'_0={\{{\langle \mathsf{H},0\rangle}\}}\), and retracting it from \(s_1\) produces \(s'_1={\{{\langle \mathsf{H},1\rangle}\}}\). The set consisting of these two situations is the
premise set
.
To evaluate \(\mathsf{\neg R>W}\), one finds the set of worlds from \(\textit{Universe}_{C_3}\) that contains some member of the premise set \(s'_0\) or \(s'_1\): \({\{w_0,w_1,w_2,w_3\}}\)—these are the worlds consistent with the premise set and the laws. Are all of the \(\neg \mathsf{R}\)-worlds in \({\{w_0,w_1,w_2,w_3\}}\) also \(\mathsf{W}\)-worlds? No, \(w_2\) and \(w_3\) are not. Thus, \(\neg \mathsf{R>W}\) is not true in (or supported by) the context \(C_3\). This was the intuitively correct prediction about example
(42)
. Of course, the similarity analysis supplemented with
Lewis’ (1979) System of Weights
also makes this prediction. But consider again example
(43)
, which is not predicted:
(43)
[You’re invited to bet heads on a coin-toss. You decline. The coin comes up heads.] See, if you had bet heads you would have won!
(Slote 1978: 27 fn33)
This example relies seamlessly on three pieces of background knowledge about how betting works:
If you don’t bet, you don’t win: \(\mathsf{\medsquare(\neg B\supset\neg W)}\)
If you bet and it comes up heads, you win: \(\mathsf{\medsquare((B\land H)\supset W)}\)
If you bet and it doesn’t come up heads, you don’t win: \(\mathsf{\medsquare((B\land\neg H)\supset\neg W)}\)
And it specifies facts: \(\mathsf{\neg B\land H}\). The resulting context is detailed in
Figure  10
:
C
(43)
\(\mathsf{B}\)
\(\mathsf{H}\)
\(\mathsf{W}\)
\(w_0\)
0
0
0
\(\xcancel{w_1}\)
\(\xcancel{0}\)
\(\xcancel{0}\)
\(\xcancel{1}\)
\(\boldsymbol{w_2}\)
0
1
0
\(\xcancel{w_3}\)
\(\xcancel{0}\)
\(\xcancel{1}\)
\(\xcancel{1}\)
\(w_4\)
1
0
0
\(\xcancel{w_5}\)
\(\xcancel{1}\)
\(\xcancel{0}\)
\(\xcancel{1}\)
\(\xcancel{w_6}\)
\(\xcancel{1}\)
\(\xcancel{1}\)
\(\xcancel{0}\)
\(w_7\)
1
1
1
Figure 10:
Context for
(43)
Now, consider the counterfactual \(\mathsf{B>W}\). The first step is to retract the fact that \(\mathsf{B}\) is false from each world in \(\textit{Facts}_{C_{(43)}}\). That’s just \(w_2\). This world has two bases—minimal situations consisting of undetermined facts—\(s_0={\{{\langle \mathsf{B},0\rangle},{\langle \mathsf{H},1\rangle}\}}\) and \(s_1={\{{\langle \mathsf{H},1\rangle},{\langle \mathsf{W},0\rangle}\}}\).
[
39
]
The next step is to retract the fact that \(\mathsf{B}\) is false from both bases. For \(s_0\) this yields \(s'_0={\{{\langle \mathsf{H},1\rangle}\}}\) and for \(s_1\) this also yields \(s'_0\)—since the fact that you didn’t win together with the fact that the coin came up heads, forces it to be false that you bet. Given this situation, the premise set consists of the two worlds in
Universe
(43)
that contain \(s'_0\): \({\{w_2,w_7\}}\). Now, are all of the \(\mathsf{B}\)-worlds in this set also \(\mathsf{W}\)-worlds? Yes, \(w_7\) is the only \(\mathsf{B}\)-world, and it is also a \(\mathsf{W}\)-world. So
Veltman (2005)
correctly predicts that
(43)
is true in (supported by) its natural context.
It should now be more clear how premise semantics delivers on its promise to be more predictive than similarity semantics when it comes to counterfactuals in context, and affords a more natural characterization of how a context informs the interpretation of counterfactuals. This analysis was crucially based on the idea that some facts determine other facts, and that the process of retracting a fact is constrained by these relations. However, even premise semantics has encountered counterexamples.
Schulz (2007: 101)
poses the following counterexample to
Veltman (2005)
.
(45)
a.
If both Switch A and Switch B are up, the light is on.
\(\mathsf{\medsquare((A\land B)\supset L)}\)
b.
If either Switch A or Switch B is down, the light is off.
\(\mathsf{\medsquare((\neg A\lor\neg B)\supset \neg L)}\)
c.
Switch A is up, Switch B is down, and the light is off.
\(\mathsf{A\land\neg B\land\neg L}\)
d.
If Switch B had been up, the light would have been on.
\(\mathsf{B>L}\)
Intuitively,
(45d)
is true in the context.
Figure  11
details the context predicted for it by
Veltman (2005)
.
\(C_2\)
\(\mathsf{A}\)
\(\mathsf{B}\)
\(\mathsf{L}\)
\(w_0\)
0
0
0
\(\xcancel{w_1}\)
\(\xcancel{0}\)
\(\xcancel{0}\)
\(\xcancel{1}\)
\(w_2\)
0
1
0
\(\xcancel{w_3}\)
\(\xcancel{0}\)
\(\xcancel{1}\)
\(\xcancel{1}\)
\(\boldsymbol{w_4}\)
1
0
0
\(\xcancel{w_5}\)
\(\xcancel{1}\)
\(\xcancel{0}\)
\(\xcancel{1}\)
\(\xcancel{w_6}\)
\(\xcancel{1}\)
\(\xcancel{1}\)
\(\xcancel{0}\)
\(w_7\)
1
1
1
Figure 11:
Context for
(45d)
There are two bases for \(w_4\): \(s_0={\{{\langle \mathsf{A},1\rangle},{\langle \mathsf{L},0\rangle}\}}\)—the fact that Switch A is up and the light is off determines that Switch B is down—and \(s_1={\{{\langle \mathsf{A},1\rangle},{\langle \mathsf{B},0\rangle}\}}\)—the fact that Switch A is up and the fact that B is down determines that the light is off. (No smaller situation would determine the facts of \(w_4\).) Retracting \(\mathsf{B}\)’s falsity from \(s_0\) leads to trouble. \(s_0\) forces \(\mathsf{B}\) to be false, but there are two ways of changing this. First, one can remove the fact that the light is on, yielding \(s'_0={\{{\langle \mathsf{A},1\rangle}\}}\). Second, one can eliminate the fact that Switch A is up, yielding \(s''_0={\{{\langle \mathsf{L},0\rangle}\}}\). Because of \(s''_0\), the premise set will contain \(w_2\), meaning it allows that in retracting the fact that Switch B is down one can give up the fact that Switch A is up. But then there is a \(\mathsf{B}\)-world where \(\mathsf{L}\) is false, and \(\mathsf{B>L}\) is incorrectly predicted to be false.
Intuitively, the analysis went wrong in allowing the removal of the fact that Switch A is up when retracting the fact that Switch B is down.
Schulz (2007: §5.5)
provides a more sophisticated version of this diagnosis: although the fact that Switch A is up and the fact that the light is off together determine that Switch B is down, only the fact that the light is off depends on the fact that Switch B is down. If one could articulate this intuitive concept of dependence, and instead only retract facts that depend on the fact you are retracting (in this case the fact that B is down), then the error could be avoided. It is unclear how to implement this kind of dependence in Veltman’s (
2005
) framework.
Schulz (2007: §5.5)
goes on show that structural equations and causal models provide the necessary concept of dependence—for more on this approach see
§3.3
below. After all, it seems plausible that the light being off causally depends on Switch B being down, but Switch A being up does not causally depend on Switch B being down. It remains to be seen whether the more powerful framework developed by
Kratzer (1989, 2012)
can predict
(45)
.
3.2 Conditional Probability Analyses
While premise semantics has been prominent among linguists, probabilistic theories have been very prominent among philosophers thinking about knowledge and scientific explanation.
[
40
]
Adams (1965, 1975)
made a seminal proposal in this literature:
Adams’ Thesis
The assertability of
q if p
is proportional to \(P(q\mid p)\), where
P
is a probability function representing the agent’s subjective credences—see
Definition  1
.
However,
Adams (1970)
was also aware
that indicative/subjunctive pairs
like
(3)
/
(4)
differ in their assertability. To explain this, he proposed
the
prior probability
analysis of
counterfactuals
(Adams 1976)
:
Adams’ Prior Probability Analysis
The
assertability of \(\phi>\psi\) is proportional to
\(P_0(\psi\mid\phi)\), where \(P_0\) is the agent’s credence
prior to learning that \(\phi\) was false.
It would seem that this analysis accurately predicts our intuitions
in
(45)
about \(\mathsf{B>L}\). Let
\(P_0\) be an agent’s credence before learning that Switch B is
down.
(45a)
requires that
\(P_0(\mathsf{L}\mid \mathsf{A\land B})\) is (or is close to)
1,
(45b)
requires that \(P_0(\mathsf{\neg
L}\mid \mathsf{\neg A\lor \neg B})\) is (or is close to) 1. The agent
also learns that Switch A is up, so \(P_0(\mathsf{A})\) is (or is
close to) 1. All of this together seems to guarantee that
\(P_0(\mathsf{B\mid L})\) is also very high. However, this is due to
an inessential artifact of the example: the agent learned that Switch
B was down
after
learning that Switch A is up. This detail
does not matter to the intuition. As was seen with
example
(43)
, we often hold fixed facts that
happen after the antecedent turns out false. Indeed, Adams’
Prior Probability Analysis makes the incorrect prediction
that
(43)
is unassertible in its natural
context.
This problem for Adams’ Prior Probability Analysis is addressed in
Edgington (2003, 2004: 21)
who amends the analysis: \(P_0\) may also reflect any facts the agent learns after they learn that the antecedent is false, provides that those facts are causally independent of the antecedent. This parallels the idea pursued by
Schulz (2007: Ch.5)
to integrate causal dependence into the analysis of counterfactuals. This idea was also pursued in a probabilistic framework by
Kvart (1986, 1992)
.
Kvart (1986, 1992)
, however, does not propose a prior probability analysis and does not regard the probabilities as subjective credences: they are instead objective probabilities (propensity or objective chance).
Skyrms (1981)
also proposes a propensity account, but pursues a prior propensity account analogous to the subjective one proposed by
Adams (1976)
.
Objective probability analyses have been popular among philosophers trying to capture the way that counterfactuals feature in physical explanations, and why they are so useful to agents like us in worlds like ours.
Loewer (2007)
is a good example of such an account, who grounds the truth of certain counterfactuals regarding our decisions like
(46)
in statistical mechanical probabilities.
(46)
If I were to decide to bet on the coin’s landing heads, then the chance I would win is 0.5
Loewer (2007)
proposes that
(46)
is true just in case (where \(P_{\textit{SM}}\) is the statistical mechanical probability distribution and \(M(t)\) is a description of the macro-state of the universe at
t
):
(47)
\(P_{\textit{SM}}(W\mid M(t)\land D_1)=0.5\)
Loewer (2007)
acknowledges that this analysis is limited to counterfactuals like
(46)
. He argues that it can address the philosophical objections to the similarity analysis discussed in
§2.6
, namely why counterfactuals are useful in scientific explanations, and for agents like us in a world like our own.
Conditional probability analyses do not proceed by assigning
truth-conditions to (all) counterfactuals. They instead associate them
with certain conditional
probabilities.
[
41
]
This makes it difficult to integrate the
theory into a comprehensive compositional semantics and logic for a
natural language.
Kaufmann (2005 2008)
makes important advances here, but it remains an open issue for
conditional probability analyses.
Leitgeb
(2012a,b)
thoroughly develops a new conditional probability
analysis which regards \(\mathsf{\phi>\psi}\) as true when the
relevant conditional probability is sufficiently
high.
[
42
]
But
conditional probability analyses have other limitations. Without
further development, these analyses are limited in their ability to
explain how humans judge particular counterfactuals to be true. There
is a large literature in psychology, beginning
with
Kahneman, Slovic, and Tversky 1982
,
showing that human reasoning diverges in predictable way from precise
probabilistic reasoning. Even if these performance differences
didn’t turn up in counterfactuals and conditional probabilities,
there is an implementation issue. As discussed
in
§1.2.3
, directly implementing
probabilistic knowledge makes unreasonable demands on memory. Bayesian
Networks are one proposed solution to this implementation issue. They
are also used in the analysis of causal dependence
(
§1.3
), which conditional
probability analyses must appeal to anyway. Since Bayesian Networks
can also be used to directly formulate a semantics of counterfactuals,
they provide an worthwhile alternative to conditional probability
analyses despite proceeding from similar assumptions.
3.3 Bayesian Networks, Structural Equations, and Causal Models
Recall from
§1.2.3
the basic idea of a Bayesian Network: rather than storing probability values for all possible combinations of some set of variables, a Bayesian Network represents only the conditional probabilities of variables whose values depend on each other. This can be illustrated for
(45)
.
(45)
a.
If both Switch A and Switch B are up, the light is on.
\(\mathsf{\medsquare((A\land B)\supset L)}\)
b.
If either Switch A or Switch B is down, the light is off.
\(\mathsf{\medsquare((\neg A\lor\neg B)\supset \neg L)}\)
c.
Switch A is up, Switch B is down, and the light is off.
\(\mathsf{A\land\neg B\land\neg L}\)
d.
If Switch B had been up, the light would have been on.
\(\mathsf{B>L}\)
Sentences
(45a)
-
(45c)
can be encoded by the Bayesian Network and structural equations in
Figure  12
.
\[\begin{aligned} 
A = 1\\
B = 0\\
L = 0\\
\end{aligned}\]
Figure
12:
Bayesian Network and Structural Equations for
(45)
Recall that \(L\dequal A\land B\) means that the value of
L
equals the value of \(A\land B\), but also asymmetrically
depends on the value of \(A\land B\): the value of \(A\land B\)
determines the value of
L
, and not vice-versa. How, given the
network in
Figure 12
,
 does one evaluate the counterfactual \(\mathsf{B>N}\)? Several
different answers have been given to this question.
Pearl (1995, 2000, 2009, 2013: Ch.7)
proposes:
Interventionism
Evaluate \(\mathsf{B > L}\)
relative to a Bayesian Network by removing any incoming arrows to
B
, setting its value to 1, and projecting this change forward
through the remaining network. If
L
is 1 in the resulting
network, \(\mathsf{B > L}\) is true; otherwise it’s
false.
On this approach, one simply deletes the assignment \(B=0\), replaces
it with \(B=1\), and solves for
L
using the equation \(L\dequal
A\land B\). Since the deletion of \(B=0\) does not effect the
assignment \(A=1\), it follows that \(L=1\) and that the
counterfactual is true. This simple recipe yields the right result.
Pearl nicely sums up the difference between this kind of analysis and
a similarity analysis:
In contrast with Lewis’s theory, counterfactuals are not based
on an abstract notion of similarity among hypothetical worlds;
instead, they rest directly on the mechanisms (or “laws,”
to be fancy) that produce those worlds and on the invariant properties
of those mechanisms. Lewis’s elusive “miracles” are
replaced by principled [interventions] which represent the minimal
change (to a model) necessary for establishing the antecedent…
Thus, similarities and priorities—if they are ever
needed—may be read into the [interventions] as an
afterthought… but they are not basic to the analysis.
(Pearl
2009: 239–240)
As interventionism is stated above, it does not apply to conditionals
with logically complex antecedents or consequents. This limitation is
addressed by
Briggs (2012)
, who also
axiomatizes and compares the resultant logic to
D.
Lewis (1973b)
and
Stalnaker
(1968)
—significantly extending
the analysis and results in
Pearl (2009:
Ch.7)
. Integrations of causal models with premise semantics
(Schulz 2007, 2011; Kaufmann 2013; Santorio
2014; Champollion, Ciardelli, & Zhang 2016; Ciardelli, Zhang,
& Champollion forthcoming)
provide another way of
incorporating an interventionist analysis into a fully compositional
semantics. However, interventionism does face other limitations.
Hiddleston (2005)
presents the following
example.
(48)
a.
If the cannon is lit, there is a simultaneous flash and bang.
b.
The cannon was not lit, there was no flash, and no bang.
c.
But, if there had been a flash, there would have been a bang.
(48c)
is intuitively true in this context. The network for
(48)
is given in
Figure 13
.
\[\begin{aligned} 
L = 0\\
F = 0\\
B = 0\\
\end{aligned}\]
Figure 13:
Bayesian Network and
Structural Equations for
(48)
Hiddleston (2005)
observes that
interventionism does not predict \(\mathsf{F>B}\) to be true. It
tells one to delete the arrow going in to
F
, set its value to
1, and project the consequences of doing so. However, none of the
other values depend on
F
so they keep their actual values:
\(L=0\) and \(B=0\). Accordingly, \(\mathsf{F>B}\) is false,
contrary to intuition. Further, because the intervention on
F
has destroyed its connection to
B
, it’s not even possible
to tweak interventionism to allow values to flow backwards (to the
left) through the
 network.
[
43
]
Hiddleston’s (
2005
)
counterexample highlights the possibility of another kind of
counterexample featuring embedded conditionals. Consider again the
network in
Figure 12
.
 The following counterfactual seems true (
Starr
2012: 13
).
(49)
If the light had been on, then if you had flipped Switch A down, the light would be off.
And, considering a simple match,
Fisher (2017b:
§1)
observes that
(50b)
is intuitively false.
(50)
a.
A match is struck but does not light.
b.
If the match had lit, then (even) if it had not been struck, it would have lit.
In both cases, interventionism is destined to make the wrong
prediction. With
(49)
,
 the intervention in the first antecedent removes the connection
between Switch A and the light, so when the antecedent of the
consequent is made true by intervention, it does not result in
L
’s value becoming 0. And so the whole counterfactual
comes out false. Similarly with
(50b)
,
 when the first antecedent is made true by intervention, it stays true
even after the second antecedent is evaluated. Hence the whole
conditional is predicted to be true.
Fisher
(2017a)
also observes that interventionism also has no way of
treating counterlegal counterfactuals like
if Switch A had alone
controlled the light, the light would be on
.
These counterexamples to interventionism have stimulated alternative
accounts like Hiddleston’s (
2005
)
minimal network analysis
and further developments of that
analysis
(Rips 2010; Rips & Edwards 2013;
Fisher 2017b)
. Instead of modifying an existing network to make
the antecedent true, this analysis considers alternate networks where
only the parent nodes of the antecedent which directly influence it
are changed to make the antecedent come true. However, Pearl’s
(
2009
) interventionist analysis has also
been incorporated into the
extended structural models
analysis
(Lucas & Kemp 2015)
. This
analysis aims to capture interventions as a special case of a more
general proposal about how antecedents are made true. One important
aspect of this proposal is that interventions often involve inserting
a hidden node that amounts to an unknown cause of the antecedent. The
analysis of
Snider and Bjorndahl (2015)
pursues a third idea: counterfactuals are not interpreted by
manipulating a background network, but instead serve to constrain the
class of possible networks compatible with the information shared in a
conversation, as in Stalnaker’s (
1978
)
theory of
 assertion.
[
44
]
Among these relations can be cause-to-effect networks as in
(45d)
,
 but also networks that involve the antecedent and consequent having a
common cause, as in
(48c)
.
 As should be clear, this is a rapidly developing area of research
where it is not possible to identify one analysis as standard or
representative. It does bear emphasizing that this literature is
driven not only by precise formal models, but also by experimental
data which is brought to bear on the predictions of these
analyses.
A few final philosophical remarks are in order about the kinds of
analyses discussed here. If one follows
Woodward
(2002)
and
Hitchcock
(2001)
in their interpretation of
these networks, a structural equation should be viewed as a primitive
counterfactual. It follows that this is a non-reductive analysis of
counterfactual dependence: it only explains how the truth of
arbitrarily complex counterfactual sentences are grounded in basic
relations of counterfactual dependence. However, note in the earlier
quotation above from
Pearl (2009:
239–240)
that he interprets structural equations as basic
mechanisms or laws, and so arguably counts as an analysis of
counterfactuals in terms of laws. These amount to two very different
philosophical positions that interact with the philosophical debates
 surveyed in
§1.3
.
It is also worth noting that while many working in this framework
apply these networks to causal relations, there is no reason to assume
that the analysis would not apply to other kinds of dependence
relations. For example, constitutional dependence is at the heart of
counterfactuals like:
(51)
If Socrates hadn’t existed, the set consisting of Socrates wouldn’t have existed.
From a Bayesian Network approach to mental representation
 (
§1.2.3
),
 this makes perfect sense: the networks encode probabilistic
dependence which can come from causal or constitutional facts.
Finally, it is worth highlighting that the philosophical objections
directed at the similarity analysis in
§2.6
are addressed, at least to some degree, by structural equation
analyses. Because the central constructs of this
analysis—structural equations and Bayesian Networks—are
also employed in models of mental representation, causation, and
scientific explanation, it grounds counterfactuals in a construct
already taken to explain how creatures like us cope with a world like
the one we live in.
3.4 Summary
Premise semantics
 (
3.1
),
 conditional probability analyses
 (
§3.2
)
 and structural equation analyses
 (
§3.3
)
 all aim to analyze counterfactuals by focusing on certain relations
between facts, rather than similarities between worlds. These accounts
make clearer and more accurate predictions about particular
counterfactuals in context than similarity analyses. But, ultimately,
both premise semantics and conditional probability analyses had to
incorporate causal dependence into their theories. Structural equation
analyses do this from the start, and improve further on the
predictions of premise semantics and conditional probability analyses.
Another strength of this analysis is that it integrates elegantly into
the broader applications of counterfactuals in theories of
rationality, mental representation, causation, and scientific
explanation surveyed in
§1.1
.
 There is still rapid development of structural equation analyses,
though, so it is too early to say where the analysis will stabilize,
or how it will fair under thorough critical examination.
4. Conclusion
Philosophers, linguists, and psychologists remain fiercely divided on
how to best understand counterfactuals. Rightly so. They are at the
center of questions of deep human interest
 (
§1
).
 The renaissance on this topic in the 1970s and 1980s focused on
addressing certain semantic puzzles and capturing the logic of
counterfactuals
 (
§2
).
 From this seminal literature, similarity analyses
(D.
Lewis 1973b; Stalnaker 1968)
have enjoyed
the most widespread popularity in philosophy
 (
§2.3
).
 But the logical debate between similarity and strict analyses is
still raging, and strict analyses provide a viable logical alternative
 (
§2.4
).
 Criticisms of these logical analyses have focused recent debates on
our intuitions about particular utterances of counterfactuals in
particular contexts. Structural equation analyses
 (
§3.3
)
 have emerged as a particularly prominent alternative to similarity
and strict analyses, which claims to improve on both in significant
respects. These analyses are now being actively developed by
philosophers, linguists, psychologists, and computer scientists.
Bibliography
Adams, Ernest W., 1965, “The Logic of Conditionals”,
Inquiry
, 8: 166–197. doi:10.1080/00201746508601430
–––, 1970, “Subjunctive and Indicative
Conditionals”,
Foundations of Language
, 6(1):
89–94.
–––, 1975,
The Logic of Conditionals
,
Dordrecht: D. Reidel.
–––, 1976, “Prior Probabilities and
Counterfactual Conditionals”, in
Foundations of Probability
Theory, Statistical Inference, and Statistical Theories of
Science
, William L. Harper and Clifford Alan Hooker (eds.) (The
University of Western Ontario Series in Philosophy of Science),
Springer Netherlands, 6a:1–21.
doi:10.1007/978-94-010-1853-1_1
Alonso-Ovalle, Luis, 2009, “Counterfactuals, Correlatives,
and Disjunction”,
Linguistics and Philosophy
, 32(2):
207–244. doi:10.1177/0146167214563673
Alquist, Jessica L., Sarah E. Ainsworth, Roy F. Baumeister,
Michael Daly, and Tyler F. Stillman, 2015, “The Making of
Might-Have-Beens: Effects of Free Will Belief on Counterfactual
Thinking”,
Personality and Social Psychology Bulletin
,
41(2): 268–283. doi:10.1177/0146167214563673
Anderson, Alan Ross, 1951, “A Note on Subjunctive and
Counterfactual Conditionals”,
Analysis
, 12(2):
35–38. doi:10.2307/3327037
Arregui, Ana, 2007, “When Aspect Matters: The Case of
Would-Conditionals”,
Natural Language Semantics
, 15(3):
221–264. doi:10.1007/s11050-007-9019-6
–––, 2009, “On Similarity in
Counterfactuals”,
Linguistics and Philosophy
, 32(3):
245–278. doi:10.1007/s10988-009-9060-7
Barker, Stephen J., 1998, “Predetermination and Tense
Probabilism”,
Analysis
, 58(4): 290–296.
doi:10.1093/analys/58.4.290
Bennett, Jonathan, 1974, “Counterfactuals and Possible
Worlds”,
Canadian Journal of Philosophy
, 4(2):
381–402. doi:10.1080/00455091.1974.10716947
–––, 2003,
A Philosophical Guide to
Conditionals
, Oxford: Oxford University Press.
Bennett, Karen, 2017,
Making Things Up
, New York: Oxford
University Press.
Bittner, Maria, 2011, “Time and Modality without Tenses or
Modals”, in
Tense Across Languages
, Renate Musan and
Monika Rathers (eds.), Tübingen: Niemeyer, 147–188.
 [
Bittner 2011 available online
]
Bobzien, Susanne, 2011, “Dialectical School”, in
The Stanford Encyclopedia of Philosophy
, Edward N. Zalta
(ed.), Fall 2011, URL =
 <
http://plato.stanford.edu/archives/fall2011/entries/dialectical-school/
>
Bowie, G. Lee, 1979, “The Similarity Approach to
Counterfactuals: Some Problems”,
Noûs
, 13(4):
477–498. doi:10.2307/2215340
Brée, D.S., 1982, “Counterfactuals and
Causality”,
Journal of Semantics
, 1(2): 147–185.
doi:10.1093/jos/1.2.147
Briggs, R.A., 2012, “Interventionist Counterfactuals”,
Philosophical Studies
, 160(1): 139–166.
doi:10.1007/s11098-012-9908-5
Byrne, Ruth M. J., 2005,
The Rational Imagination: How People
Create Alternatives to Reality
, Cambridge, MA: MIT Press.
–––, 2016, “Counterfactual Thought”,
Annual Review of Psychology
, 67(1): 135–157.
doi:10.1146/annurev-psych-122414-033249
Carnap, Rudolf, 1948,
Introduction to Semantics
,
Cambridge, MA: Harvard University Press.
–––, 1956,
Meaning and Necessity
,
second edition, Chicago: Chicago University Press.
Champollion, Lucas, Ivano Ciardelli, and Linmin Zhang, 2016,
“Breaking de Morgan’s Law in Counterfactual
Antecedents”, in
Proceedings from Semantics and Linguistic
Theory (SALT) 26
, Mary Moroney, Carol-Rose Little, Jacob Collard,
and Dan Burgdorf (eds.), Ithaca, NY: CLC Publications, 304–324.
doi:10.3765/salt.v26i0.3800
Chater, Nick, Mike Oaksford, Ulrike Hahn, and Evan Heit, 2010,
“Bayesian Models of Cognition”,
Wiley
Interdisciplinary Reviews: Cognitive Science
, 1(6):
811–823. doi:10.1002/wcs.79
Chisholm, Roderick M., 1955, “Law Statements and
Counterfactual Inference”,
Analysis
, 15(5):
97–105. doi:10.1093/analys/15.5.97
Ciardelli, Ivano, Linmin Zhang, and Lucas Champollion,
forthcoming, “Two Switches in the Theory of
Counterfactuals”,
Linguistics and Philosophy
, first
online: 15 June 2018. doi:10.1007/s10988-018-9232-4
Cohen, Jonathan and Aaron Meskin, 2006, “An Objective
Counterfactual Theory of Information”,
Australasian Journal
of Philosophy
, 84(3): 333–352.
doi:10.1080/00048400600895821
Copeland, B. Jack, 2002, “The Genesis of Possible Worlds
Semantics”,
Journal of Philosophical Logic
, 31(2):
99–137. doi:10.1023/A:1015273407895
Costello, Tom and John McCarthy, 1999, “Useful
Counterfactuals”,
Linköping Electronic Articles in
Computer and Information Science
, 4(12): 1–24.
Cresswell, Max J. and G.E. Hughes, 1996,
A New Introduction to
Modal Logic
, London: Routledge.
Daniels, Charles B. and James B. Freeman, 1980, “An Analysis
of the Subjunctive Conditional”,
Notre Dame Journal of
Formal Logic
, 21(4): 639–655.
doi:10.1305/ndjfl/1093883247
Declerck, Renaat and Susan Reed, 2001,
Conditionals: A
Comprehensive Emprical Analysis
, (Topics in English Linguistics,
37), New York: De Gruyter Mouton.
Dretske, Fred I., 1981,
Knowledge and the Flow of
Information
, Cambridge, MA: The MIT Press.
–––, 1988,
Explaining Behavior: Reasons in a
World of Causes
, Cambridge, MA: MIT Press.
–––, 2002, “A Recipe for Thought”,
in
Philosophy of Mind: Contemporary and Classical Readings
,
David J. Chalmers (ed.), New York: Oxford University Press,
491–499.
–––, 2011, “Information-Theoretic
Semantics”, in
The Oxford Handbook of Philosophy of
Mind
, Brian McLaughlin, Angsar Beckermann, and Sven Walter
(eds.), New York: Oxford University Press, 381–393.
Dudman, Victor Howard, 1984a, “Conditional Interpretations
of ‘If’ Sentences”,
Australian Journal of
Linguistics
, 4(2): 143–204.
doi:10.1080/07268608408599325
–––, 1984b, “Parsing
‘If’-Sentences”,
Analysis
, 44(4):
145–153. doi:10.1093/analys/44.4.145
–––, 1988, “Indicative and
Subjunctive”,
Analysis
, 48(3): 113–122.
doi:10.1093/analys/48.3.113a
Edgington, Dorothy, 2003, “What If? Questions About
Conditionals”,
Mind & Language
, 18(4):
380–401. doi:10.1111/1468-0017.00233
–––, 2004, “Counterfactuals and the
Benefit of Hindsight”, in
Cause and Chance: Causation in an
Indeterministic World
, Phil Dowe & Paul Noordhof (ed.), New
York: Routledge, 12–27.
Fine, Kit, 1975, “Review of Lewis’
Counterfactuals”,
Mind
, 84: 451–458.
doi:10.1093/mind/LXXXIV.1.451
–––, 2012a, “Counterfactuals Without
Possible Worlds”,
Journal of Philosophy
, 109(3):
221–246. doi:10.5840/jphil201210938
–––, 2012b, “A Difficulty for the Possible
Worlds Analysis of Counterfactuals”,
Synthese
, 189(1):
29–57. doi:10.1007/s11229-012-0094-y
Fintel, Kai von, 1999, “The Presupposition of Subjunctive
Conditionals”, in
The Interpretive Tract
, Uli Sauerland
and Orin Percus (eds.), Cambridge, MA: MITWPL, MIT Working Papers in
Linguistics 25: 29–44.
 [
Fintel 1999 available online
]
–––, 2001, “Counterfactuals in a Dynamic
Context”, in
Ken Hale, A Life in Language
, Michael
Kenstowicz (ed.), Cambridge, MA: The MIT Press, 123–152.
 [
Fintel 2001 available online
]
–––, 2012, “Subjunctive
Conditionals”, in
The Routledge Companion to Philosophy of
Language
, Gillian Russell and Delia Graff Fara (eds.), New York:
Routledge, 466–477.
 [
Fintel 2012 available online
]
Fintel, Kai von and Sabine Iatridou, 2002, “If and When
If
-Clauses Can Restrict Quantifiers”, Paper for the
Workshop in Philosophy and Linguistics, University of Michigan,
November 8–10, 2002.
 [
Fintel & Iatridou 2002 available online
]
Fisher, Tyrus, 2017a, “Causal Counterfactuals Are Not
Interventionist Counterfactuals”,
Synthese
, 194(12):
4935–4957. doi:10.1007/s11229-016-1183-0
–––, 2017b, “Counterlegal Dependence and
Causation’s Arrows: Causal Models for Backtrackers and
Counterlegals”,
Synthese
, 194(12): 4983–5003.
doi:10.1007/s11229-016-1189-7
Fodor, Jerry A., 1987,
Psychosemantics: The Problem of Meaning
in the Philosophy of Mind
, Cambridge, MA: The MIT Press.
–––, (ed.), 1990,
A Theory of Content and
Other Essays
, Cambridge, MA: The MIT Press.
Fraassen, Bas C. Van, 1966, “Singular Terms, Truth-Value
Gaps and Free Logic”, Journal of Philosophy, 3: 481–495.
doi:10.2307/2024549
Frege, Gottlob, 1893,
Grundgesetze Der Arithmetik
,
Begriffsschriftlich Abgeleitet, Vol. 1, 1st ed, Jena: H. Pohle.
Galinsky, Adam D., Katie A. Liljenquist, Laura J. Kray, and Neil
J. Roes, 2005, “Finding Meaning from Mutability: Making Sense
and Deriving Significance through Counterfactual Thinking”, in
The Psychology of Counterfactual Thinking
, David R. Mandel,
Denis J. Hilton, and Patrizia Catellani (eds), New York: Routledge,
110–127.
Gamut, L.T.F., 1991,
Logic, Language and Meaning: Intensional
Logic and Logical Grammar
, Vol. 2, Chicago: The University of
Chicago Press.
Gärdenfors, Peter, 1978, “Conditionals and Changes of
Belief”, in
The Logic and Epistemology of Scientific
Belief
, Ilkka Niiniluoto and Raimo Tuomela (eds.), Amsterdam:
North-Holland.
–––, 1982, “Imaging and
Conditionalization”,
Journal of Philosophy
, 79(12):
747–760. doi:10.2307/2026039
Gibbard, Allan F., 1980, “Two Recent Theories of
Conditionals”, in Harper, Stalnaker, and Pearce 1980:
211–247. doi:10.1007/978-94-009-9117-0_10
Gibbard, Allan F. and William L. Harper, 1978,
“Counterfactuals and Two Kinds of Expected Utility”, in
Foundations and Applications of Decision Theory
, Clifford
Hooker, James J. Leach, and Edward McClennen (eds.), Dordrecht: D.
Reidel, 125–162. doi:10.1007/978-94-009-9789-9_5
Gillies, Anthony, 2007, “Counterfactual Scorekeeping”,
Linguistics and Philosophy
, 30(3): 329–360.
doi:10.1007/s10988-007-9018-6
–––, 2012, “Indicative
Conditionals”, in
The Routledge Companion to Philosophy of
Language
, Gillian Russell and Delia Graff Fara (eds.), New York:
Routledge, 449–465.
Ginsburg, Matthew L., 1985, “Counterfactuals”, in
Proceedings of the Ninth International Joint Conference on
Artificial Intelligence
, Aravind Joshi (ed.), Los Altos, CA:
Morgan Kaufmann, 80–86.
 [
Ginsburg 1985 available online
]
Glymour, Clark, 2001,
The Mind’s Arrows: Bayes Nets and
Graphical Causal Models in Psychology
, Cambridge, MA: MIT
Press.
Goodman, Nelson, 1947, “The Problem of Counterfactual
Conditionals”,
The Journal of Philosophy
, 44(5):
113–118. doi:10.2307/2019988
–––, 1954,
Fact, Fiction and Forecast
,
Cambridge, MA: Harvard University Press.
Gopnik, Alison, Clark Glymour, David M. Sobel, Laura E. Schulz,
Tamar Kushnir, and David Danks, 2004, “A Theory of Causal
Learning in Children: Causal Maps and Bayes Nets”, Psychological
Review, 111(1): 3–32. doi:10.1037/0033-295X.111.1.3
Gopnik, Alison and Joshua B. Tenenbaum, 2007, “Bayesian
Networks, Bayesian Learning and Cognitive Development”,
Developmental Science, 10(3): 281–287.
doi:10.1111/j.1467-7687.2007.00584.x
Hájek, Alan, 2014, “Probabilities of Counterfactuals
and Counterfactual Probabilities”,
Journal of Applied
Logic
, 12(3): 235–251. doi:10.1016/j.jal.2013.11.001
Halpern, Joseph and Judea Pearl, 2005a, “Causes and
Explanations: A Structural-Model Approach. Part I: Causes”,
British Journal for Philosophy of Science
, 56(4):
843–887. doi:10.1093/bjps/axi147
–––, 2005b, “Causes and Explanations: A
Structural-Model Approach. Part II: Explanations”,
British
Journal for Philosophy of Science
, 56(4): 889–911.
doi:10.1093/bjps/axi148
Hansson, Sven Ove, 1989, “New Operators for Theory
Change”,
Theoria
, 55(2): 114–132.
doi:10.1111/j.1755-2567.1989.tb00725.x
Harper, William L., 1975, “Rational Belief Change, Popper
Functions and the Counterfactuals”,
Synthese
,
30(1–2): 221–262. doi:10.1007/BF00485309
Harper, William L., Robert Stalnaker, and Glenn Pearce (eds.),
1980,
Ifs: Conditionals, Belief, Decision, Chance and Time
,
Dordrecht: Springer Netherlands. doi:10.1007/978-94-009-9117-0
Hawthorne, John, 2005, “Chance and Counterfactuals”,
Philosophy and Phenomenological Research
, 70(2):
396–405. doi:10.1111/j.1933-1592.2005.tb00534.x
Heintzelman, Samantha J., Justin Christopher, Jason Trent, and
Laura A. King, 2013, “Counterfactual Thinking about One’s
Birth Enhances Well-Being Judgments”,
The Journal of
Positive Psychology
, 8(1): 44–49.
doi:10.1080/17439760.2012.754925
Herzberger, Hans, 1979, “Counterfactuals and
Consistency”,
The Journal of Philosophy
, 76(2):
83–88. doi:10.2307/2025977
Hiddleston, Eric, 2005, “A Causal Theory of
Counterfactuals”,
Noûs
, 39(4): 632–657.
doi:10.1111/j.0029-4624.2005.00542.x
Hitchcock, Christopher, 2001, “The Intransitivity of
Causation Revealed by Equations and Graphs”,
The Journal of
Philosophy
, 98(6): 273–299. doi:10.2307/2678432
–––, 2007, “Prevention, Preemption, and
the Principle of Sufficient Reason”,
Philosophical
Review
, 116(4): 495–532. doi:10.1215/00318108-2007-012
Horwich, Paul, 1987,
Asymmetries in Time
, Cambridge, MA:
MIT Press.
Iatridou, Sabine, 2000, “The Grammatical Ingredients of
Counterfactuality”,
Linguistic Inquiry
, 31(2):
231–270. doi:10.1162/002438900554352
Ichikawa, Jonathan, 2011, “Quantifiers, Knowledge, and
Counterfactuals”,
Philosophy and Phenomenological
Research
, 82(2): 287–313.
doi:10.1111/j.1933-1592.2010.00427.x
Ippolito, Michela, 2006, “Semantic Composition and
Presupposition Projection in Subjunctive Conditionals”,
Linguistics and Philosophy
, 29(6): 631–672.
doi:10.1007/s10988-006-9006-2
–––, 2008, “Subjunctive
Conditionals”, in
Proceedings of Sinn Und Bedeutung 12
,
Atle Grønn (ed.), Oslo: Department of Literature, Area Studies
and European Languages, University of Oslo, 256–270.
–––, 2013,
Subjunctive Conditionals: A
Linguistic Analysis
, (Linguistic Inquiry Monograph Series 65),
Cambridge, MA: MIT Press.
–––, 2016, “How Similar Is Similar
Enough?”,
Semantics and Pragmatics
, 9(6): 1–60.
doi:10.3765/sp.9.6
Isard, S.D., 1974, “What Would You Have Done
If…”,
Theoretical Linguistics
, 1(1–3):
233–255. doi:10.1515/thli.1974.1.1-3.233
Jackson, Frank, 1987,
Conditionals
, Oxford: Basil
Blackwell.
Kahneman, Daniel, Paul Slovic, and Amos Tversky (eds.), 1982,
Judgement under Uncertainty: Heuristics and Biases
,
Cambridge: Cambridge University Press.
Kant, Immanuel, 1781,
Critique of Pure Reason
, Paul Guyer
and Allen Wood (trans.), Cambridge: Cambridge University Press,
1998.
Kaufmann, Stefan, 2005, “Conditional Predictions”,
Linguistics and Philosophy
, 28(2): 181–231.
doi:10.1007/s10988-005-3731-9
–––, 2008, “Conditionals Right and Left:
Probabilities for the Whole Family”,
Journal of
Philosophical Logic
, 38(1): 1–53.
doi:10.1007/s10992-008-9088-0
–––, 2013, “Causal Premise
Semantics”,
Cognitive Science
, 37(6): 1136–1170.
doi:10.1111/cogs.12063
–––, 2017, “The Limit Assumption”,
Semantics and Pragmatics
, 10(18). doi:10.3765/sp.10.18
Khoo, Justin, 2015, “On Indicative and Subjunctive
Conditionals”,
Philosophers’ Imprint
, 15(32):
1–40.
 [
Khoo 2015 available online
]
Kment, Boris, 2006, “Counterfactuals and Explanation”,
Mind
, 115(458): 261–310. doi:10.1093/mind/fzl261
–––, 2014,
Modality and Explanatory
Reasoning
, New York: Oxford University Press.
doi:10.1093/acprof:oso/9780199604685.001.0001
Koslicki, Kathrin, 2016, “Where Grounding and Causation Part
Ways: Comments on Schaffer”,
Philosophical Studies
,
173(1): 101–112. doi:10.1007/s11098-014-0436-3
Kratzer, Angelika, 1981a, “The Notional Category of
Modality”, in
Words, Worlds and Contexts
,
Hans-Jürgen Eikmeyer and Hannes Rieser (eds.), Berlin: Walter de
Gruyter, 38–74.
–––, 1981b, “Partition and Revision: The
Semantics of Counterfactuals”,
Journal of Philosophical
Logic
, 10(2): 201–216. doi:10.1007/BF00248849
–––, 1986, “Conditionals”, in
Proceedings from the 22nd Regional Meeting of the Chicago
Linguistic Society
, Chicago: University of Chicago, 1–15.
 [
Kratzer 1986 available online
]
–––, 1989, “An Investigation of the Lumps
of Thought”,
Linguistics and Philosophy
, 12(5):
607–653. doi:10.1007/BF00627775
–––, 1990, “How Specific Is a
Fact?”, in
Proceedings of the 1990 Conference on Theories of
Partial In- Formation
, Center for Cognitive Science, University
of Texas at Austin.
–––, 1991, “Modality”, in
Semantics: An International Handbook of Contemporary
Research
, A. von Stechow and D. Wunderlich (eds.), Berlin: De
Gruyter Mouton, 639–650.
–––, 2002, “Facts: Particulars or
Information Units?”,
Linguistics and Philosophy
,
25(5–6): 655–670. doi:10.1023/A:1020807615085
–––, 2012,
Modals and Conditionals: New and
Revised Perspectives
, New York: Oxford University Press.
doi:10.1093/acprof:oso/9780199234684.001.0001
Kray, Laura J., Linda G. George, Katie A. Liljenquist, Adam D.
Galinsky, Philip E. Tetlock, and Neal J. Roese, 2010, “From What
Might Have Been to What Must Have Been: Counterfactual Thinking
Creates Meaning”,
Journal of Personality and Social
Psychology
, 98(1): 106–118. doi:10.1037/a0017905
Kripke, Saul A., 1963, “Semantical Analysis of Modal Logic
I: Normal Modal Propositional Calculi”,
Zeitschrift Für
Mathematische Logik Und Grundlagen Der Mathematik
, 9(5–6):
67–96. doi:10.1002/malq.19630090502
Kvart, Igal, 1986,
A Theory of Counterfactuals
,
Indianapolis, IN: Hackett.
–––, 1992, “Counterfactuals”,
Erkenntnis
, 36(2): 139–179. doi:10.1007/BF00217472
Lange, Marc, 1999, “Laws, Counterfactuals, Stability, and
Degrees of Lawhood”,
Philosophy of Science
, 66(2):
243–267. doi:10.1086/392686
–––, 2000,
Natural Laws in Scientific
Practice
, New York: Oxford University Press.
–––, 2009,
Laws and Lawmakers: Science,
Metaphysics, and the Laws of Nature
, Oxford: Oxford University
Press. doi:10.1093/acprof:oso/9780195328134.001.0001
Leitgeb, Hannes, 2012a, “A Probabilistic Semantics for
Counterfactuals: Part A”,
The Review of Symbolic Logic
,
5(1): 26–84. doi:10.1017/S1755020311000153
–––, 2012b, “A Probabilistic Semantics for
Counterfactuals: Part B”,
The Review of Symbolic Logic
,
5(1): 85–121. doi:10.1017/S1755020311000165
Levi, Isaac, 1988, “The Iteration of Conditionals and the
Ramsey Test”,
Synthese
, 76(1): 49–81.
doi:10.1007/BF00869641
Lewis, C. I., 1912, “Implication and the Algebra of
Logic”,
Mind
, New Series, 21(84): 522–531.
doi:10.1093/mind/XXI.84.522
–––, 1914, “The Calculus of Strict
Implication”,
Mind
, New Series, 23(90): 240–247.
doi:10.1093/mind/XXIII.1.240
Lewis, David K., 1973a, “Causation”,
Journal of
Philosophy
, 70(17): 556–567. doi:10.2307/2025310
–––, 1973b,
Counterfactuals
, Cambridge,
MA: Harvard University Press.
–––, 1973c, “Counterfactuals and
Comparative Possibility”,
Journal of Philosophical
Logic
, 2(4): 418–446. doi:10.2307/2215339
–––, 1979, “Counterfactual Dependence and
Time’s Arrow”,
Noûs
, 13(4): 455–476.
doi:10.2307/2215339
–––, 1981, “Ordering Semantics and Premise
Semantics for Counterfactuals”,
Journal of Philosophical
Logic
, 10(2): 217–234. doi:10.1007/BF00248850
Lewis, Karen S., 2016, “Elusive Counterfactuals”,
Noûs
, 50(2): 286–313. doi:10.1111/nous.12085
–––, 2017, “Counterfactuals and
Knowledge”, in
The Routledge Handbook of Epistemic
Contextualism
, Jonathan Jenkins Ichikawa (ed.), New York:
Routledge, 411–424.
–––, 2018, “Counterfactual Discourse in
Context”,
Noûs
, 52(3): 481–507.
doi:10.1111/nous.12194
Loewer, Barry, 1976, “Counterfactuals with Disjunctive
Antecedents”,
The Journal of Philosophy
, 73(16):
531–537. doi:10.2307/2025717
–––, 1983, “Information and Belief”,
Behavioral and Brain Sciences
, 6(1): 75–76.
doi:10.1017/S0140525X00014783
–––, 2007, “Counterfactuals and the Second
Law”, in
Causation, Physics, and the Constitution of
Reality: Russell’s Republic Revisited
, Huw Price and
Richard Corry (eds.), New York: Oxford University Press,
293–326.
Lowe, E. J., 1983, “A Simplification of the Logic of
Conditionals”,
Notre Dame Journal of Formal Logic
,
24(3): 357–366. doi:10.1305/ndjfl/1093870380
–––, 1990, “Conditionals, Context, and
Transitivity”,
Analysis
, 50(2): 80–87.
doi:10.1093/analys/50.2.80
Lucas, Christopher G. and Charles Kemp, 2015, “An Improved
Probabilistic Account of Counterfactual Reasoning”,
Psychological Review, 122(4): 700–734. doi:10.1037/a0039655
Lycan, William G., 2001,
Real Conditionals
, Oxford:
Oxford University Press.
Lyons, John, 1977,
Semantics
, Vol. 2, Cambridge:
Cambridge University Press. doi:10.1017/CBO9780511620614
Mackie, John L., 1974,
The Cement of the Universe: A Study in
Causation
, Oxford: Oxford University Press.
Marr, David, 1982,
Vision: A Computational Investigation into
the Human Representation and Processing of Visual Information
,
San Francisco: W.H. Freeman.
Maudlin, Tim, 2007,
Metaphysics Within Physics
, New York:
Oxford University Press.
doi:10.1093/acprof:oso/9780199218219.001.0001
McKay, Thomas J. and Peter van Inwagen, 1977,
“Counterfactuals with Disjunctive Antecedents”,
Philosophical Studies
, 31(5): 353–356.
doi:10.1007/BF01873862
Morreau, Michael, 2009, “The Hypothetical Syllogism”,
Journal of Philosophical Logic
, 38(4): 447–464.
doi:10.1007/s10992-008-9098-y
–––, 2010, “It Simply Does Not Add Up:
Trouble with Overall Similarity”,
The Journal of
Philosophy
, 107(9): 469–490.
doi:10.5840/jphil2010107931
Moss, Sarah, 2012, “On the Pragmatics of
Counterfactuals”,
Noûs
, 46(3): 561–586.
doi:10.1111/j.1468-0068.2010.00798.x
Nelson, Everett J., 1933, “On Three Logical Principles in
Intension”,
The Monist
, 43(2): 268–284.
doi:10.5840/monist19334327
Nozick, Robert, 1969, “Newcomb’s Problem and Two
Principles of Choice”, in
Essays in Honor of Carl G.
Hempel
, Nicholas Rescher (ed.), Dordrecht: D. Reidel,
111–5.
Nute, Donald, 1975a, “Counterfactuals”,
Notre Dame
Journal of Formal Logic
, 16(4): 476–482.
doi:10.1305/ndjfl/1093891882
–––, 1975b, “Counterfactuals and the
Similarity of Words”,
The Journal of Philosophy
,
72(21): 773–778. doi:10.2307/2025340
–––, 1980a, “Conversational Scorekeeping
and Conditionals”,
Journal of Philosophical Logic
,
9(2): 153–166. doi:10.1007/BF00247746
–––, (ed.), 1980b,
Topics in Conditional
Logic
, Dordrecht: Reidel. doi:10.1007/978-94-009-8966-5
Palmer, Frank Robert, 1986,
Mood and Modality
, Cambridge:
Cambridge University Press.
Parisien, Christopher and Paul Thagard, 2008,
“Robosemantics: How Stanley the Volkswagen Represents the
World”,
Minds and Machines
, 18(2): 169–178.
doi:10.1007/s11023-008-9098-2
Pearl, Judea, 1995, “Causation, Action, and
Counterfactuals”, in
Computational Learning and
Probabilistic Reasoning
, A. Gammerman (ed.), New York: John Wiley
and Sons, 235–255.
–––, 2000,
Causality: Models, Reasoning, and
Inference
, Cambridge: Cambridge University Press.
–––, 2002, “Reasoning with Cause and
Effect”,
AI Magazine
, 23(1): 95–112.
 [
Pearl 2002 available online
]
–––, 2009,
Causality: Models, Reasoning, and
Inference
, second edition, Cambridge: Cambridge University
Press.
–––, 2013, “Structural Counterfactuals: A
Brief Introduction”,
Cognitive Science
, 37(6):
977–985. doi:10.1111/cogs.12065
Peirce, Charles S., 1896, “The Regenerated Logic”,
The Monist
, 7(1): 19–40.
doi:10.5840/monist18967121
Pendlebury, Michael, 1989, “The Projection Strategy and the
Truth: Conditions of Conditional Statements”,
Mind
,
98(390): 179–205. doi:10.1093/mind/XCVIII.390.179
Pereboom, Derk, 2014,
Free Will, Agency, and Meaning in
Life
, New York: Oxford University Press.
doi:10.1093/acprof:oso/9780199685516.001.0001
Pollock, John L., 1976,
Subjunctive Reasoning
, Dordrecht:
D. Reidel Publishing Co., doi:10.1007/978-94-010-1500-4
–––, 1981, “A Refined Theory of
Counterfactuals”,
Journal of Philosophical Logic
,
10(2): 239–266. doi:10.1007/BF00248852
Quine, Willard Van Orman, 1960,
Word and Object
,
Cambridge, MA: MIT Press.
–––, 1982,
Methods of Logic
, fourth
edition, Cambridge, MA: Harvard University Press.
Rips, Lance J., 2010, “Two Causal Theories of Counterfactual
Conditionals”,
Cognitive Science
, 34(2): 175–221.
doi:10.1111/j.1551-6709.2009.01080.x
Rips, Lance J. and Brian J. Edwards, 2013, “Inference and
Explanation in Counterfactual Reasoning”,
Cognitive
Science
, 37(6): 1107–1135. doi:10.1111/cogs.12024
Ryle, Gilbert, 1949,
The Concept of Mind
, London:
Hutchinson.
Sanford, David H., 1989,
If P Then Q: Conditionals and the
Foundations of Reasoning
, London: Routledge.
Santorio, Paolo, 2014, “Filtering Semantics for
Counterfactuals: Bridging Causal Models and Premise Semantics”,
in the
Proceedings of Semantics and Linguistic Theory (SALT)
24
, 494–513.
Schaffer, Jonathan, 2016, “Grounding in the Image of
Causation”,
Philosophical Studies
, 173(1):
49–100. doi:10.1007/s11098-014-0438-1
Schulz, Katrin, 2007, “Minimal Models in Semantics and
Pragmatics: Free Choice, Exhaustivity, and Conditionals”, PhD
Thesis, Amsterdam: University of Amsterdam: Institute for Logic,
Language and Computation.
 [
Schultz 2007 available online
]
–––, 2011, “If You’d Wiggled A, Then
B Would’ve Changed”,
Synthese
, 179(2):
239–251. doi:10.1007/s11229-010-9780-9
–––, 2014, “Fake Tense in Conditional
Sentences: A Modal Approach”,
Natural Language
Semantics
, 22(2): 117–144.
doi:10.1007/s11050-013-9102-0
Seto, Elizabeth, Joshua A. Hicks, William E. Davis, and Rachel
Smallman, 2015, “Free Will, Counterfactual Reflection, and the
Meaningfulness of Life Events”,
Social Psychological and
Personality Science
, 6(3): 243–250.
doi:10.1177/1948550614559603
Sider, Theodore, 2010,
Logic for Philosophy
, New York:
Oxford University Press.
Skyrms, Brian, 1980, “The Prior Propensity Account of
Subjunctive Conditionals”, in Harper, Stalnaker, and Pearce
1980: 259–265. doi:10.1007/978-94-009-9117-0_13
Sloman, Steven, 2005,
Causal Models: How People Think About
the World and Its Alternatives
, New York: Oxford University
Press. doi:10.1093/acprof:oso/9780195183115.001.0001
Sloman, Steven A. and David A. Lagnado, 2005, “Do We
‘Do’?”,
Cognitive Science
, 29(1):
5–39. doi:10.1207/s15516709cog2901_2
Slote, Michael, 1978, “Time in Counterfactuals”,
Philosophical Review
, 87(1): 3–27.
doi:10.2307/2184345
Smilansky, Saul, 2000,
Free Will and Illusion
, New York:
Oxford University Press.
Snider, Todd and Adam Bjorndahl, 2015, “Informative
Counterfactuals”,
Semantics and Linguistic Theory
, 25:
1–17. doi:10.3765/salt.v25i0.3077
Spirtes, Peter, Clark Glymour, and Richard Scheines, 1993,
Causation, Prediction, and Search
, Berlin:
Springer-Verlag.
–––, 2000,
Causation, Prediction, and
Search
, second edition, Cambridge, MA: The MIT Press.
Sprigge, Timothy L.S., 1970,
Facts, Worlds and Beliefs
,
London: Routledge & K. Paul.
–––, 2006, “My Philosophy and Some Defence
of It”, in
Consciousness, Reality and Value: Essays in
Honour of T. L. S. Sprigge
, Pierfrancesco Basile and Leemon B.
McHenry (eds.), Heusenstamm: Ontos Verlag, 299–321.
Stalnaker, Robert C., 1968, “A Theory of
Conditionals”, in
Studies in Logical Theory
, Nicholas
Rescher (ed.), Oxford: Basil Blackwell, 98–112.
–––, 1972 [1980], “Letter to David
Lewis”. Reprinted in Harper, Stalnaker, and Pearce 1980:
151–152. doi:10.1007/978-94-009-9117-0_7
–––, 1975, “Indicative
Conditionals”,
Philosophia
, 5(3): 269–286.
doi:10.1007/BF02379021
–––, 1978, “Assertion”, in
Syntax and Semantics 9: Pragmatics
, Peter Cole (ed.), New
York: Academic Press, 315–332.
–––, 1980, “A Defense of Conditional
Excluded Middle”, in Harper, Stalnaker, and Pearce 1980:
87–104. doi:10.1007/978-94-009-9117-0_4
–––, 1984,
Inquiry
, Cambridge, MA: MIT
Press.
–––, 1999,
Context and Content: Essays on
Intentionality in Speech and Thought
, Oxford: Oxford University
Press.
Stalnaker, Robert C. and Richmond H. Thomason, 1970, “A
Semantic Analysis of Conditional Logic”,
Theoria
,
36(1): 23–42. doi:10.1111/j.1755-2567.1970.tb00408.x
Starr, William B., 2012,
The Structure of Possible
Worlds
, UCLA Workshop.
 [
Starr 2012 available online
]
–––, 2014, “A Uniform Theory of
Conditionals”,
Journal of Philosophical Logic
, 43(6):
1019–1064. doi:10.1007/s10992-013-9300-8
Stone, Matthew, 1997, “The Anaphoric Parallel between
Modality and Tense”. Philadelphia, PA: University of
Pennsylvania Institute for Research in Cognitive Science, Technical
Report No. MS-CIS-97-06.
 [
Stone 1997 available online
]
Swanson, Eric, 2012, “Conditional Excluded Middle without
the Limit Assumption”,
Philosophy and Phenomenological
Research
, 85(2): 301–321.
doi:10.1111/j.1933-1592.2011.00507.x
Tadeschi, Philip, 1981, “Some Evidence for a
Branching-Futures Semantic Model”, in
Tense and Aspect
,
(Syntax and Semantics, 14), Philip Tedeschi and Annie Zaenen (eds.),
New York: Academic Press, 239–269.
Tarski, Alfred, 1936, “Der Wahrheitsbegriff in Den
Formalizierten Sprachen”,
Studia Philosophica
, 1:
261–405.
Thrun, Sebastian, Mike Montemerlo, Hendrik Dahlkamp, David
Stavens, Andrei Aron, James Diebel, Philip Fong, et al., 2006,
“Stanley: The Robot That Won the DARPA Grand Challenge”,
Journal of Field Robotics
, 23(9): 661–692.
doi:10.1002/rob.20147
Tichý, Pavel, 1976, “A Counterexample to the
Stalnaker-Lewis Analysis of Counterfactuals”,
Philosophical
Studies
, 29(4): 271–273. doi:10.1007/BF00411887
Todd, William, 1964, “Counterfactual Conditionals and the
Presuppositions of Induction”,
Philosophy of Science
,
31(2): 101–110. doi:10.1086/287987
Veltman, Frank, 1976, “Prejudices, Presuppositions and the
Theory of Counterfactuals”, in
Amsterdam Papers in Formal
Grammar
, J. Groenendijck and M. Stokhof (eds.) (Proceedings of
the 1st Amsterdam Colloquium), University of Amsterdam,
248–281.
–––, 1985, “Logics for
Conditionals”, Ph.D. Dissertation, Amsterdam: University of
Amsterdam.
–––, 1986, “Data Semantics and the
Pragmatics of Indicative Conditionals”, in
On
Conditionals
, Elizabeth C. Traugott, Alice ter Meulen, Judy S.
Reilly, and Charles A. Ferguson (eds.), Cambridge: Cambridge
University Press.
–––, 2005, “Making Counterfactual
Assumptions”,
Journal of Semantics
, 22(2):
159–180. doi:10.1093/jos/ffh022
Walters, Lee, 2014, “Against Hypothetical Syllogism”,
Journal of Philosophical Logic
, 43(5): 979–997.
doi:10.1007/s10992-013-9305-3
Walters, Lee and J. Robert G. Williams, 2013, “An Argument
for Conjunction Conditionalization”,
The Review of Symbolic
Logic
, 6(04): 573–588. doi:10.1017/S1755020313000191
Warmbrōd, Ken, 1981a, “Counterfactuals and Substitution
of Equivalent Antecedents”,
Journal of Philosophical
Logic
, 10(2): 267–289. doi:10.1007/BF00248853
–––, 1981b, “An Indexical Theory of
Conditionals”,
Dialogue, Canadian Philosophical Review
,
20(4): 644–664. doi:10.1017/S0012217300021399
Wasserman, Ryan, 2006, “The Future Similarity Objection
Revisited”,
Synthese
, 150(1): 57–67.
doi:10.1007/s11229-004-6256-9
Weatherson, Brian, 2001, “Indicative and Subjunctive
Conditionals”,
The Philosophical Quarterly
, 51(203):
200–216. doi:10.1111/j.0031-8094.2001.00224.x
Willer, Malte, 2015, “Simplifying Counterfactuals”, in
20th Amsterdam Colloquium
, Thomas Brochhagen, Floris
Roelofsen, and Nadine Theiler (eds.), Amsterdam: ILLC, 428–437.
 [
Willer 2015 available online
]
–––, 2017, “Lessons from Sobel
Sequences”,
Semantics and Pragmatics
, 10(4).
doi:10.3765/sp.10.4
–––, 2018, “Simplifying with Free
Choice”,
Topoi
, 37(3): 379–392.
doi:10.1007/s11245-016-9437-5
Williams, J. Robert G., 2010, “Defending Conditional
Excluded Middle”,
Noûs
, 44(4): 650–668.
doi:10.1111/j.1468-0068.2010.00766.x
Williamson, Timothy, 2005, “Armchair Philosophy,
Metaphysical Modality and Counterfactual Thinking”,
Proceedings of the Aristotelian Society
, 105(1): 1–23.
doi:10.1111/j.0066-7373.2004.00100.x
–––, 2007,
The Philosophy of
Philosophy
, Malden, MA: Blackwell.
Wilson, Alastair, 2018, “Metaphysical Causation”,
Noûs
, 52(4): 723–751. doi:10.1111/nous.12190
Woodward, Jim, 2002, “What Is a Mechanism? A Counterfactual
Account”,
Philosophy of Science
, 69(S3):
S366–S377. doi:10.1086/341859
–––, 2003,
Making Things Happen: A Theory of
Causal Explanation
, Oxford: Oxford University Press.
doi:10.1093/0195155270.001.0001
Zeman, Jay, 1997, “Peirce and Philo”, in
Studies
in the Logic of Charles Sanders Peirce
, Nathan Houser, Don
Roberts, and James Van Evra (eds.), Indianapolis: Indiana University
Press, 402–417.
Academic Tools
How to cite this entry
.
Preview the PDF version of this entry
at the
Friends of the SEP Society
.
Look up topics and thinkers related to this entry
at the Internet Philosophy Ontology Project (InPhO).
Enhanced bibliography for this entry
at
PhilPapers
, with links to its database.
Other Internet Resources
Byrne, Ruth, 2017,
 “
Counterfactual Reasoning
”,
 Oxford Bibliographies. (Surveys important psychological research on
counterfactual reasoning.)
[Please contact the author with suggestions.]
Related Entries
causation: counterfactual theories of
|
conditionals
|
impossible worlds
|
laws of nature
|
logic: conditionals
|
logic: modal
|
modality: epistemology of
|
modality: varieties of
|
possibilism-actualism debate
|
possible worlds