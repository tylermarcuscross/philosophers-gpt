Collapse Theories
First published Thu Mar 7, 2002; substantive revision Fri May 15, 2020
Quantum mechanics, with its revolutionary implications, has posed
innumerable problems to philosophers of science. In particular, it has
suggested reconsidering basic concepts such as the existence of a
world that is, at least to some extent, independent of the observer,
the possibility of getting reliable and objective knowledge about it,
and the possibility of taking (under appropriate circumstances) at
least some properties to be objectively possessed by physical systems.
It has also raised many others questions which are well known to those
involved in the debate on the interpretation of this pillar of modern
science. One can argue that most of the problems are not only due to
the intrinsic revolutionary nature of the phenomena which have led to
the development of the theory. They are also related to the fact that,
in its standard formulation and interpretation, quantum mechanics is a
theory which is excellent (in fact it has an unprecedented success in
the history of science) in telling us everything about
what we
observe
, but it meets with serious difficulties in telling us
what there is
. We are making here specific reference to the
central problem of the theory, usually referred to as
the
measurement problem
, which is accompanying quantum theory since
its birth. It is just one of the many attempts to overcome the
difficulties posed by this problem that has led to the development of
Collapse Theories
, i.e., to the
Dynamical Reduction
Program
(DRP). As we shall see, this approach consists in
accepting that the dynamical equation of the standard theory should be
modified by the addition of stochastic and nonlinear terms. The nice
fact is that the resulting theory is capable, on the basis of a single
dynamics which is assumed to govern all natural processes, to account
at the same time for all well-established facts about microscopic
systems as described by the standard theory, as well as for the
so-called postulate of wave packet reduction (WPR), which accompanies
the interaction of a microscopic system with a measuring device. As is
well known, such a postulate is assumed in the standard scheme just in
order to guarantee that
measurements have outcomes
but, as we
shall discuss below, it meets with insurmountable difficulties if one
tries to derive it by assuming the measurement itself to be a process
governed by the linear laws of the theory. Finally, the collapse
theories account in a completely satisfactory way for the classical
behavior of macroscopic systems.
Two specifications are necessary in order to make clear from the
beginning what the limitations and the merits of the program are. The
only satisfactory explicit models of this type (the model proposed by
Ghirardi, Rimini, and Weber (1986), usually referred to as the GRW
theory, as well as all subsequent developments) are phenomenological
attempts to solve a foundational problem. At present, they involve
phenomenological parameters which, if the theory is taken seriously,
acquire the status of new constants of nature. Moreover, the problem
of building satisfactory relativistic generalizations of collapse
models is very difficult, though some improvements have been made,
which have elucidated some crucial points.
In spite of their phenomenological character, Collapse Theories are
assuming a growing relevance, since they provide a clear resolution
for the difficulties of the formalism, to
close the circle
in
the precise sense defined by Abner Shimony (1989). Moreover, they have
allowed a clear identification of the formal features which should
characterize any unified theory of micro and macro processes.
Last but not least, Collapse Theories qualify themselves as rival
theories of quantum mechanics and one can easily identify some of
their physical implications which, in principle, would allow crucial
tests discriminating between the two. Getting stringent indications
from such tests requires experiments, whose technology has been
developed only very recently. Actually, it is just due to remarkable
improvements in the field of opto-mechanics and cold atoms, as well as
nuclear physics, that specific bounds have already been obtained for
the parameters characterizing the theories under investigation; more
important, precise families of physical processes in which a violation
of the linear nature of the standard formalism might emerge have been
clearly identified and are the subject of systematic investigations
which might lead, in the end, to relevant discoveries.
1. General Considerations
2. The Formalism: A Concise Sketch
3. The Macro-Objectification Problem
4. The Birth of Collapse Theories
5. The Original Collapse Model
6. The Continuous Spontaneous Localization Model (CSL)
7. CSL and Experiments
8. Some Remarks about Collapse Theories
9. Relativistic Dynamical Reduction Models
10. Collapse Theories and Definite Perceptions
11. The Interpretation of the Theory and its Primitive Ontologies
12. The Problem of the Tails of the Wave Function
13. The Status of Collapse Models and Recent Positions about them
14. Summary
Bibliography
Academic Tools
Other Internet Resources
Related Entries
1. General Considerations
A very natural question, which all scientists who are concerned about
the meaning and the value of science have to face, is whether one can
develop a coherent worldview that can accommodate our knowledge of
natural phenomena as it is embodied in our best theories. Such a
program meets serious difficulties with quantum mechanics, essentially
because of two formal aspects of the theory according to its standard
formulation, which are common to all of its versions, from the
original nonrelativistic formulations of the 1920s, to current quantum
field theories: the linear nature of the state space and of the
evolution equation; in other words: the validity of the superposition
principle and the related phenomenon of entanglement, which, in
Schrödinger’s words:
is not one but the characteristic trait of quantum mechanics, the one
that enforces its entire departure from classical lines of thought
(Schrödinger 1935: 807).
These two formal features have embarrassing consequences, since they
imply
objective indefiniteness of physical properties both at the micro
and macro level, unless the state collapses;
objective chance in natural processes, i.e., the nonepistemic
nature of quantum probabilities; and
objective entanglement between spatially separated and
non-interacting constituents of a composite system, entailing a sort
of holism and a precise kind of nonlocality.
For the sake of generality, we shall first of all present a very
concise sketch of ‘the rules of the quantum game’.
2. The Formalism: A Concise Sketch
Let us recall the axiomatic structure of quantum theory:
States of physical systems are associated with normalized vectors in a
Hilbert space, a complex, infinite-dimensional, complete and separable
linear vector space equipped with a scalar product. Linearity implies
that the superposition principle holds: if \(\ket{f}\) is a state and
\(\ket{g}\) is a state, then (for \(a\) and \(b\) arbitrary complex
numbers) also
\[
\ket{K} = a\ket{f} + b\ket{g}
\]
is a state. Moreover, the state evolution is linear, i.e., it
preserves superpositions: if \(\ket{f,t}\) and \(\ket{g,t}\) are the
states obtained by evolving the states \(\ket{f,0}\) and
\(\ket{g,0}\), respectively, from the initial time \(t=0\) to the time
\(t\), then \(a\ket{f,t} + b\ket{g,t}\) is the state obtained by the
evolution of \(a\ket{f,0} + b\ket{g,0}\). Finally, the completeness
assumption is made, i.e., that the knowledge of its statevector
represents, in principle, the most accurate information one can have
about the state of an individual physical system.
Observable quantities are represented by self-adjoint operators \(B\)
on the Hilbert space containing the possible states of the system. The
associated eigenvalue equations \(B\ket{b_k} = b_k \ket{b_k}\) and the
corresponding eigenmanifolds (the linear manifolds spanned by the
eigenvectors associated to a given eigenvalue, also called
eigenspaces) play a basic role for the predictive content of the
theory. In fact:
The eigenvalues \(b_k\) of an operator \(B\) represent the only
possible outcomes in a measurement of the corresponding
observable.
The square of the norm (i.e., the length) of the projection of the
normalized statevector (i.e., of length 1) describing the state of the
system onto the eigenmanifold associated to a given eigenvalue gives
the probability of obtaining the corresponding eigenvalue as the
outcome of the measurement of that observable. In particular, it is
useful to recall that when one is interested in the probability of
finding a particle at a given place, one has to resort to the
so-called configuration space representation of the statevector. In
such a case the statevector becomes a square-integrable function of
the position variables of the particles of the system, whose square
modulus yields the probability density for the possible outcomes of
position measurements.
We stress that, according to the above scheme, quantum mechanics makes
only conditional probabilistic predictions (conditional on the
measurement being actually performed) for the outcomes of prospective
(and in general incompatible among themselves) measurement processes.
Only if a state belongs to an eigenmanifold of the observable, which
is going to be measured, already before the act of measurement, one
can predict the outcome with certainty. In all other cases—if
the completeness assumption is made—one has objective
nonepistemic probabilities for different outcomes.
The orthodox position gives a very simple answer to the question: what
determines the outcome, when different outcomes are possible? The
answer is “nothing”—the theory is complete and
therefore it is illegitimate to raise any question about properties
possessed prior to a measurement, when different outcomes of a
measurement of an observable have non-vanishing probabilities of
occurring, if the measurement is actually performed. Correspondingly,
the referents of the theory are only the results of measurements.
These are to be described in classical terms and involve in general
mutually exclusive physical conditions.
Regarding the legitimacy of attributing properties to physical
systems, one could say that quantum mechanics warns us against
attributing too many properties to physical systems.
However—with Einstein—one can adopt a sufficient condition
for the existence of an objective individual property the possibility
to predict with certainty the outcome of a measurement. This implies
that, whenever the overall statevector factorizes into the state of
the Hilbert space of the physical system \(S\) times the state for the
rest of the universe, \(S\) does possess some properties (actually a
complete set of properties, i.e., those associated to appropriate
maximal sets of commuting observables).
Before concluding this section some comments about the measurement
process are of relevance. Quantum theory was created to describe the
behavior of microscopic phenomena as was emerging from observations.
In order to obtain information about system at the molecular and
(sub-) atomic scale, one must be able to establish strict correlations
between the states of the microscopic system and the states of the
measuring devices, which we directly perceive. Within the formalism,
this is described by considering appropriate micro-macro interactions.
The fact that when the measurement is completed one can make
statements about the outcome is accounted for by the already mentioned
WPR postulate (Dirac 1935):
a measurement always causes a system
to jump in an eigenstate of the observed quantity
.
Correspondingly, also the statevector of the apparatus
‘jumps’ into the manifold associated to the recorded
outcome.
3. The Macro-Objectification Problem
We shall now clarify why the formalism we have just presented gives
rise to the measurement problem. To this purpose we shall, first of
all, discuss the standard oversimplified argument based on the
so-called von Neumann ideal measurement scheme.
Let us begin by recalling how measurements are described in the
standard formalism:
Suppose that a microsystem \(S\), immediately before the measurement
of one of its observables, say \(B\), is in the eigenstate
\(\ket{b_j}\) of the corresponding operator. The apparatus (a
macrosystem) used to gain information about \(B\) is initially assumed
to be in a precise macroscopic state, its ready state, corresponding
to a definite macro property—e.g., its pointer points at 0 on a
scale. Since the apparatus \(A\) is made of elementary particles,
atoms and so on, it should be possible to describe it within quantum
mechanics, which will associate a well defined state vector
\(\ket{A_0}\) to it (at least in principle). One then assumes that
there is an appropriate system-apparatus interaction lasting for a
finite time, such that when the initial state of the apparatus is
triggered by the state \(\ket{b_j}\), it ends up in a final
configuration \(\ket{A_j}\), which is macroscopically distinguishable
from the initial one and from the other configurations \(\ket{A_k}\)
in which it would end up if triggered by a different eigenstate
\(\ket{b_k}\). Moreover, for simplicity one assumes that the system is
left by the measurement in its initial state. In brief, one assumes
that one can dispose things in such a way that the system-apparatus
interaction can be described as:
\[\begin{align}
\tag{1}
(\textit{initial state}){:}\ & \ket{b_k} \ket{A_0} \\
(\textit{final state}){:}\ & \ket{b_k} \ket{A_k} 
\end{align}\]
Equation (1) and the hypothesis that the superposition principle
governs all natural processes tell us that, if the initial state of
the microsystem is a linear superposition of different eigenstates
(for simplicity we will consider only two of them), one has:
\[\begin{align}
\tag{2}
(\textit{initial state}){:}\ & (a\ket{b_k} + b\ket{b_j})\ket{A_0 } \\
(\textit{final state}){:}\ & (a\ket{b_k} \ket{A_k} + b\ket{b_j} \ket{A_j}).
\end{align}\]
Some remarks about this are in order:
Clearly, the above scheme is highly idealized, both because it
takes for granted that one can prepare the apparatus in a precise
state, which is impossible since we cannot have control over all its
degrees of freedom, and because it assumes that the apparatus
registers the outcome without altering the state of the measured
system. However, as we shall discuss below, these assumptions are by
no means essential to derive the embarrassing conclusion we have to
face, i.e., that the final state is a linear superposition of two
states corresponding to two macroscopically different states of the
apparatus. Since we know that the + representing linear superpositions
cannot be replaced by the logical alternative
either …
or
, the measurement problem arises: what meaning can one attach
to a state of affairs in which two macroscopically and perceptively
different states occur simultaneously?
As already mentioned, the standard solution to this problem is
given by the WPR postulate: in a measurement process reduction occurs:
the final state is not the one appearing in the second line of
equation (2) but, since macro-objectification takes place, it is
\[
\begin{align}
\tag{3}
\text{either } &\ket{b_k} \ket{A_k} \text{ with probability }
\lvert a\rvert^2 \\ \text{or } &\ket{b_j} \ket{A_j} \text{ with
probability } \lvert b\rvert^2.
\end{align}
\]
Nowadays, there is a general consensus that this solution is
absolutely unacceptable. It corresponds to assuming that the linear
nature of the theory is broken at some point, without clearly
specifying when. Thus, quantum theory is unable to explain how it can
happen that apparatuses behave as required by the WPR postulate (which
is one of the axioms of the theory), instead of satisfying the
Schrödinger equation. Even if one were to accept that quantum
mechanics has a limited field of applicability, so that it does not
account for all natural processes and, in particular, it breaks down
at the macrolevel, it is clear that the theory does not contain any
precise criterion for identifying the borderline between micro and
macro, linear and nonlinear, deterministic and stochastic, reversible
and irreversible. To use the words of J.S. Bell, there is nothing in
the theory fixing such a borderline and the
split
between the
two above types of processes is fundamentally
shifty
.
If one looks at the historical debate on this problem, one can easily
see that it is precisely by continuously resorting to this ambiguity
about the split that adherents of the Copenhagen orthodoxy or
easy
solvers
(Bell 1990) of the measurement problem have rejected the
criticism of the
heretics
(Gottfried 2000). For instance,
Bohr succeeded in rejecting Einstein’s criticisms at the Solvay
Conferences by stressing that some macroscopic parts of the apparatus
had to be treated fully quantum mechanically; von Neumann and Wigner
displaced the split by locating it between the physical processes and
the consciousness (but what is a conscious being, from the physical
point of view?), and so on.
It is not our task to review here the various attempts to solve the
above difficulties. One can find many exhaustive treatments of this
problem in the literature. We conclude this section by discussing how
the measurement problem is indeed a consequence of very general, in
fact unavoidable, assumptions on the nature of measurements, and not
specifically of the assumptions of von (oversimplified) von
Neumann’s model. This was established in a series of theorems of
increasing generality, notably the ones by Fine (1970),
d’Espagnat (1971), Shimony (1974), Brown (1986) and Busch &
Shimony (1996). Possibly the most general and direct proof is given by
Bassi and Ghirardi (2000), whose results we briefly summarize. The
assumptions of the theorem are:
A microsystem can be prepared at least in two different
eigenstates of an observable (for example the spin component along the
z
-axis) and in a superposition of two such states;
One has a sufficiently reliable way of ‘measuring’
such an observable, meaning that when the measurement is triggered by
each of the two above eigenstates, the process leads
in the vast
majority of cases
to macroscopically and perceptually different
situations of the universe. This requirement allows for cases in which
the experimenter does not have perfect control of the apparatus, the
apparatus is entangled with the rest of the universe, the apparatus
makes mistakes, or the measured system is altered or even destroyed in
the measurement process;
All natural processes obey the linear laws of quantum theory.
From these very general assumptions one can show that, repeating the
measurement on systems prepared in the superposition of the two given
eigenstates, in the great majority of cases one ends up in a
superposition of macroscopically and perceptually different situations
of the whole universe. This, again, is the measurement problem of
quantum mechanics, which calls for a resolution.
4. The Birth of Collapse Theories
The debate on the macro-objectification problem continued for many
years after the early days of quantum mechanics. In the early 1950s an
important step was taken by D. Bohm who presented (Bohm 1952) a
mathematically precise deterministic completion of quantum mechanics
(see the entry on Bohmian Mechanics), which was anticipated by de
Broglie in the 1920s. In the area of Collapse Theories, one should
mention the contribution by Bohm and Bub (1966), which was based on
the interaction of the statevector with Wiener-Siegel hidden
variables. But let us come to Collapse Theories in the sense currently
attached to this expression.
Important investigations during the 1970s can be considered as
preliminary steps for the subsequent developments. In the years 1970
the school of L. Fonda in Italy concerned with quantum decay processes
and in particular with the possibility of deriving, within a quantum
context, the exponential decay law (Fonda, Ghirardi, and Rimini 1978).
Some features of this approach turned out to be relevant for the
subsequent development of Collapse Theories:
The focus is on individual physical systems, not ensembles;
The statevector is supposed to undergo random processes at random
times, inducing sudden changes, which drive it either within the
linear manifold of the unstable state or within that of the decay
products;
To make the treatment quite general (the apparatus is insensitive
of which kind of unstable system it is testing) one is led to identify
the random processes with localization processes of the relative
coordinates of the decay fragments. Such an assumption, combined with
the peculiar resonant dynamics characterizing an unstable system,
yields, completely in general, the desired result. The ‘relative
position basis’ is the preferred basis of this theory;
Analogous ideas have been applied to measurement processes;
The final equation for the evolution at the ensemble level is of
the quantum dynamical semigroup type and has a structure extremely
similar to the final equation of the GRW theory.
Obviously, in these papers the considered reduction processes were not
assumed to be ‘spontaneous and fundamental’ natural
processes, but due to system- environment interactions. Accordingly,
these attempts did not represent original proposals for solving the
macro-objectification problem, yet they have paved the way for the
elaboration of the GRW theory.
Around the same years, P. Pearle (1976, 1979), and subsequently N.
Gisin (1984a,b) and Diosi (1988), had developed models which accounted
for the reduction process in terms of stochastic differential
equations. While they were looking for a new dynamical equation
offering a solution to the macro-objectification problem, they did not
succeed in identifying the states to which the dynamical equation
should lead. The these states were assumed to depend on the particular
measurement process one was considering, leaving the program of
formulating a universal dynamics accounting for the quantum properties
of microscopic systems together the classical properties of
macroscopic objects incomplete. In those years N. Gisin formulated
subsequently an interesting argument (Gisin 1989) according to which
nonlinear modifications of the Schrödinger equation in general
are unacceptable, since they imply the possibility of sending
superluminal signals. This argument eventually proved that only a very
specific class of nonlinear (and stochastic) modifications of the
Schrödinger equation is physically acceptable (Caiaffa, Smirne
& Bassi 2017, and references therein), the class which collapse
models belong to.
5. The Original Collapse Model
As already mentioned, the Collapse Theory we are going to describe
amounts to accepting a modification of the standard evolution law of
quantum theory such that microprocesses and macroprocesses are
governed by a single dynamics. Such a dynamics must imply that the
micro-macro interaction in a measurement process leads to WPR. Bearing
this in mind, recall that the characteristic feature distinguishing
the quantum evolution from WPR is that, while Schrödinger’s
equation is linear and deterministic (at the wave function level), WPR
is nonlinear and stochastic. It is then natural to consider, as was
suggested for the first time in the above quoted papers by P. Pearle,
the possibility of nonlinear and stochastic modifications of the
standard Schrödinger dynamics. Such modifications, to be
universal, must satisfy one important requirement, called the trigger
problem by Pearle (1989): the reduction mechanism must become more and
more effective in going from the micro to the macro domain. The
solution to this problem constitutes the central feature of Collapse
Theories of the GRW type. To discuss these points, let us briefly
review the GRW model, first consistent model to appear in the
literature.
Within such a model, initially referred to as QMSL (Quantum Mechanics
with Spontaneous Localizations), the problem of the choice of the
preferred basis is solved by noting that the most embarrassing
superpositions, at the macroscopic level, are those involving
different spatial locations of macroscopic objects. Actually, as
Einstein has stressed, this is a crucial point which has to be faced
by anybody aiming at taking a macro-objective position about natural
phenomena: ‘A macro-body must always have a quasi-sharply
defined position in the objective description of reality’ (Born
1971: 223). Accordingly, QMSL considers the possibility of spontaneous
processes, which are assumed to occur instantaneously and at the
microscopic level, which tend to suppress the linear superpositions of
differently localized states. The required trigger mechanism must then
follow consistently.
The key assumption of QMSL is the following: each elementary
constituent of any physical system is subjected, at random times, to
random and spontaneous localization processes (which we will call
hittings) around appropriate positions. To have a precise mathematical
model one has to be very specific about the above assumptions, making
explicit HOW the process works (which modifications of the wave
function are induced by the localizations), WHERE it occurs (what
determines the occurrence of a localization at a certain position
rather than at another one), and finally WHEN (at what times), it
occurs. The answers to these questions are now presented.
Let us consider a system of \(N\) distinguishable particles and let us
denote by \(F(\boldsymbol{q}_1, \boldsymbol{q}_2 , \ldots
,\boldsymbol{q}_N )\) the coordinate representation (wave function) of
the state vector (we disregard spin variables since hittings are
assumed not to act on them).
The answer to the question HOW is: if a hitting occurs for the
\(i\)-th particle at point \(\boldsymbol{x}\), the wave function is
instantaneously multiplied by a Gaussian function (appropriately
normalized) 

\[ G(\boldsymbol{q}_i, \boldsymbol{x}) = K
\exp[-\{1/(2d^2)\}(\boldsymbol{q}_i -\boldsymbol{x})^2], \]
where \(d\) represents the localization accuracy. Let us denote as
\[ L_i (\boldsymbol{q}_1, \boldsymbol{q}_2, \ldots, \boldsymbol{q}_N ;
\boldsymbol{x}) = F(\boldsymbol{q}_1, \boldsymbol{q}_2, \ldots,
\boldsymbol{q}_N) G(\boldsymbol{q}_i, \boldsymbol{x}) \]
the wave function immediately after the localization, as yet
unnormalized.
As for WHERE the localization occurs, it is assumed that the
probability density \(P(\boldsymbol{x})\) of its taking place at the
point \(\boldsymbol{x}\) is given by the square of the norm of the
state \(L_i\) (the length, or to be more precise, the integral of the
modulus squared of the function \(L_i\) over the \(3N\)-dimensional
space). This implies that hittings occur with higher probability at
those places where, in the standard quantum description, there is a
higher probability of finding the particle if a measurement were
performed (but remember that in our case there is no measurement being
performed; hittings are spontaneous processes). Note that the above
prescription introduces nonlinear and stochastic elements in the
dynamics. The constant \(K\) appearing in the expression of
\(G(\boldsymbol{q}_i, \boldsymbol{x})\) is chosen in such a way that
the integral of \(P(\boldsymbol{x})\) over the whole space equals
1.
Finally, the question WHEN is answered by assuming that the
hittings occur at randomly distributed times, according to a Poisson
distribution, with mean frequency \(f\).
It is straightforward to see that the hitting process leads, when it
occurs, to the localization of states of the particle, which are
initially delocalized over distances greater than \(d\). As a simple
example we can consider a single particle whose wavefunction is
different from zero only in two small and far apart regions \(h\) and
\(t\). Suppose that a localization occurs around \(h\); the state
after the hitting is then appreciably different from zero only in a
region around \(h\) itself. A completely analogous argument holds if
the hitting takes place around \(t\). Regarding the possibility for
the state to collapse around points, which are far from both \(h\) and
\(t\), one easily sees that the probability density for such hittings
, according to the multiplication rule determining \(L_i\), is
practically zero; moreover, that if such a hitting were to occur,
after it is normalized, the wave function of the system would remain
almost unchanged.
We can now discuss the most important feature of the theory: the
Trigger Mechanism. To understand the way in which the spontaneous
localization mechanism is enhanced by increasing the number of
particles which are in far apart spatial regions (as compared to
\(d)\), one can consider, for simplicity, the superposition
\(\ket{S}\), with equal weights, of two macroscopic pointer states
\(\ket{H}\) and \(\ket{T}\), corresponding to two different pointer
positions \(H\) and \(T\), respectively. Taking into account that the
pointer is ‘almost rigid’ and contains a macroscopic
number \(N\) of microscopic constituents, the state can be written, in
obvious notation, as:
\[\tag{4} \ket{S} = [\ket{1 \near h_1} \ldots \ket{N \near h_N} +
\ket{1 \near t_1} \ldots \ket{N \near t_N}], \]
where \(h_i\) is near \(H\), and \(t_i\) is near \(T\). The states
appearing in first term on the right-hand side of equation (4) are
different from zero only when their arguments \((1,\ldots ,N)\) are
all near \(H\), while those of the second term are different from zero
only when they are all near \(T\). It is now evident that if any of
the particles (say, the \(i\)-th particle) undergoes a hitting
process, for example around \(h_i\), the multiplication prescription
leads practically to the suppression of the second term in (4). Thus,
any spontaneous localization of any of the constituents amounts to a
localization of the pointer. The hitting frequency is therefore
effectively amplified proportionally to the number of constituents.
Notice that, for simplicity, the argument refers to an almost rigid
body, one for which all particles are around \(H\) in one of the
states of the superposition and around \(T\) in the other state. It
should however be obvious that what really matters in amplifying the
reductions is the number of particles which are in different positions
in the two states appearing in the superposition itself.
Under these premises we can now proceed to choose the parameters \(d\)
and \(f\) of the theory, i.e., the localization accuracy and the mean
localization frequency. The argument given above suggests how one can
choose the parameters in such a way that the quantum predictions for
microscopic systems remain fully valid while the embarrassing
macroscopic superpositions in measurement-like situations are
suppressed in very short times. Accordingly, as a consequence of the
unified dynamics governing all physical processes, individual
macroscopic objects acquire definite macroscopic properties. The
choice suggested in the GRW-model is:
\[\begin{align}
\tag{5}
f &= 10^{-16} \text{ s}^{-1} \\
d &= 10^{-5} \text{ cm} 
\end{align}\]
It follows that a microscopic system undergoes a localization, on
average, every hundred million years, while a macroscopic one
undergoes a localization every \(10^{-7}\) seconds. With reference to
the challenging version of the macro-objectification problem presented
by Schrödinger with the famous example of his cat, J.S. Bell
comments (1987: 44): [within QMSL]
the cat is not both dead and
alive for more than a split second
. Besides the extremely low
frequency of the hittings for microscopic systems, also the fact that
the localization width is large compared to the dimensions of atoms
(so that even when a localization occurs it does very little violence
to the internal economy of an atom) plays an important role in
guaranteeing that no violation of well-tested quantum mechanical
predictions is implied by the modified dynamics.
Contrary to standard quantum mechanics, the GRW theory allows to
locate precisely the ‘split’ between micro and macro,
reversible and irreversible, quantum and classical. This is another
way of saying that GRW solved the measurement problem. The transition
between the two types of ‘regimes’ is governed by the
number of particles, which are localized by the collapse process. A
consequence of this is that GRW makes predictions, which are different
from standard quantum mechanical predictions. We will come back on
this important issue.
Concerning the choice of the parameters of the model, it has to be
stressed that, as it is obvious, the just mentioned transition region
from micro to macro depends crucially on their values. departing from
the original choice of GRW, Adler (2003) has suggested to increase the
value of \(f\) by a factor of the order of \(10^9\). The reasons for
this derive from requiring that during latent image formation in
photography, the collapse becomes effective right after a grain of the
emulsion has been excited; this is equivalent to requiring that when a
human eye is hit by few photons (the perceptual threshold being very
low) reduction takes place in the rods of the eye (Bassi, Deckert and
Ferialdi 2010). As we will discuss in what follows, if one takes the
original GRW value for \(f\), reduction cannot occur in the rods
(because a relatively small number of molecules—less than
\(10^5\)—are affected), but only during the transmission along
the nervous signal within the brain, a process which involves the
displacement of a number of ions of the order of \(10^{12}\).
It is interesting to remark that the drastic change suggested by Adler
(2003) has physical implications which have already been
experimentally falsified, see Curceanu, Hiesmayr, and Piscicchia 2015;
Bassi, Deckert, and Ferialdi 2010; Vinante et al. 2016; and
Toroš and Bassi 2018.
6. The Continuous Spontaneous Localization Model (CSL)
The model just presented (QMSL) has a serious drawback: it does not
allow to deal with systems containing identical constituents, because
it does not respect the symmetry or antisymmetry requirements for such
particles. A quite natural idea to overcome this difficulty is to
relate the hitting process not to the individual particles but to the
particle number density averaged over an appropriate volume. This can
be done by introducing a new phenomenological parameter in the theory
which however can be eliminated by an appropriate limiting procedure
(see below).
Another way to overcome this problem derives from injecting the
physically appropriate principles of the GRW model within the original
approach of P. Pearle. This line of thought has led to what is known
as the CSL (Continuous Spontaneous Localization) model (Pearle 1989;
Ghirardi, Pearle, and Rimini 1990) in which the discontinuous jumps
which characterize QMSL are replaced by a continuous stochastic
evolution in the Hilbert space (a sort of Brownian motion of the
statevector).
The basic working principles are CSL are similar to those of the GRW
model, though the technical detail might different significantly. For
a review see (Bassi and Ghirardi 2003; Adler 2007, Bassi, Lochan, et
al. 2013). At this regard, it is interesting to note (Ghirardi,
Pearle, & Rimini 1990) that for any CSL dynamics there is a hitting
dynamics which, from a physical point of view, is ‘as close to
it as one wants’. Instead of entering into the details of the
CSL formalism, it is useful, for the discussion below, to analyze a
simplified version of it.
With the aim of understanding the physical implications of the CSL
model, such as the rate of suppression of coherence, we make now some
simplifying assumptions. First, we assume that we are dealing with
only one kind of particles (e.g., the nucleons), secondly, we
disregard the standard Schrödinger term in the evolution and,
finally, we divide the whole space in cells of volume \(d^3\). We
denote by \(\ket{n_1, n_2 ,\ldots}\) a Fock state in which there are
\(n_i\) particles in cell \(i\), and we consider a superposition of
two states \(\ket{n_1, n_2 , \ldots}\) and \(\ket{m_1, m_2 , \ldots}\)
which differ in the occupation numbers of the various cells of the
universe. With these assumptions it is quite easy to prove that the
rate of suppression of the coherence between the two states (so that
the final state is one of the two and not their superposition) is
governed by the quantity:
\[\tag{6}
\exp\{-f [(n_1 - m_1)^2 + (n_2 - m_2)^2 +\ldots]t\},
\]
all cells of the universe appearing in the sum within the square
brackets in the exponent. Apart from differences relating to the
identity of the constituents, the overall physics is quite similar to
that implied by QMSL.
Equation 6 offers the opportunity of discussing the possibility of
relating the suppression of coherence to gravitational effects. In
fact, with reference to this equation we notice that the worst case
scenario (from the point of view of the time necessary to suppress
coherence) is that corresponding to the superposition of two states
for which the occupation numbers of the individual cells differ only
by one unit. In this case the amplifying effect of taking the square
of the differences disappears. Let us then ask the question: how many
nucleons (at worst) should occupy different cells, in order for the
given superposition to be dynamically suppressed within the time which
characterizes human perceptual processes? Since such a time is of the
order of \(10^{-2}\) sec and \(f = 10^{-16}\text{ sec}^{-1}\),
the number of displaced nucleons must be of the order of \(10^{18}\),
which corresponds, to a remarkable accuracy, to a Planck mass. This
figure seems to point in the same direction as Penrose’s
attempts to relate reduction mechanisms to quantum gravitational
effects (Penrose 1989).
7. CSL and Experiments
By modifying the quantum dynamics, CSL like all collapse models makes
predictions, which slightly differ from the standard quantum
mechanical ones. We review the most important cases.
Effects in superconducting devices
. A detailed analysis has
been presented in (Ghirardi & Rimini 1990). As shown there and as
follows from estimates about possible effects for superconducting
devices (Rae 1990; Gallis and Fleming 1990; Rimini 1995), and for the
excitation of atoms (Squires 1991), it turns out not to be possible,
with present technology, to perform clear-cut experiments allowing to
discriminate the model from standard quantum mechanics.
Loss of coherence in diffraction experiments with
macromolecules
. The Viennese groups of A. Zeilinger first, and
then of M. Arndt, have performed important diffraction experiments
involving macromolecules. The most relevant ones involve C\(_{60}\),
(720 nucleons) (Arndt et al. 1999), C\(_{70}\), (840 nucleons)
(Hackermueller et al. 2004) and more complex molecules (over 10,000
nucleons, Eibenberger et al. 2013, Fein et al. 2019). So far these
experiments are not capable of testing the proposal of Alder,
therefore even less the weaker proposal of GRW, for the collapse rate
(Toroš, Gasbarri, and Bassi 2017). Significant technological
development is necessary in order to probe these values, possibly by
realizing the experiment in outer space where coherences can be
maintained for longer times (Kaltenbaek, Hechenblaikner, et al. 2012).
Loss of coherence in opto-mechanical interferometers
.
Recently, an interesting proposal of testing the superposition
principle by resorting to an experimental set-up involving a
(mesoscopic) mirror has been advanced (Marshall et al. 2003). This
stimulating proposal has led a group of scientists directly interested
in Collapse Theories (Bassi, Ippoliti & Adler 2005; Adler, Bassi
& Ippoliti 2005) to check whether the proposed experiment might be a
crucial one for testing dynamical reduction models versus quantum
mechanics. The problem is extremely subtle because the extension of
the oscillations of the mirror is much smaller than the localization
accuracy of GRW, so that the localizations processes become almost
ineffective. However, quite recently a detailed reconsideration of the
physics of such systems has been performed and it has allowed to draw
the relevant conclusion that the proposal by Adler (2007) of changing
the frequency of the GRW theory of a factor like the one he has
considered is untenable.
Non-interferometric tests in opto-mechanical systems
. In
2003, an interesting proposal of testing the superposition of a
mesoscopic mirror was put forward (Marshall et al. 2003). This
stimulating proposal faced strong technical difficulties, such as
environmental decoherence, which prevents the detection of the
superposition. There is, however, a side effect of collapse theories
that can be exploited in such systems. Indeed, the collapse of the
wavefunction leads to an effective noise on the center of mass of the
system (Collett & Pearle 2003), which can be eventually bounded
through experiments. The optomechanical application has been proposed
(Bahrami, Paternostro, et al. 2014; Nimmrichter, et al. 2014; Diosi
2015) to test such an effect, and various experiments showed the
potential of this technique. They range from nanomechanical cantilever
cooled to millikelvin temperature (Vinante, Bahrami, et al. 2016;
Vinante, Mezzena, et al. 2017) to the gravitational wave detectors
LIGO, AURIGA and LISA Pathfinder (Carlesso, Bassi, et al. 2016; Helou
et al. 2017) as well as optically or magnetically levitated systems at
room temperature (Zheng et al.  2020; Pontin et al. 2019 [Other
Internet Resources]). Recently, several proposals were presented to
push even further the bounds on the collapse parameters, which now
place constrains just below f = 10
−8
sec
−1
at d = 10
−7
m. These proposals
exploit different possible modification of current experiments, for
example a multi-layer structure of the test mass (Carlesso, Vinante,
et al. 2018) would amplify the bound for particular values of d. One
can also consider different degrees of freedom, for example the
rotational ones could in principle be more sensitive to collapse
effects (Carlesso, Paternostro, et al. 2018; Schrinski, Stickler,
& Hornberger 2017).  A first application was implemented in a
torsional experiment (Komori et al. 2020).
Non-interferometric experiments with cold atoms
. The recent
advances in trapping, cooling and manipulating ensembles of atoms
paved the way for testing collapse models with cold atoms. Similarly
to optomechanical systems, bounds on the collapse parameters are
derived by quantifying the Brownian noise induced by the collapse
process. The focus is on the energy increase or the position
diffusion. To make an example, if the atomic cloud can freely evolve,
the energy will grow linearly with time, while the position spread
goes with the cubic power. Experimental bounds were obtained from both
variables and analyzed in Laloe, Muillin, and Pearle 2014 and
Bilardello et al. 2016 respectively.
Spontaneous X-ray emission from Germanium
. Collapse models
not only forbid macroscopic superpositions to be stable, they share
several other features which are forbidden by the standard theory. One
of these is the spontaneous emission of radiation from otherwise
stable systems, like atoms. While the standard theory predicts that
such systems—if not excited—do not emit radiation,
collapse models allow for radiation to be produced, as a consequence
of the interaction between the system and the noise responsible for
the collapse. The emission rate has been computed for free charged
particles (Fu 1997; Adler, Bassi, & Donadi 2013), an harmonic
oscillator (Bassi & Donadi 2014; Donadi, Deckert, & Bassi
2014) and for hydrogenic atoms (Adler et al. 2007). A formula for the
radiation emission from a generic system is given in (Donadi &
Bassi 2014). The theoretical predictions are compatible with current
experimental data (Fu 1997). At any rate, the importance of such
experiments lies in the fact that—so far—they provide the
strongest upper bounds on the collapse parameters (Adler & Bassi
2007). But this is not the whole story: very recently (Curceanu,
Hiesmayr, & Piscicchia 2015; Curceanu, Bartalucci, et al. 2016;
Piscicchia et al. 2017), following this line of research, it was
proven experimentally that the proposal by Adler (2007) of a drastic
change of the frequency of the localizations with respect to those of
the original GRW paper is definitely incompatible with the
experimental data, unless the CSL model is modified by taking a
non-white noise (which is actually a reasonable assumption, if the
noise is physical).
CSL and conscious perceptions
. One interesting feature of
CSL is that when conscious perceptions are involved, the collapse time
of two brain states in a superposition and the time which is necessary
for the emergence of a definite perception, are quite similar, and
this has some (small but significant) implications concerning the
probabilities of the outcomes. This point has been analyzed in detail
and explicitly evaluated by resorting to a simple model of a quantum
system subjected to reduction processes (Ghirardi & Romano 2014).
The idea is to consider a spin 1/2 particle whose spin rotates around
the
x
-axis with a frequency of about one hundreth of the one of
the random measurements ascertaining whether its spin is UP or DOWN
with respect to the
z
-axis. It turns out that for a
superposition with amplitudes \(a\) and \(b\) of the two eigenstates
of S\(_z\), the probability of the two supervening perceptions
associated to the two outcomes will differ of about 1% from those
predicted by quantum mechanics, i.e. \(\lvert a\rvert^2\) and \(\lvert
b\rvert^2\), respectively.
The test would be quite interesting also for the general meaning of
collapse theories because it will give some practical evidence
concerning the fact that, in the case in which a superposition of two
microscopic different states which are able to trigger two precise
(and different) perceptions, the brain actually collapses the
wavefunction yielding only one perception, an clear-cut indication
that the standard theory cannot run the whole process.
Summarizing, due to fast technological improvements, experiments in
which one might test the deviations from Standard Quantum Theory
implied by Collapse Models, seems to have become more and more
feasible.
8. Some Remarks about Collapse Theories
A. Pais famously recalls in his biography of Einstein:
We often discussed his notions on objective reality. I recall that
during one walk Einstein suddenly stopped, turned to me and asked
whether I really believed that the moon exists only when I look at it.
(Pais 1982: 5)
In the context of Einstein’s remarks in
Albert Einstein,
Philosopher-Scientist
(Schilpp 1949), we can regard this
reference to the moon as an extreme example of ‘a fact that
belongs entirely within the sphere of macroscopic concepts’, as
is also a mark on a strip of paper that is used to register the
outcome of a decay experiment, so that
as a consequence, there is hardly likely to be anyone who would be
inclined to consider seriously […] that the existence of the
location is essentially dependent upon the carrying out of an
observation made on the registration strip. For, in the macroscopic
sphere it simply is considered certain that one must adhere to the
program of a realistic description in space and time; whereas in the
sphere of microscopic situations one is more readily inclined to give
up, or at least to modify, this program. (1949: 671)
However,
the ‘macroscopic’ and the ‘microscopic’ are so
inter-related that it appears impracticable to give up this program in
the ‘microscopic’ alone. (1949: 674)
One might speculate that Einstein would not have taken the DRP
seriously, given that it is a fundamentally indeterministic program.
On the other hand, the DRP allows precisely for this middle ground,
between giving up a ‘classical description in space and
time’ altogether (the moon is not there when nobody looks), and
requiring that it be applicable also at the microscopic level (as
within some kind of ‘hidden variables’ theory). It would
seem that the pursuit of ‘realism’ for Einstein was more a
program that had been very successful rather than an a priori
commitment, and that in principle he would have accepted attempts
requiring a radical change in our classical conceptions concerning
microsystems, provided they would nevertheless allow to take a
macrorealist position matching our definite perceptions at this
scale.
In the DRP, we can say of an electron in an EPR-Bohm situation that
‘when nobody looks’, it has no definite spin in any
direction , and in particular that when it is in a superposition of
two states localised far away from each other, it cannot be thought to
be at a definite place (see, however, the remarks in Section 11). In
the macrorealm, however, objects do have definite positions and are
generally describable in classical terms. That is, in spite of the
fact that the DRP program is not adding ‘hidden variables’
to the theory, it implies that the moon is definitely there even if no
sentient being looks at it. In the words of J. S. Bell, the DRP
allows electrons (in general microsystems) to enjoy the cloudiness of
waves, while allowing tables and chairs, and ourselves, and black
marks on photographs, to be rather definitely in one place rather than
another, and to be described in classical terms. (Bell 1989a: 364)
Such a program, as we have seen, is implemented by assuming only the
existence of wave functions, and by proposing a unified dynamics that
governs both microscopic processes and ‘measurements’.
With reference to the latter, no vague definitions are needed. The new
dynamical equations govern the unfolding of any physical process, and
the macroscopic ambiguities that would arise from the linear evolution
are theoretically possible, but only of momentary duration, of no
practical importance and no source of embarrassment.
We have not yet analyzed the implications about locality, but since in
the DRP program no hidden variables are introduced, the situation can
be no worse than in ordinary quantum mechanics:
‘by adding
mathematical precision to the jumps in the wave function’
,
the GRW theory
‘simply makes precise the action at a
distance of ordinary quantum mechanics’
(Bell 1987: 46).
Indeed, a detailed investigation of the locality properties of the
theory becomes possible as shown by Bell himself (Bell 1987: 47).
Moreover, as it will become clear when we will discuss the
interpretation of the theory in terms of mass density, the QMSL and
CSL theories naturally account for the behaviour of macroscopic
objects, corresponding to our definite perceptions about them, the
main objective of Einstein’s requirements.
The achievements of the DRP which are relevant for the debate about
the foundations of quantum mechanics can also be concisely summarized
in the words of H.P. Stapp:
The collapse mechanisms so far proposed could, on the one hand, be
viewed as ad hoc mutilations designed to force ontology to kneel to
prejudice. On the other hand, these proposals show that one can
certainly erect a coherent quantum ontology that generally conforms to
ordinary ideas at the macroscopic level. (Stapp 1989: 157)
9. Relativistic Dynamical Reduction Models
As soon as the GRW proposal appeared and attracted the attention of
J.S. Bell, it stimulated him to look at it from the point of view of
relativity theory. As he stated subsequently:
When I saw this theory first, I thought that I could blow it out of
the water, by showing that it was
grossly
in violation of
Lorentz invariance. That’s connected with the problem of
‘quantum entanglement’, the EPR paradox. (Bell 1989b: 1)
Actually, he had already investigated this point by studying the
effect on the theory of a transformation mimicking a nonrelativistic
approximation of a Lorentz transformation and he arrived at a
surprising conclusion:
… the model is as Lorentz invariant as it could be in its
nonrelativistic version. It takes away the ground of my fear that any
exact formulation of quantum mechanics must conflict with fundamental
Lorentz invariance. (Bell 1987: 49)
What Bell had actually proved by resorting to a two-times formulation
of the Schrödinger equation is that the model violates locality
by violating outcome independence and not, as deterministic hidden
variable theories do, parameter independence.
Indeed, with reference to this point we recall that, as extensively
discussed in the literature (Suppes & Zanotti 1976; van Fraassen
1982; Jarrett 1984; Shimony 1984; see also the entry on
Bell’s Theorem
),
 Bell’s locality assumption is equivalent to the conjunction of
two other assumptions, viz., in Shimony’s terminology, parameter
independence and outcome independence. In view of the experimental
violation of Bell’s inequality, one has to give up either one or
both these assumptions. The above splitting of the locality
requirement into two logically independent conditions is particularly
useful in discussing the different status of CSL and deterministic
hidden variable theories with respect to relativistic requirements.
Actually, as proved by Jarrett himself, when parameter independence is
violated, if one had access to the variables which specify completely
the state of individual physical systems, one could send
faster-than-light signals from one wing of the apparatus to the other.
Moreover, in Ghirardi and Grassi (1996) it has been proved that it is
impossible to build a
genuinely
relativistically invariant
theory which, in its nonrelativistic limit, exhibits parameter
dependence. Here we use the term
genuinely invariant
to
denote a theory for which there is no (hidden) preferred reference
frame. On the other hand, if locality is violated only by the
occurrence of outcome dependence then faster-than-light signaling
cannot be achieved (Eberhard 1978; Ghirardi, Rimini, & Weber
1980). Few years after the just mentioned proof by Bell, it has been
shown in complete generality (Ghirardi, Grassi, Butterfield, &
Fleming 1993) that the GRW and CSL theories, just as standard quantum
mechanics, exhibit only outcome dependence. This is to some extent
encouraging and shows that there are no reasons of principle making
unviable the project of building a relativistically invariant DRM.
Let us be more specific about this crucial problem. P. Pearle was the
first to propose (Pearle 1990) a relativistic generalization of CSL to
a quantum field theory describing a fermion field coupled to a meson
scalar field enriched with the introduction of stochastic and
nonlinear terms. A quite detailed discussion of this proposal was
presented in (Ghirardi, Grassi & Pearle 1990) where it was shown
that the theory enjoys of all properties which are necessary in order
to meet the relativistic constraints. Pearle’s approach requires
the precise formulation of the idea of stochastic Lorentz
invariance.
In this model, one considers a fermion field coupled to a meson field
and puts forward the idea of inducing localizations for the fermions
through their coupling to the mesons with a stochastic dynamical
reduction mechanism acting on the meson variables. In practice,
working in the interaction picture, one considers the standard
Heisenberg evolution equations for the two coupled fields and a
Tomonaga-Schwinger CSL-type evolution equation with a skew-hermitian
coupling to a c-number stochastic potential for the state vector. This
approach has been systematically investigated by Ghirardi, Grassi, and
Pearle (1990), to which we refer the reader for a detailed discussion.
Here we stress that, under specific approximations, one obtains in the
non-relativistic limit a CSL-type equation inducing spatial
localization. However, due to the white noise nature of the stochastic
potential, novel renormalization problems arise: the increase per unit
time and per unit volume of the energy of the meson field is infinite
due to the fact that infinitely many mesons are created. This point
has also been lucidly discussed by Bell (1989c [2007]) in the talk he
delivered at Trieste on the occasion of the 25th anniversary of the
International Centre for Theoretical Physics. This talk appeared under
the title
The Trieste Lecture of John Stewart Bell
. For these
reasons one cannot consider this as a satisfactory example of a
relativistic reduction model.
In the years following the just mentioned attempts there has been a
flourishing of researches aimed at getting the desired result. Let us
briefly comment on them. As already mentioned, the source of the
divergences is the assumption of point interactions between the
quantum field operators in the dynamical equation for the statevector,
or, equivalently, the white character of the stochastic noise. Having
this aspect in mind, P. Pearle (1989), L. Diosi (1990) and A. Bassi
and G.C. Ghirardi (2002) reconsidered the problem from the beginning
by investigating nonrelativistic theories with nonwhite Gaussian
noises. The problem turns out to be very difficult from the
mathematical point of view, but steps forward have been made. In
recent years, a precise formulation of the nonwhite generalization
(Bassi & Ferialdi 2009a and 2009b) of the so-called QMUPL model,
which represents a simplified version of GRW and CSL, has been
proposed. Moreover, a perturbative approach for the CSL model has been
worked out (Adler & Bassi 2007, 2008). Further work is
necessary. This line of thought is very interesting at the
nonrelativistic level; however, it is not yet clear whether it will
lead to a real step forward in the development of relativistic
theories of spontaneous collapse.
In the same spirit, Nicrosini and Rimini (2003) tried to smear out the
point interactions without success because, in their approach, a
preferred reference frame had to be chosen in order to circumvent the
nonintegrability of the Tomonaga-Schwinger equation
Other interesting and different approaches have been suggested. Among
them we mention the one by Dove and Squires (1996) based on discrete
rather than continuous stochastic processes and those by Dowker and
Herbauts (2004) and Dawker and Henson (2004) formulated on a discrete
space-time.
Precisely in the same years similar attempts to formulate a
relativistic generalization of Bohmian Mechanics were ongoing,
encountering difficulties. Relevant steps are represented by a paper
(Dürr 1999) resorting to a preferred spacetime slicing, by the
investigations of Goldstein and Tumulka (2003) and by other scientists
(Berndl et al. 1996). However, we must acknowledge that no one of
these attempts has led to a fully satisfactory solution of the problem
of having a theory without observers, like Bohmian mechanics, which is
perfectly satisfactory from the relativistic point of view, precisely
due to the fact that they are not
genuinely Lorentz invariant
in the sense we have made precise before. Mention should be made also
of the attempt by Horton and Dewdney (2001) to build a
relativistically invariant model based on particle trajectories.
Let us come back to the relativistic DRP. Some important changes have
occurred quite recently. Tumulka (2006a) succeeded in proposing a
relativistic version of the GRW theory for N non-interacting
distinguishable particles, based on the consideration of a multi-time
wavefunction whose evolution is governed by Dirac like equations and
adopts as its Primitive Ontology (see the next section) the one which
attaches a primary role to the space and time points at which
spontaneous localizations occur, as originally suggested by Bell
(1987). To our knowledge this represents the first proposal of a
relativistic dynamical reduction mechanism, which satisfies all
relativistic requirements. In particular it is free from divergences
and foliation independent. However, it is formulated only for systems
containing a fixed number of noninteracting fermions.
D. Bedingham (2011) following strictly the original proposal by Pearle
(1990) of a quantum field theory inducing reductions based on a
Tomonaga- Schwinger equation, has worked out an analogous model which,
however, overcomes the difficulties of the original model. In fact,
Bedingham has circumvented the crucial problems arising from point
interactions by (paying the price of) introducing, besides the fields
characterizing the Quantum Field Theories he is interested in, an
auxiliary relativistic field that amounts to a smearing of the
interactions whilst preserving Lorentz invariance and frame
independence. Adopting this point of view and taking advantage also of
the proposal by Ghirardi (2000) concerning the appropriate way to
define objective properties at any space-time point \(x\), he has been
able to work out a fully satisfactory and consistent relativistic
scheme for quantum field theories in which reduction processes may
occur.
Taking once more advantage of the ideas of the paper by Ghirardi
(2000), various of the just quoted authors (Bedingham, Duerr,
Ghirardi, et al. 2014), have been able to prove that it is possible to
work out a relativistic generalization of Collapse models when their
primitive ontology is taken to be the one given by the mass density
interpretation for the nonrelativistic case we will present in what
follows.
In view of these results and taking into account the interesting
investigations concerning relativistic Bohmian-like theories,the
conclusions that Tumulka has drawn concerning the status of attempts
to account for the macro-objectification process from a relativistic
perspective are well-founded:
A somewhat surprising feature of the present situation is that we seem
to arrive at the following alternative: Bohmian mechanics shows that
one can explain quantum mechanics, exactly and completely, if one is
willing to pay with using a preferred slicing of spacetime; our model
suggests that one should be able to avoid a preferred slicing of
spacetime if one is willing to pay with a certain deviation from
quantum mechanics, (Tumulka 2006a: 842)
a conclusion that he has rephrased and reinforced in Tumulka
(2006c: 350):
Thus, with the presently available models we have the alternative:
either the conventional understanding of relativity is not right, or
quantum mechanics is not exact.
Very recently, a thorough and illuminating discussion of the important
approach by Tumulka has been presented by Tim Maudlin (2011) in the
third revised edition of his book
Quantum Non-Locality and
Relativity
. Tumulka’s position is perfectly consistent with
the present ideas concerning the attempts to transform relativistic
standard quantum mechanics into an ‘exact’ theory in the
sense which has been made precise by J. Bell. Since the only unified,
mathematically precise and formally consistent formulations of the
quantum description of natural processes are Bohmian mechanics and
GRW-like theories, if one chooses the first alternative one has to
accept the existence of a preferred reference frame, while in the
second case one is not led to such a drastic change of position with
respect to relativistic concepts but must accept that the ensuing
theory disagrees with the predictions of quantum mechanics and
acquires the status of a rival theory with respect to it.
In spite of the fact that the situation is, to some extent, still open
and requires further investigations, it has to be recognized that the
efforts which have been spent on such a program have made a better
understanding of some crucial points possible and have thrown light on
some important conceptual issues. First, they have led to a completely
general and rigorous formulation of the concept of stochastic
invariance. Second, they have prompted a critical reconsideration,
based on the discussion of smeared observables with compact support,
of the problem of locality at the individual level. This analysis has
brought out the necessity of reconsidering the criteria for the
attribution of objective local properties to physical systems. In
specific situations, one cannot attribute any local property to a
microsystem: any attempt to do so gives rise to ambiguities. However,
when dealing with macroscopic systems, the impossibility of
attributing to them local properties (or, equivalently, the ambiguity
associated to such properties) lasts only for time intervals necessary
for the dynamical reduction to take place. Moreover, no objective
property corresponding to a local observable, even for microsystems,
can emerge as a consequence of a measurement-like event occurring in a
space-like separated region: such properties emerge only in the future
light cone of the considered macroscopic event. Finally, recent
investigations (Ghirardi & Grassi 1996; Ghirardi 2000) have shown
that the very formal structure of the theory is such that it does not
allow, even conceptually, to establish cause-effect relations between
space-like events.
The conclusion of this section, is that the question of whether a
relativistic dynamical reduction program can find a satisfactory
formulation seems to admit a positive answer.
Connected to collapses and relativity, a paper by Conway and Kochen
(2006a, 2006b [Other Internet Resources]) is of relevance. The first
and most important aim of the paper is the derivation of what the
authors have called
The Free Will Theorem
, putting forward
the provocative idea that if human beings are free to make their
choices about the measurements they will perform on one of a pair of
far-away entangled particles, then one must admit that also the
elementary particles involved in the experiment have free will. A
detailed discussion of what the Free Will theorem implies would be
needed; for us here the relevant fact is that the authors claim that
their theorem implies, as a byproduct, the impossibility of
elaborating a relativistically invariant dynamical reduction model. A
lively debate has arisen. At the end, Goldstein et al. (2010) have
made clear why the argument of Conway and Kochen is not pertinent. We
may conclude that nothing in principle forbids a perfectly
satisfactory relativistic generalization of the GRW theory, and,
actually, as repeatedly stressed, there are many elements which
indicate that this is actually feasible.
10. Collapse Theories and Definite Perceptions
Some authors (Albert & Vaidman 1989; Albert 1990, 1992) have
raised an interesting objection concerning the emergence of definite
perceptions within Collapse Theories. The objection is based on the
fact that one can easily imagine situations leading to definite
perceptions, that nevertheless do not involve the displacement of a
large number of particles up to the stage of the perception itself.
These cases would then constitute actual measurement situations which
cannot be described by the GRW theory, contrary to what happens for
the idealized (according to the authors) situations considered in many
presentations of it, i.e., those involving the displacement of some
sort of pointer. To be more specific, the above papers consider a
‘measurement-like’ process whose output is the emission of
a burst of few photons triggered by the position in which a particle
hits a screen. This can easily be devised by considering, e.g., a
Stern-Gerlach set-up in which a spin 1/2 microsystem, according to the
value of its spin component, hits a fluorescent screen in different
places and excites a small number of atoms which subsequently decay,
emitting a small number of photons.
The argument goes as follows: if one triggers the apparatus with a
superposition of two spin states, since only a few atoms are excited,
since the excitations involve displacements which are smaller than the
characteristic localization distance of GRW, since GRW does not induce
reductions on photon states and, finally, since the photon states
immediately overlap, there is no way for the spontaneous localization
mechanism to become effective in suppressing the ensuing superposition
of the states ‘photons emerging from point \(A\) of the
screen’ and ‘photons emerging from point \(B\) of the
screen’. On the other hand, since the visual perception
threshold is quite low (about 6–7 photons), there is no doubt
that the naked eye of a human observer is sufficient to detect whether
the luminous spot on the screen is at \(A\) or at \(B\). The
conclusion follows: in the case under consideration no dynamical
reduction can take place and as a consequence no measurement is over,
no outcome is definite, up to the moment in which a conscious observer
perceives the spot.
Aicardi et al. (1991) have presented a detailed answer to this
criticism: it is agreed that in the considered case the superposition
persists for long times (actually the superposition must persist
since, being the system under consideration microscopic, one could
perform interference experiments which everybody would expect to
confirm quantum mechanics). However, to deal in the appropriate and
correct way with such a criticism, one has to consider all the systems
which enter into play (electron, screen, photons and brain) and the
universal dynamics governing all relevant physical processes. A simple
estimate of the number of ions which are involved in the transmission
of the nervous signal up to the higher virtual cortex makes perfectly
plausible that, in the process, a sufficient number of particles are
displaced by a sufficient spatial amount to satisfy the conditions
under which, according to the GRW theory, the suppression of the
superposition of the two nervous signals will take place within the
time scale of the perception.
This analysis by no means amounts to attributing a special role to the
conscious observer or to the perception process. The observer’s
brain is the only system present in the set-up in which a
superposition of two states involving different locations of a large
number of particles occurs. As such it is the only place where the
reduction can and actually must take place according to the theory. It
is extremely important to stress that if in place of the eye of a
human being one puts in front of the photons’ beam a spark chamber or
a device leading to the displacement of a macroscopic pointer, or
producing ink spots on a computer output, reduction will equally take
place. In the given example, the human nervous system is simply a
physical system, a specific assembly of particles, which performs the
same function as any other device, if no other such device interacts
with the photons before the human observer does. It follows that it is
incorrect and seriously misleading to claim that the GRW theory
requires a conscious observer in order for measurements to have a
definite outcome.
A further remark may be appropriate. The above analysis could be taken
by the reader as indicating a very naive and oversimplified attitude
towards the deep problem of the mind-brain correspondence. There is no
claim and no presumption that GRW allows a physicalist explanation of
conscious perception. It is only pointed out that, based on what we
know about the purely physical aspects of the process, one can state
that before the nervous pulses reach the higher visual cortex, the
conditions guaranteeing the suppression of one of the two signals are
verified. In brief, a consistent use of the dynamical reduction
mechanism in the above situation accounts for the definiteness of the
conscious perception, even in the extremely peculiar situation devised
by Albert and Vaidman.
11. The Interpretation of the Theory and its Primitive Ontologies
As stressed in the opening sentences of this contribution, the most
serious problem of standard quantum mechanics lies in its being
extremely successful in telling us about
what we observe
, but
being basically silent on
what there is
. This specific
feature is closely related to the probabilistic interpretation of the
statevector, combined with the completeness assumption of the theory.
Notice that what is under discussion is the probabilistic
interpretation, not the probabilistic character, of the theory. Also
collapse theories have a fundamentally stochastic character but, due
to their most specific feature, i.e., that of driving the statevector
of any individual physical system into appropriate and physically
meaningful manifolds, they allow for a different interpretation. One
could even say (if one wants to avoid that they too, as the standard
theory, speak only of
what we find
) that they
require
a different interpretation, one that accounts for our
perceptions at the appropriate, i.e., macroscopic, level.
We must admit that this opinion is not universally shared. According
to various authors, the ‘rules of the game’ embodied in
the precise formulation of the GRW and CSL theories represent all
there is to say about them. However, this cannot be the whole story:
stricter and more precise requirements than the purely formal ones
must be imposed for a theory to be taken seriously as a fundamental
description of natural processes (an opinion shared by J. Bell). This
request of going beyond the purely formal aspects of a theoretical
scheme has been denoted as (the necessity of specifying) the Primitive
Ontology (PO) of the theory in an extremely interesting paper (Allori,
et al. 2008). The fundamental requisite of the PO is that it should
make absolutely precise what the theory is fundamentally about.
This is not a new problem; as already mentioned it has been raised by
J. Bell since his first presentation of the GRW theory. Let me
summarize the terms of the debate. Given that the wavefunction of a
many-particle system lives in a (high-dimensional) configuration
space, which is not endowed with a direct physical meaning connected
to our experience of the world around us, Bell wanted to identify the
‘local beables’ of the theory, the quantities on which one
could base a description of the perceived reality in ordinary
three-dimensional space. In the specific context of QMSL, he (Bell
1987: 45) suggested that the ‘GRW jumps’, which we called
‘hittings’, could play this role. In fact they occur at
precise times in precise positions of the three-dimensional space. As
suggested in (Allori, et al. 2008) we will denote this position
concerning the PO of the GRW theory as the ‘flashes
ontology.’
However, later Bell himself suggested that the most natural
interpretation of the wavefunction in the context of a collapse theory
would be that it describes the ‘density […] of
stuff’ in the 3N-dimensional configuration space (Bell 1990:
30), the natural mathematical framework for describing a system of
\(N\) particles. Allori et al. (2008) appropriately have pointed out
that this position amounts to avoiding commitment about the PO
ontology of the theory and, consequently, to leaving vague the precise
and meaningful connections it permits to be established between the
mathematical description of the unfolding of physical processes and
our perception of them.
The interpretation which, in our opinion, is most appropriate for
collapse theories, has been proposed in (Ghirardi, Grassi, &
Benatti 1995) and has been referred in Allori et al. 2008 as
‘the mass density ontology’. Let us briefly describe
it.
First of all, various investigations (Pearle & Squires 1994) had
made clear that QMSL and CSL needed a modification, i.e., the
characteristic localization frequency of the elementary constituents
of matter had to be made proportional to the mass characterizing the
particle under consideration. In particular, the original frequency
for the hitting processes \(f = 10^{-16}\) sec\(^{-1}\) is the one
characterizing the nucleons, while, e.g., electrons would suffer
hittings with a frequency reduced by about 2000 times. Unfortunately
we have no space to discuss here the physical reasons which make this
choice appropriate; we refer the reader to the above paper, as well as
to the detailed analysis by Peruzzi and Rimini (2000). With this
modification, what the nonlinear dynamics strives to make
‘objectively definite’ is the mass distribution in the
whole universe. Second, a deep critical reconsideration (Ghirardi,
Grassi, & Benatti 1995) has made evident how the concept of
‘distance’ that characterizes the Hilbert space is
inappropriate in accounting for the similarity or difference between
macroscopic situations. Just to give a convincing example, consider
three states \(\ket{h} , \ket{h^*}\) and \(\ket{t}\) of a macrosystem
(let us say a massive macroscopic bulk of matter), the first
corresponding to its being located here, the second to its having the
same location but one of its atoms (or molecules) being in a state
orthogonal to the corresponding state in \(\ket{h}\), and the third
having exactly the same internal state of the first but being
differently located (there). Then, despite the fact that the first two
states are indistinguishable from each other at the macrolevel, while
the first and the third correspond to completely different and
directly perceivable situations, the Hilbert space distance between
\(\ket{h}\) and \(\ket{h^*}\), is equal to that between \(\ket{h}\)
and \(\ket{t}\).
When the localization frequency is related to the mass of the
constituents, then, in completely generality (i.e., even when one is
dealing with a body which is not almost rigid, such as a gas or a
cloud), the mechanism leading to the suppression of the superpositions
of macroscopically different states is fundamentally governed by the
the integral of the squared differences of the mass densities
associated to the two superposed states. Actually, in the original
paper the mass density at a point was identified with its average over
the characteristic volume of the theory, i.e., \(10^{-15}\) cm\(^3\)
around that point. It is however easy to convince oneself that there
is no need to do so and that the mass density at any point, directly
identified by the statevector (see below), is the appropriate quantity
on which to base an appropriate ontology. Accordingly, we take the
following attitude: what the theory is about, what is real ‘out
there’ at a given space point \(\boldsymbol{x}\), is just a
field, i.e., a variable \(m(\mathbf{x},t)\) given by the expectation
value of the mass density operator \(M(\boldsymbol{x})\) at
\(\boldsymbol{x}\) obtained by multiplying the mass of any kind of
particle times the number density operator for the considered type of
particle and summing over all possible types of particles which can be
present:
\[\begin{align}
\tag{7}
m(\boldsymbol{x},t) &= \langle F,t \mid M(\boldsymbol{x}) \mid F,t
\rangle; \\ M(\boldsymbol{x}) &= {\sum}_{(k)}
m_{(k)}a^*_{(k)}(\boldsymbol{x})a_{(k)}(\boldsymbol{x}).
\end{align}
\]
Here \(\ket{F,t}\) is the statevector characterizing the system at the
given time, and \(a^*_{(k)}(\boldsymbol{x})\) and
\(a_{(k)}(\boldsymbol{x})\) are the creation and annihilation
operators for a particle of type \(k\) at point \(\boldsymbol{x}\). It
is obvious that within standard quantum mechanics such a function
cannot be endowed with any objective physical meaning due to the
occurrence of linear superpositions which give rise to values that do
not correspond to what we find in a measurement process or what we
perceive. In the case of GRW or CSL theories, if one considers only
the states allowed by the dynamics one can give a description of the
world in terms of \(m(\boldsymbol{x},t)\), i.e., one recovers a
physically meaningful account of physical reality in the usual
3-dimensional space and time. To illustrate this crucial point we
consider, first of all, the embarrassing situation of a macroscopic
object in the superposition of two differently located position
states. We have then simply to recall that in a collapse model
relating reductions to mass density differences, the dynamics
suppresses in extremely short times the embarrassing superpositions of
such states to recover the mass distribution corresponding to our
perceptions. Let us come now to a microsystem and let us consider the
equal weight superposition of two states \(\ket{h}\) and \(\ket{t}\)
describing a microscopic particle in two different locations. Such a
state gives rise to a mass distribution corresponding to 1/2 of the
mass of the particle in the two considered space regions. This seems,
at first sight, to contradict what is revealed by any measurement
process. But in such a case we know that the theory implies that the
dynamics running all natural processes within GRW ensures that
whenever one tries to locate the particle they will always find it in
a definite position, e.g., one and only one of the Geiger counters
which might be triggered by the passage of the proton will fire, just
because a superposition of ‘a counter which has fired’ and
‘one which has not fired’ is dynamically forbidden.
This analysis shows that one can consider at all levels (the micro and
the macroscopic ones) the field \(m(\mathbf{x},t)\) as accounting for
‘what is out there’, as originally suggested by
Schrödinger with his realistic interpretation of the square of
the wave function of a particle as representing the
‘fuzzy’ character of the mass (or charge) of the particle.
Obviously, within standard quantum mechanics such a position cannot be
maintained because
wavepackets diffuse, and with the passage of time become infinitely
extended … but however far the wavefunction has extended, the
reaction of a detector … remains spotty (Bell 1990: 39).
As we hope to have made
clear, the picture is radically different when one takes into account
the new dynamics which succeeds perfectly in reconciling the spread
and sharp features of the wavefunction and of the detection process,
respectively.
It is also extremely important to stress that, by resorting to the
quantity (7) one can define an appropriate ‘distance’
between two states as the integral over the whole 3-dimensional space
of the square of the difference of \(m(\boldsymbol{x},t)\) for the two
given states, a quantity which turns out to be perfectly appropriate
to ground the concept of macroscopically similar or distinguishable
Hilbert space states. In turn, this distance can be used as a basis to
define a sensible psychophysical correspondence within the theory.
12. The Problem of the Tails of the Wave Function
There has been a lively debate around a problem which has its origin,
according to some of the authors which have raised it, in the fact
that even though the localization process which corresponds to
multiplying the wave function times a Gaussian, thus leading to wave
functions strongly peaked around the position of the hitting, they
allow nevertheless the final wavefuntion to be different from zero
over the whole space. The first criticism of this kind was raised by
A. Shimony (1990) and can be summarized by his sentence,
[one should not] tolerate“tails” which are so broad that
different parts [...] can be discriminated by the senses, even if very
low probability amplitude is assigned to the tail (1990: 53)
After a localization of a macroscopic system, typically the pointer of
the apparatus, its centre of mass will be associated to a wave
function which is different from zero over the whole space. If one
adopts the probabilistic interpretation of the standard theory, this
means that even when the measurement process is over, there is a
nonzero (even though extremely small) probability of finding its
pointer in an arbitrary position, instead of the one corresponding to
the registered outcome. This is taken as unacceptable, as indicating
that the DRP does not actually overcome the macro-objectification
problem.
Let us state immediately that the (alleged) problem arises entirely
from keeping the standard interpretation of the wave function
unchanged, in particular assuming that its squared modulus gives the
probability density of the position variable. However, as we have
discussed in the previous section, there are much more serious reasons
of principle which require to abandon the probabilistic interpretation
and replace it either with the ‘flash ontology’, or with
the ‘ mass density ontology’ which we have discussed
above.
Before entering into a detailed discussion of this subtle point we
need to focus the problem better. Suppose one adopts, for the moment,
the conventional quantum position. We agree that, within such a
framework, the fact that wave functions never have strictly compact
spatial support can be considered puzzling. However this is an
unavoidable problem arising directly from the mathematical features
(spreading of wave functions) and from the probabilistic
interpretation of the theory, and not at all a problem peculiar to
dynamical reduction models. Indeed, the fact that, e.g., the wave
function of the center of mass of a pointer or of a table has not a
compact support has never been taken to be a problem for standard
quantum mechanics. When, e.g., the center of mass of a table is
extremely well peaked around a given point in space, it has always
been accepted that it describes a table located at some position, and
that this corresponds in some way to our perception of it. It is
obviously true that, for the given wave function, the quantum rules
entail that if a measurement were performed the table could be found
(with an extremely small probability) to be kilometers far away, but
this
is not
the measurement or the macro-objectification
problem of the standard theory. The latter concerns a completely
different situation, i.e., that in which one is confronted with a
superposition with comparable weights of two macroscopically separated
wave functions, both of which possess tails (i.e., have non-compact
support) but are appreciably different from zero only in far-away
narrow intervals. This is the really embarrassing situation which
conventional quantum mechanics is unable to make understandable. To
which perception of the position of the pointer (of the table) does
this wave function correspond?
Within GRW, the superposition of two states which, when considered
individually, are assumed to lead to different and definite
perceptions of macroscopic locations, are dynamically forbidden. If
some process tends to produce such superpositions, then the reducing
dynamics induces the localization of the centre of mass (the
associated wave function being appreciably different from zero only in
a narrow and precise interval). Correspondingly, the possibility
arises of attributing to the system the property of being in a
definite place and thus of accounting for our definite perception of
it. Summarizing, we stress once more that the criticism about the
tails as well as the requirement that the appearance of
macroscopically extended (even though extremely small) tails be
strictly forbidden is exclusively motivated by uncritically committing
oneself to the probabilistic interpretation of the theory, even for
what concerns the psycho-physical correspondence: when this position
is taken, states assigning non-exactly vanishing probabilities to
different outcomes of position measurements should correspond to
ambiguous perceptions about these positions. Since neither within the
standard formalism nor within the framework of dynamical reduction
models a wave function can have compact support, taking such a
position leads to conclude that it is just the linear character of the
Hilbert space description of physical systems which has to be given
up.
It ought to be stressed that there is nothing in the GRW theory which
forbids or makes problematic to assume that the localization function
has compact support, but it also has to be noted that following this
line would be totally useless: since the evolution equation contains
the kinetic energy term, any function, even if it has compact support
at a given time, will instantaneously spread, acquiring a tail
extending over the whole space. If one sticks to the probabilistic
interpretation and one accepts the completeness of the description of
the states of physical systems in terms of the wave function, the tail
problem cannot be avoided.
The solution to the tails problem can only derive from abandoning
completely the probabilistic interpretation and from adopting a more
physical and realistic interpretation relating ‘what is out
there’ to, e.g., the mass density distribution over the whole
universe. In this connection, the following example will be
instructive. Take a massive sphere of normal density and mass of about
1 kg. Classically, the mass of this body would be totally concentrated
within the radius of the sphere, call it \(r\). In QMSL, after the
extremely short time interval in which the collapse dynamics leads to
a ‘regime’ situation, and if one considers a sphere with
radius \(r + 10^{-5}\) cm, the integral of the mass density over the
rest of space turns out to be an incredibly small fraction (of the
order of 1 over 10 to the power \(10^{15})\) of the mass of a single
proton. In such conditions, it seems quite legitimate to claim that
the macroscopic body is localised within the sphere.
However, also this quite reasonable conclusion has been questioned and
it has been claimed (Lewis 1997), that the very existence of the tails
implies that the enumeration principle (i.e., the fact that the claim
‘particle 1 is within this box & particle 2 is within this
box & … & particle \(n\) is within this box &
no other particle is within this box’ implies the claim
‘there are \(n\) particles within this box’) does not
hold, if one takes seriously the mass density interpretation of
collapse theories. This paper has given rise to a long debate which
would be inappropriate to reproduce here.
We conclude this brief analysis by stressing once more that, in our
opinion, all the disagreements and the misunderstandings concerning
this problem have their origin in the fact that the idea that the
probabilistic interpretation of the wave function must be abandoned
has not been fully accepted by the authors who find some difficulties
in the proposed mass density interpretation of the Collapse Theories.
For a more recent reconsideration of the problem we refer the reader
to the paper by Lewis (2003).
13. The Status of Collapse Models and Recent Positions about them
We recall that, as stated in Section 3, the macro-objectification
problem has been at the centre of the most lively and most challenging
debate originated by the quantum view of natural processes. According
to the majority of those who adhere to the orthodox position such a
problem does not deserve a particular attention: classical concepts
are a logical prerequisite for the very formulation of quantum
mechanics and, consequently, the measurement process itself, the
dividing line between the quantum and the classical world, cannot and
must not be investigated, but simply accepted. This position has been
lucidly summarized by J. Bell himself:
Making a virtue of necessity and influenced by positivistic and
instrumentalist philosophies, many came to hold not only that it is
difficult to find a coherent picture but that it is wrong to look for
one—if not actually immoral then certainly unprofessional.
(1981: 45)
The situation has seen many changes in the course of time, and the
necessity of making a clear distinction between what is quantum and
what is classical has given rise to many proposals for ‘easy
solutions’ to the problem which are based on the possibility,
for all practical purposes
(FAPP), of locating the splitting
between these two faces of reality at different levels.
Then came Bohmian mechanics, a theory which has made clear, in a lucid
and perfectly consistent way, that there is no reason of principle to
require a dichotomic description of the world. A universal dynamical
principle runs all physical processes and even though ‘it
completely agrees with standard quantum predictions’, it
accounts for the standard wave-packet reduction in micro-macro
interactions as well as the classical behaviour of macroscopic
objects.
As we have mentioned, the other consistent proposal, at the
nonrelativistic level, of a conceptually satisfactory solution of the
macro-objectification problem is represented by the Collapse Theories
which are the subject of these pages. Contrary to Bohmian mechanics,
they are rival to quantum mechanics, since they make different
predictions (even though quite difficult to put into evidence)
concerning various physical processes.
A common criticism makes reference to the fact that within any
collapse model the ensuing dynamics for the statistical operator can
be considered as the reduced dynamics deriving from a unitary (and,
consequently, essentially a standard quantum) dynamics for the states
of an enlarged Hilbert space of a composite quantum system \(S+E\)
involving, besides the physical system \(S\) of interest, an ancilla
\(E\) whose degrees of freedom are completely unaccessible. Due to the
quantum dynamical semigroup nature of the evolution equation for the
statistical operator, any GRW-like model can always be seen as a
phenomenological model deriving from a standard quantum evolution on a
larger Hilbert space. In this way, the unitary deterministic evolution
characterizing quantum mechanics would be fully restored.
Apart from the obvious remark that such a critical attitude completely
fails to grasp the most important feature of collapse theories, i.e.,
of dealing with individual quantum systems and not with statistical
ensembles and of yielding a perfectly satisfactory description,
matching our perceptions concerning
individual macroscopic
systems
, invoking an unaccessible ancilla to account for the
nonlinear and stochastic character of GRW-type theories is once more a
purely verbal way of avoiding facing the real puzzling aspects of the
quantum description of macroscopic systems.
Other reasons for ignoring the dynamical reduction program have been
put forward within the quantum information community. We will not
spend too much time in analyzing and discussing the new position about
the foundational issues which have motivated the elaboration of
collapse theories. The crucial fact is that, from this perspective,
one takes the theory not to be about something real ‘occurring
out there’ in a real word, but simply about information. This
point is made extremely explicit by Zeilinger (2002: 252):
information is the most basic notion of quantum mechanics, and it is
information about possible measurement results that is represented in
the quantum state. Measurement results are nothing more than states of
the classical apparatus used by the experimentalist. The quantum
system then is nothing other than the consistently constructed
referent of the information represented in the quantum state.
It is clear that if one takes such a position almost all motivations
to be worried by the measurement problem disappear, and with them the
reasons to work out what Bell has denoted as ‘an exact version
of quantum mechanics’. The most appropriate reply to this type
of criticisms is to recall that J. Bell (1990) has included
‘information’ among the words which must have no place in
a formulation with any pretension to physical precision. In particular
he has stressed that one cannot even mention information unless one
has given a precise answer to the two following questions:
Whose
information?
and
Information about what?
A much more serious attitude is to call attention, as many serious
authors do, to the fact that since collapse theories represent rival
theories with respect to standard quantum mechanics they lead to the
identification of experimental situations which would allow, in
principle, crucial tests to discriminate between the two. As we have
discussed above, presently, fully discriminating tests are not out of
reach.
14. Summary
We presented a comprehensive picture of the ideas, the implications,
the achievements and the problems of the DRP. We conclude by stressing
once more our position with respect to Collapse Theories. Their
interest derives entirely from the fact that they have given some
hints about a possible way out from the difficulties characterizing
standard quantum mechanics, by proving that explicit and precise
models can be worked out, which agree with all known predictions of
the theory and nevertheless allow, on the basis of a universal
dynamics governing all natural processes, to overcome in a
mathematically clean and precise way the basic problems of the
standard theory. In particular, Collapse Models show how one can work
out a theory that makes perfectly legitimate to take a macrorealistic
position about natural processes, without contradicting any of the
experimentally tested predictions of standard quantum mechanics.
Finally, they might give precise hints about where to look in order to
put into evidence, experimentally, possible violations of the
superposition principle.
Bibliography
Adler, Stephen L., 2003, “Why Decoherence Has Not Solved the
Measurement Problem: A Response to P.W. Anderson”,
Studies
in History and Philosophy of Science Part B: Studies in History and
Philosophy of Modern Physics
, 34(1): 135–142.
doi:10.1016/S1355-2198(02)00086-2
–––, 2007, “Lower and Upper Bounds on CSL
Parameters from Latent Image Formation and IGM~heating”,
Journal of Physics A: Mathematical and Theoretical
, 40(44):
13501–13501. doi:10.1088/1751-8121/40/44/C01
Adler, Stephen L. and Angelo Bassi, 2007, “Collapse Models
with Non-White Noises”,
Journal of Physics A: Mathematical
and Theoretical
, 40(50): 15083–15098.
doi:10.1088/1751-8113/40/50/012
–––, 2008, “Collapse Models with Non-White
Noises: II. Particle-Density Coupled Noises”,
Journal of
Physics A: Mathematical and Theoretical
, 41(39): 395308.
doi:10.1088/1751-8113/41/39/395308
Adler, Stephen L., Angelo Bassi, and Sandro Donadi, 2013,
“On Spontaneous Photon Emission in Collapse Models”,
Journal of Physics A: Mathematical and Theoretical
, 46(24):
245304. doi:10.1088/1751-8113/46/24/245304
Adler, Stephen L., Angelo Bassi, and Emiliano Ippoliti, 2005,
“Towards Quantum Superpositions of a Mirror: An Exact Open
Systems Analysis—Calculational Details”,
Journal of
Physics A: Mathematical and General
, 38(12): 2715–2727.
doi:10.1088/0305-4470/38/12/013
Adler, Stephen L. and Fethi M. Ramazanoglu, 2009,
“Photon-Emission Rate from Atomic Systems in the CSL
Model”,
Journal of Physics A: Mathematical and
Theoretical
, 42(10): 109801.
doi:10.1088/1751-8121/42/10/109801
Aicardi, F., A. Borsellino, G. C. Ghirardi, and R. Grassi, 1991,
“Dynamical Models for State-Vector Reduction: Do They Ensure
That Measurements Have Outcomes?”,
Foundations of Physics
Letters
, 4(2): 109–128. doi:10.1007/BF00666047
Albert, David Z., 1990, “On the Collapse of the Wave
Function”, in Miller 1990: 153–166.
–––, 1992,
Quantum Mechanics and
Experience
, Cambridge, MA: Harvard University Press.
Albert, David Z. and Lev Vaidman, 1989, “On a Proposed
Postulate of State-Reduction”,
Physics Letters A
,
139(1–2): 1–4. doi:10.1016/0375-9601(89)90595-1
Allori, Valia, Sheldon Goldstein, Roderich Tumulka, and Nino
Zanghi, 2008, “On the Common Structure of Bohmian Mechanics and
the Ghirardi-Rimini-Weber Theory: Dedicated to GianCarlo Ghirardi on
the Occasion of His 70th Birthday”,
The British Journal for
the Philosophy of Science
, 59(3): 353–389.
doi:10.1093/bjps/axn012
Arndt, Markus, Olaf Nairz, Julian Vos-Andreae, Claudia Keller,
Gerbrand van der Zouw, and Anton Zeilinger, 1999,
“Wave–Particle Duality of C60 Molecules”,
Nature
, 401(6754): 680–682. doi:10.1038/44348
Bahrami, M., S. Donadi, L. Ferialdi, A. Bassi, C. Curceanu, A. Di
Domenico, and B. C. Hiesmayr, 2013, “Are Collapse Models
Testable with Quantum Oscillating Systems? The Case of Neutrinos,
Kaons, Chiral Molecules”,
Scientific Reports
, 3(1):
art. 1952. doi:10.1038/srep01952
Bahrami, M., M. Paternostro, A. Bassi, and H. Ulbricht, 2014,
“Proposal for a Noninterferometric Test of Collapse Models in
Optomechanical Systems”,
Physical Review Letters
,
112(21): art. 210404 (5 pages).
doi:10.1103/PhysRevLett.112.210404
Bassi, Angelo, D.-A. Deckert, and L. Ferialdi, 2010,
“Breaking Quantum Linearity: Constraints from Human Perception
and Cosmological Implications”,
EPL (Europhysics
Letters)
, 92(5): art. 50006 (6 pages).
doi:10.1209/0295-5075/92/50006
Bassi, Angelo and S. Donadi, 2014, “Spontaneous Photon
Emission from a Non-Relativistic Free Charged Particle in Collapse
Models: A Case Study”,
Physics Letters A
, 378(10):
761–765. doi:10.1016/j.physleta.2014.01.002
Bassi, Angelo and Luca Ferialdi, 2009a, “Non-Markovian
Dynamics for a Free Quantum Particle Subject to Spontaneous Collapse
in Space: General Solution and Main Properties”,
Physical
Review A
, 80(1): art. 012116 (18 pages).
doi:10.1103/PhysRevA.80.012116
–––, 2009b, “Non-Markovian Quantum
Trajectories: An Exact Result”,
Physical Review
Letters
, 103(5): art. 050403 (4 pages).
doi:10.1103/PhysRevLett.103.050403
Bassi, Angelo and GianCarlo Ghirardi, 2000, “A General
Argument against the Universal Validity of the Superposition
Principle”,
Physics Letters A
, 275(5–6):
373–381. doi:10.1016/S0375-9601(00)00612-5
–––, 2001, “Counting Marbles: Reply to
Clifton and Monton”,
The British Journal for the Philosophy
of Science
, 52(1): 125–130. doi:10.1093/bjps/52.1.125
–––, 2002, “Dynamical Reduction Models
with General Gaussian Noises”,
Physical Review A
,
65(4): art. 042114 (10 pages). doi:10.1103/PhysRevA.65.042114
–––, 2003, “Dynamical Reduction
Models”,
Physics Reports
, 379(5–6):
257–426. doi:10.1016/S0370-1573(03)00103-0
Bassi, Angelo, Emiliano Ippoliti and Stephen L. Adler, 2005,
“Towards Quantum Superpositions of a Mirror: An Exact Open
System Analysis”,
Physical Review Letters
94,
030401.
Bassi, Angelo, Kinjalk Lochan, Seema Satin, Tejinder P. Singh, and
Hendrik Ulbricht, 2013, “Models of Wave-Function Collapse,
Underlying Theories, and Experimental Tests”,
Reviews of
Modern Physics
, 85(2): 471–527.
doi:10.1103/RevModPhys.85.471
Bedingham, Daniel J., 2011, “Relativistic State Reduction
Dynamics”,
Foundations of Physics
, 41(4):
686–704. doi:10.1007/s10701-010-9510-7
Bedingham, Daniel, Detlef Dürr, GianCarlo Ghirardi, Sheldon
Goldstein, Roderich Tumulka, and Nino Zanghì, 2014,
“Matter Density and Relativistic Models of Wave Function
Collapse”,
Journal of Statistical Physics
,
154(1–2): 623–631. doi:10.1007/s10955-013-0814-9
Bell, John Stewart, 1981, “Bertlmann’s Socks and the
Nature of Reality”,
Le Journal de Physique Colloques
,
42(C2): 41–62. doi:10.1051/jphyscol:1981202
–––, 1987, “Are There Quantum
Jumps?”, in
Schrödinger: Centenary Celebration of a
Polymath
, C. W. Kilmister (ed.), Cambridge: Cambridge University
Press, 41–52. doi:10.1017/CBO9780511564253.005
–––, 1989a, “Six Possible Worlds of
Quantum Mechanics”, in
Possible Worlds in Arts and Sciences;
Proceedings of the Nobel Symposium 65
, held August 1986,
Allén Sture (ed.), New York: de Gruyter, 359–373.
–––, 1989b, “Towards an Exact Quantum
mechanics”, in
Themes in Contemporary Physics II: Essays in
Honour of Julian Schwinger’s 70th Birthday
, S. Deser, R.J.
Finkelstein (eds.), Singapore: World Scientific: 1–26.
–––, 1989c [2007], “The Trieste Lecture of
John Stewart Bell”, printed in 2007, Angelo Bassi and GianCarlo
Ghirardi (eds.),
Journal of Physics A: Mathematical and
Theoretical
, 40(12): 2919–2933.
doi:10.1088/1751-8121/40/12/S02
–––, 1990, “Against
‘Measurement’”, in Miller 1990: 17–32.
Berndl, Karin, Detlef Dürr, Sheldon Goldstein, and Nino
Zanghì, 1996, “Nonlocality, Lorentz Invariance, and
Bohmian Quantum Theory”,
Physical Review A
, 53(4):
2062–2073. doi:10.1103/PhysRevA.53.2062
Bilardello, Marco, Sandro Donadi, Andrea Vinante, and Angelo
Bassi, 2016, “Bounds on Collapse Models from Cold-Atom
Experiments”,
Physica A: Statistical Mechanics and Its
Applications
, 462: 764–782.
doi:10.1016/j.physa.2016.06.134
Bohm, David, 1952, “A Suggested Interpretation of the
Quantum Theory in Terms of ‘Hidden’ Variables”,
Physical Review
,
I, 85(2): 166–179, doi:10.1103/PhysRev.85.166.
II, 85(2): 180–193, doi:10.1103/PhysRev.85.180.
Bohm, David and Jeffrey Bub, 1966, “A Proposed Solution of
the Measurement Problem in Quantum Mechanics by a Hidden Variable
Theory”,
Reviews of Modern Physics
, 38(3):
453–469. doi:10.1103/RevModPhys.38.453
Born, Max, 1971,
The Born-Einstein Letters: Correspondence
Between Albert Einstein and Max and Hedwig Born from 1916 to
1955
, Max Born (ed.), Irene Born (trans.), New York: Walter and
Co.
Brown, Harvey R., 1986, “The Insolubility Proof of the
Quantum Measurement Problem”,
Foundations of Physics
,
16(9): 857–870. doi:10.1007/BF00765334
Bub, Jeffrey, 1997,
Interpreting the Quantum World
,
Cambridge: Cambridge University Press.
Busch, Paul and Abner Shimony, 1996, “Insolubility of the
Quantum Measurement Problem for Unsharp Observables”,
Studies in History and Philosophy of Science Part B: Studies in
History and Philosophy of Modern Physics
, 27(4): 397–404.
doi:10.1016/S1355-2198(96)00012-3
Caiaffa, Matteo, Andrea Smirne, and Angelo Bassi, 2017,
“Stochastic Unraveling of Positive Quantum Dynamics”,
Physical Review A
, 95(6): art. 062101 (9 pages).
doi:10.1103/PhysRevA.95.062101
Carlesso, Matteo, Angelo Bassi, Paolo Falferi, and Andrea Vinante,
2016, “Experimental Bounds on Collapse Models from Gravitational
Wave Detectors”,
Physical Review D
, 94(12): 124036 (7
pages). doi:10.1103/PhysRevD.94.124036
Carlesso, Matteo, Andrea Vinante, and Angelo Bassi, 2018,
“Multilayer Test Masses to Enhance the Collapse Noise”,
Physical Review A
, 98(2): art. 022122 (9 pages).
doi:10.1103/PhysRevA.98.022122
Carlesso, Matteo, Mauro Paternostro, Hendrik Ulbricht, Andrea
Vinante, and Angelo Bassi, 2018, “Non-Interferometric Test of
the Continuous Spontaneous Localization Model Based on Rotational
Optomechanics”,
New Journal of Physics
, 20(8): art.
083022 (10 pages). doi:10.1088/1367-2630/aad863
Clifton, R. and B. Monton, 1999, “Discussion. Losing Your
Marbles in Wavefunction Collapse Theories”,
The British
Journal for the Philosophy of Science
, 50(4): 697–717.
doi:10.1093/bjps/50.4.697
–––, 2000, “Discussion. Counting Marbles
with ‘accessible’ Mass Density: A Reply to Bassi and
Ghirardi”,
The British Journal for the Philosophy of
Science
, 51(1): 155–164. doi:10.1093/bjps/51.1.155
Collett, Brian and Philip Pearle, 2003, “Wavefunction
Collapse and Random Walk”,
Foundations of Physics
,
33(10): 1495–1541. doi:10.1023/A:1026048530567
Conway, John H. and Simon Kochen, 2006a, “The Free Will
Theorem”,
Foundations of Physics
, 36(10):
1441–1473. doi:10.1007/s10701-006-9068-6
–––, 2007, “Reply to Comments of Bassi,
Ghirardi, and Tumulka on the Free Will Theorem”,
Foundations
of Physics
, 37(11): 1643–1647.
doi:10.1007/s10701-007-9173-1
–––, 2009, “The Strong Free Will
Theorem”,
Notices of the American Mathematical Society
,
56(2): 226–232.
Curceanu, C., B. C. Hiesmayr, and K. Piscicchia, 2015,
“X-Rays Help to Unfuzzy the Concept of Measurement”,
Journal of Advanced Physics
, 4(3): 263–266.
doi:10.1166/jap.2015.1193
Curceanu, C., S. Bartalucci, A. Bassi, M. Bazzi, S. Bertolucci, C.
Berucci, A. M. Bragadireanu, M. Cargnelli, A. Clozza, L. De Paolis, S.
Di Matteo, S. Donadi, A. D’Uffizi, J.-P. Egger, C. Guaraldo, M.
Iliescu, T. Ishiwatari, M. Laubenstein, J. Marton, E. Milotti, et al.,
2016, “Spontaneously Emitted X-Rays: An Experimental Signature
of the Dynamical Reduction Models”,
Foundations of
Physics
, 46(3): 263–268. doi:10.1007/s10701-015-9923-4
Cushing, James T. and Eman McMullin (eds), 1989,
Philosophical
Consequences of Quantum Theory: Reflections on Bell’s
Theorem
, Notre Dame, IN: University of Notre Dame Press.
Dowker, Fay and Isabelle Herbauts, 2004, “Simulating Causal
Wavefunction Collapse Models”,
Classical and Quantum
Gravity
, 21(12): 2963–2979.
doi:10.1088/0264-9381/21/12/011
Dowker, Fay and Joe Henson, 2004, “Spontaneous Collapse
Models on a Lattice”,
Journal of Statistical Physics
,
115(5/6): 1327–1339. doi:10.1023/B:JOSS.0000028061.97843.84
d’Espagnat, Benjamin, 1971,
Conceptual Foundations of
Quantum Mechanics
, Reading, MA: W.A. Benjamin.
Diósi, Lajos, 1988, “Quantum Stochastic Processes as
Models for State Vector Reduction”,
Journal of Physics A:
Mathematical and General
, 21(13): 2885–2898.
doi:10.1088/0305-4470/21/13/013
–––, 1990, “Relativistic Theory for
Continuous Measurement of Quantum Fields”,
Physical Review
A
, 42(9): 5086–5092. doi:10.1103/PhysRevA.42.5086
–––, 2015, “Testing Spontaneous
Wave-Function Collapse Models on Classical Mechanical
Oscillators”,
Physical Review Letters
, 114(5): art.
050403 (5 pages). doi:10.1103/PhysRevLett.114.050403
Dirac, Paul A.M., 1935,
Quantum Mechanics
, Oxford:
Clarendon Press, 2nd edition, 1935 (the WPR postulate was first
introduced in the 2nd edition); 1st edition, 1930, 3rd edition, 1947;
4th edition, 1958.
Donadi, Sandro and Angelo Bassi, 2014, “The Emission of
Electromagnetic Radiation from a Quantum System Interacting with an
External Noise: A General Result”,
Journal of Physics A:
Mathematical and Theoretical
, 48(3): art. 035305 (20 pages).
doi:10.1088/1751-8113/48/3/035305
Donadi, Sandro, Angelo Bassi, Catalina Curceanu, Antonio Di
Domenico, and Beatrix C. Hiesmayr, 2013, “Are Collapse Models
Testable via Flavor Oscillations?”,
Foundations of
Physics
, 43(7): 813–844. doi:10.1007/s10701-013-9720-x
Donadi, Sandro, Angelo Bassi, Luca Ferialdi, and Catalina
Curceanu, 2013, “The Effect of Spontaneous Collapses on Neutrino
Oscillations”,
Foundations of Physics
, 43(9):
1066–1089. doi:10.1007/s10701-013-9732-6
Donadi, Sandro, Dirk-André Deckert, and Angelo Bassi, 2014,
“On the Spontaneous Emission of Electromagnetic Radiation in the
CSL Model”,
Annals of Physics
, 340(1): 70–86.
doi:10.1016/j.aop.2013.10.009
Dove, Chris and Evan J. Squires, 1995, “Symmetric Versions
of Explicit Wavefunction Collapse Models”,
Foundations of
Physics
, 25(9): 1267–1282. doi:10.1007/BF02055332
Dürr, Detlef, Sheldon Goldstein, Karin Münch-Berndl, and
Nino Zanghì, 1999, “Hypersurface Bohm-Dirac
Models”,
Physical Review A
, 60(4): 2729–2736.
doi:10.1103/PhysRevA.60.2729
Eberhard, P. H., 1978, “Bell’s Theorem and the
Different Concepts of Locality”,
Il Nuovo Cimento B Series
11
, 46(2): 392–419. doi:10.1007/BF02728628
Eibenberger, Sandra, Stefan Gerlich, Markus Arndt, Marcel Mayor,
and Jens Tüxen, 2013, “Matter–Wave Interference of
Particles Selected from a Molecular Library with Masses Exceeding 10
000 Amu”,
Physical Chemistry Chemical Physics
, 15(35):
14696–14700. doi:10.1039/c3cp51500a
Fein, Yaakov Y., Philipp Geyer, Patrick Zwick, Filip Kiałka,
Sebastian Pedalino, Marcel Mayor, Stefan Gerlich, and Markus Arndt,
2019, “Quantum Superposition of Molecules beyond 25 KDa”,
Nature Physics
, 15(12): 1242–1245.

doi:10.1038/s41567-019-0663-9
Fine, Arthur, 1970, “Insolubility of the Quantum Measurement
Problem”,
Physical Review D
, 2(12): 2783–2787.
doi:10.1103/PhysRevD.2.2783
Fonda, L, G C Ghirardi, and A Rimini, 1978, “Decay Theory of
Unstable Quantum Systems”,
Reports on Progress in
Physics
, 41(4): 587–631.
doi:10.1088/0034-4885/41/4/003
Fu, Qijia, 1997, “Spontaneous Radiation of Free Electrons in
a Nonrelativistic Collapse Model”,
Physical Review A
,
56(3): 1806–1811. doi:10.1103/PhysRevA.56.1806
Gallis, Michael R. and Gordon N. Fleming, 1990,
“Environmental and Spontaneous Localization”,
Physical
Review A
, 42(1): 38–48. doi:10.1103/PhysRevA.42.38
Gerlich, Stefan, Lucia Hackermüller, Klaus Hornberger,
Alexander Stibor, Hendrik Ulbricht, Michael Gring, Fabienne Goldfarb,
Tim Savas, Marcel Müri, Marcel Mayor, and Markus Arndt, 2007,
“A Kapitza–Dirac–Talbot–Lau Interferometer for
Highly Polarizable Molecules”,
Nature Physics
, 3(10):
711–715. doi:10.1038/nphys701
Ghirardi, GianCarlo, 2000, “Local Measurements of Nonlocal
Observables and the Relativistic Reduction Process”,
Foundations of Physics
, 30(9): 1337–1385.
doi:10.1023/A:1026497632474
–––, 2007, “Some Reflections Inspired by
My Research Activity in Quantum Mechanics”,
Journal of
Physics A: Mathematical and Theoretical
, 40(12): 2891–2917.
doi:10.1088/1751-8113/40/12/S01
Ghirardi, Giancarlo and Renata Grassi, 1996, “Bohm’s
Theory Versus Dynamical Reduction”, in
Bohmian Mechanics and
Quantum Theory: An Appraisal
, James T. Cushing, Arthur Fine, and
Sheldon Goldstein (eds.), (Boston Studies in the Philosophy of Science
184), Dordrecht: Springer Netherlands, 353–377.
doi:10.1007/978-94-015-8715-0_25
Ghirardi, GianCarlo, Renata Grassi, and F. Benatti, 1995,
“Describing the Macroscopic World: Closing the Circle within the
Dynamical Reduction Program”,
Foundations of Physics
,
25(1): 5–38. doi:10.1007/BF02054655
Ghirardi, GianCarlo, Renata Grassi, J. Butterfield, and G. N.
Fleming, 1993, “Parameter Dependence and Outcome Dependence in
Dynamical Models for State Vector Reduction”,
Foundations of
Physics
, 23(3): 341–364. doi:10.1007/BF01883717
Ghirardi, GianCarlo, Renata Grassi, and Philip Pearle, 1990,
“Relativistic Dynamical Reduction Models: General Framework and
Examples”,
Foundations of Physics
, 20(11):
1271–1316. doi:10.1007/BF01883487
Ghirardi, GianCarlo, Philip Pearle, and Alberto Rimini, 1990,
“Markov Processes in Hilbert Space and Continuous Spontaneous
Localization of Systems of Identical Particles”,
Physical
Review A
, 42(1): 78–89. doi:10.1103/PhysRevA.42.78
Ghirardi, GianCarlo and Alberto Rimini, 1990, “Old and New
Ideas in the Theory of Quantum Measurement”, in Miller 1990:
167–192.
Ghirardi, GianCarlo, Alberto Rimini, and Tullio Weber, 1980,
“A General Argument against Superluminal Transmission through
the Quantum Mechanical Measurement Process”,
Lettere al
Nuovo Cimento
, 27(10): 293–298. doi:10.1007/BF02817189
–––, 1986, “Unified Dynamics for
Microscopic and Macroscopic Systems”,
Physical Review
D
, 34(2): 470–491. doi:10.1103/PhysRevD.34.470
Ghirardi, GianCarlo and Raffaele Romano, 2014, “Collapse
Models and Perceptual Processes”,
Journal of Physics:
Conference Series
, 504: art. 012022 (14 pages).
doi:10.1088/1742-6596/504/1/012022
Gisin, Nicolas, 1984a, “Quantum Measurements and Stochastic
Processes”,
Physical Review Letters
, 52(19):
1657–1660. doi:10.1103/PhysRevLett.52.1657
–––, 1984b, “Gisin Responds”,
Physical Review Letters
, 53(18): 1776–1776.
doi:10.1103/PhysRevLett.53.1776
–––, 1989, “Stochastic Quantum Dynamics
and Relativity”,
Helvetica Physica Acta
, 62(4):
363–371.
Goldstein, Sheldon and Roderich Tumulka, 2003, “Opposite
Arrows of Time Can Reconcile Relativity and Nonlocality”,
Classical and Quantum Gravity
, 20(3): 557–564.
doi:10.1088/0264-9381/20/3/311
Goldstein, Sheldon, Daniel V. Tausk, Roderick Tumulka, and Nino
Zanghi, 2010, “What does the Free Will Theorem Actually
Prove?”,
Notice of the American Mathematical Society
,
57(11): 1451–1453.
Gottfried, Kurt, 2000, “Does Quantum Mechanics Carry the
Seeds of its own Destruction?”, in
Quantum Reflections
,
John Ellis and Daniele Amati (eds.), Cambridge: Cambridge University
Press, 165–185.
Großardt, André, James Bateman, Hendrik Ulbricht, and
Angelo Bassi, 2016, “Optomechanical Test of the
Schrödinger-Newton Equation”,
Physical Review D
,
93(9): art. 096003 (6 pages). doi:10.1103/PhysRevD.93.096003
Hackermüller, Lucia, Klaus Hornberger, Björn Brezger,
Anton Zeilinger, and Markus Arndt, 2004, “Decoherence of Matter
Waves by Thermal Emission of Radiation”,
Nature
,
427(6976): 711–714. doi:10.1038/nature02276
Helou, Bassam, B.J.J. Slagmolen, David E. McClelland, and
Yanbei Chen, 2017, “LISA Pathfinder Appreciably Constrains
Collapse Models”,
Physical Review D
, 95(8): art.
084054. doi:10.1103/PhysRevD.95.084054
Horton, George and Chris Dewdney, 2001, “A Non-Local,
Lorentz-Invariant, Hidden-Variable Interpretation of Relativistic
Quantum Mechanics Based on Particle Trajectories”,
Journal
of Physics A: Mathematical and General
, 34(46): 9871–9878.
doi:10.1088/0305-4470/34/46/310
Jarrett, Jon P., 1984, “On the Physical Significance of the
Locality Conditions in the Bell Arguments”,
Noûs
,
18(4): 569–589. doi:10.2307/2214878
Joos, Erich, H. Dieter Zeh, Claus Kiefer, Domenico Giulini,
Joachim Kupsch, and Ion-Olimpiu Stamatescu, 2003,
Decoherence and
the Appearance of a Classical World in Quantum Theory
, Berlin,
Heidelberg: Springer Berlin Heidelberg.
doi:10.1007/978-3-662-05328-7
Kaltenbaek, Rainer, Markus Aspelmeyer, Peter F Barker, Angelo
Bassi, James Bateman, Kai Bongs, Sougato Bose, Claus Braxmaier,
Časlav Brukner, Bruno Christophe, Michael Chwalla,
Pierre-François Cohadon, Adrian Michael Cruise, Catalina
Curceanu, Kishan Dholakia, Lajos Diósi, Klaus Döringshoff,
Wolfgang Ertmer, Jan Gieseler, Norman Gürlebeck, et al., 2016,
“Macroscopic Quantum Resonators (MAQRO): 2015 Update”,
EPJ Quantum Technology
, 3: art. 5.
doi:10.1140/epjqt/s40507-016-0043-7
Kaltenbaek, Rainer, Gerald Hechenblaikner, Nikolai Kiesel, Oriol
Romero-Isart, Keith C. Schwab, Ulrich Johann, and Markus Aspelmeyer,
2012, “Macroscopic Quantum Resonators (MAQRO): Testing Quantum
and Gravitational Physics with Massive Mechanical Resonators”,
Experimental Astronomy
, 34(2): 123–164.
doi:10.1007/s10686-012-9292-3
Komori, Kentaro, Yutaro Enomoto, Ching Pin Ooi, Yuki Miyazaki,
Nobuyuki Matsumoto, Vivishek Sudhir, Yuta Michimura, and Masaki Ando,
2020, “Attonewton-Meter Torque Sensing with a Macroscopic
Optomechanical Torsion Pendulum”,
Physical Review A
,
101(1): art. 011802 (5 pages). doi:10.1103/PhysRevA.101.011802
Laloë, Franck, William J. Mullin, and Philip Pearle, 2014,
“Heating of Trapped Ultracold Atoms by Collapse Dynamics”,
Physical Review A
, 90(5): art. 052119 (16 pages).
doi:10.1103/PhysRevA.90.052119
Lewis, Peter J., 1997, “Quantum Mechanics, Orthogonality,
and Counting”,
The British Journal for the Philosophy of
Science
, 48(3): 313–328. doi:10.1093/bjps/48.3.313
–––, 2003, “Four Strategies for Dealing
with the Counting Anomaly in Spontaneous Collapse Theories of Quantum
Mechanics”,
International Studies in the Philosophy of
Science
, 17(2): 137–142.
doi:10.1080/0269859031000160603
Marshall, William, Christoph Simon, Roger Penrose, and Dik
Bouwmeester, 2003, “Towards Quantum Superpositions of a
Mirror”,
Physical Review Letters
, 91(13): art. 130401
(4 pages). doi:10.1103/PhysRevLett.91.130401
Maudlin, Tim, 2011,
Quantum Non-Locality and Relativity:
Metaphysical Intimations of Modern Physics
, Oxford, UK:
Wiley-Blackwell. doi:10.1002/9781444396973
Miller, Arthur I. (ed.), 1990,
Sixty-Two Years of Uncertainty:
Historical, Philosophical, and Physical Inquiries into the Foundations
of Quantum Mechanics
, (NATO ASI Series, Series B, Physics 226),
New York: Plenum Press.
Nicrosini, Oreste and Alberto Rimini, 2003, “Relativistic
Spontaneous Localization: A Proposal”,
Foundations of
Physics
, 33(7): 1061–1084. doi:10.1023/A:1025685801431
Nimmrichter, Stefan, Klaus Hornberger, and Klemens Hammerer, 2014,
“Optomechanical Sensing of Spontaneous Wave-Function
Collapse”,
Physical Review Letters
, 113(2): art. 020405
(5 pages). doi:10.1103/PhysRevLett.113.020405
Pais, Abraham, 1982,
“Subtle Is the Lord”: The
Science and the Life of Albert Einstein
, Oxford: Oxford
University Press.
Pearle, Philip, 1976, “Reduction of the State Vector by a
Nonlinear Schrödinger Equation”,
Physical Review
D
, 13(4): 857–868. doi:10.1103/PhysRevD.13.857
–––, 1979, “Toward Explaining Why Events
Occur”,
International Journal of Theoretical Physics
,
18(7): 489–518. doi:10.1007/BF00670504
–––, 1989, “Combining Stochastic Dynamical
State-Vector Reduction with Spontaneous Localization”,
Physical Review A
, 39(5): 2277–2289.
doi:10.1103/PhysRevA.39.2277
–––, 1990, “Toward a Relativistic Theory
of Statevector Reduction”, in Miller 1990: 193–214.
–––, 1999a, “Collapse Models”, in
Open Systems and Measurement in Relativistic Quantum Theory
,
Heinz-Peter Breuer and Francesco Petruccione (eds.), (Lecture Notes in
Physics 526), Berlin: Springer Berlin Heidelberg, 195–234.
doi:10.1007/BFb0104404
–––, 1999b, “Relativistic Collapse Model
with Tachyonic Features”,
Physical Review A
, 59(1):
80–101. doi:10.1103/PhysRevA.59.80
Pearle, Philip and Euan Squires, 1994, “Bound State
Excitation, Nucleon Decay Experiments and Models of Wave Function
Collapse”,
Physical Review Letters
, 73(1): 1–5.
doi:10.1103/PhysRevLett.73.1
Penrose, Roger, 1989,
The Emperor’s New Mind
,
Oxford: Oxford University Press.
Peruzzi, Giulio and Alberto Rimini, 2000, “Compoundation
Invariance and Bohmian Mechanics”,
Foundations of
Physics
, 30(9): 1445–1472. doi:10.1023/A:1026405901523
Piscicchia, Kristian, Angelo Bassi, Catalina Curceanu, Raffaele
Grande, Sandro Donadi, Beatrix Hiesmayr, and Andreas Pichler, 2017,
“CSL Collapse Model Mapped with the Spontaneous
Radiation”,
Entropy
, 19(7): art. 319.
doi:10.3390/e19070319
Rae, A. I. M., 1990, “Can GRW Theory Be Tested by
Experiments on SQUIDS?”,
Journal of Physics A: Mathematical
and General
, 23(2): L57–L60.
doi:10.1088/0305-4470/23/2/003
Rimini, Alberto, 1995, “Spontaneous Localization and
Superconductivity”, in
Advances in Quantum Phenomena
,
Enrico G. Beltrametti and Jean-Marc Lévy-Leblond (eds.), (NATO
ASI Series 347), Boston, MA: Springer US, 321–333.
doi:10.1007/978-1-4615-1975-1_19
Schilpp, Paul Arthur (ed.), 1949,
Albert Einstein:
Philosopher-Scientist
, New York: Tudor.
Schrinski, Björn, Benjamin A. Stickler, and Klaus Hornberger,
2017, “Collapse-Induced Orientational Localization of Rigid
Rotors [Invited]”,
Journal of the Optical Society of America
B
, 34(6): C1–C7. doi:10.1364/JOSAB.34.0000C1
Schrödinger, E., 1935, “Die gegenwärtige Situation
in der Quantenmechanik”,
Die Naturwissenschaften
,
23(50): 844–849. doi:10.1007/BF01491987
Shimony, Abner, 1974, “Approximate Measurement in Quantum
Mechanics. II”,
Physical Review D
, 9(8):
2321–2323. doi:10.1103/PhysRevD.9.2321
–––, 1984, “Controllable and
Uncontrollable Non-Locality”, in
Proceedings of the
International Symposium: Foundations of Quantum Mechanics in the Light
of New Technology
, S. Kamefuchi et al. (eds.), Tokyo: Physical
Society of Japan: 225–230.
–––, 1989, “Search for a Worldview Which
Can Accommodate Our Knowledge of Microphysics”,
in
Philosophical consequences of Quantum Theory: Reflections on
Bell’s Theorem
, J.T. Cushing and E. McMullin (eds.),
University of Notre Dame Press: 25–37.
–––, 1990, “Desiderata for Modified
Quantum Dynamics”, in
PSA 1990: Proceedings of the Biennial
Meeting of the Philosophy of Science Association
, Volume 2, A.
Fine, M. Forbes and L. Wessels (eds), East Lansing, MI: Philosophy of
Science Association: 49–59.
Squires, Euan J., 1991, “Wavefunction Collapse and
Ultraviolet Photons”,
Physics Letters A
, 158(9):
431–432. doi:10.1016/0375-9601(91)90452-E
Stapp, Henry P., 1989, “Quantum Nonlocality and the
Description of Nature”, in
Philosophical consequences of
Quantum Theory: Reflections on Bell’s Theorem
, J.T. Cushing
and E. McMullin (eds.), Notre Dame: University of Notre Dame Press:
154–174.
Suppes, Patrick and Mario Zanotti, 1976, “On the Determinism
of Hidden Variable Theories with Strict Correlation and Conditional
Statistical Independence of Observables”, in
Logic and
Probability in Quantum Mechanics
, Patrick Suppes (ed.), (Synthese
Library 78), Dordrecht: Springer Netherlands, 445–455.
doi:10.1007/978-94-010-9466-5_21
Toroš, Marko and Angelo Bassi, 2018, “Bounds on
Quantum Collapse Models from Matter-Wave Interferometry: Calculational
Details”,
Journal of Physics A: Mathematical and
Theoretical
, 51(11): 115302. doi:10.1088/1751-8121/aaabc6
Toroš, Marko, Giulio Gasbarri, and Angelo Bassi, 2017,
“Colored and Dissipative Continuous Spontaneous Localization
Model and Bounds from Matter-Wave Interferometry”,
Physics
Letters A
, 381(47): 3921–3927.
doi:10.1016/j.physleta.2017.10.002
Tumulka, Roderich, 2006a, “A Relativistic Version of the
Ghirardi–Rimini–Weber Model”,
Journal of
Statistical Physics
, 125(4): 821–840.
doi:10.1007/s10955-006-9227-3
–––, 2006b, “On Spontaneous Wave Function
Collapse and Quantum Field Theory”,
Proceedings of the Royal
Society A: Mathematical, Physical and Engineering Sciences
,
462(2070): 1897–1908. doi:10.1098/rspa.2005.1636
–––, 2006c, “Collapse and
Relativity”, in
Quantum Mechanics: Are there Quantum Jumps?
and On the Present Status of Quantum Mechanics
, A. Bassi, D.
Dürr, T. Weber and N. Zanghi (eds.), AIP Conference Proceedings
844, American Institute of Physics. 340–351.
doi:10.1063/1.2219373
Tumulka, Roderich, 2007, “Comment on ‘The Free Will
Theorem’”,
Foundations of Physics
, 37(2):
186–197. doi:10.1007/s10701-006-9098-0
Van Fraassen, Bas C., 1982, “The Charybdis of Realism:
Epistemological Implications of Bell’s Inequality”,
Synthese
, 52(1): 25–38. doi:10.1007/BF00485253
Vinante, A., M. Bahrami, A. Bassi, O. Usenko, G. Wijts, and
T.H. Oosterkamp, 2016, “Upper Bounds on Spontaneous
Wave-Function Collapse Models Using Millikelvin-Cooled
Nanocantilevers”,
Physical Review Letters
, 116(9): art.
090402 (5 pages). doi:10.1103/PhysRevLett.116.090402
Vinante, A., R. Mezzena, P. Falferi, M. Carlesso, and A. Bassi,
2017, “Improved Noninterferometric Test of Collapse Models Using
Ultracold Cantilevers”,
Physical Review Letters
,
119(11): art. 110401 (5 pages).
doi:10.1103/PhysRevLett.119.110401
Zheng, Di, Yingchun Leng, Xi Kong, Rui Li, Zizhe Wang, Xiaohui
Luo, Jie Zhao, Chang-Kui Duan, Pu Huang, Jiangfeng Du, Matteo
Carlesso, and Angelo Bassi, 2020, “Room Temperature Test of the
Continuous Spontaneous Localization Model Using a Levitated
Micro-Oscillator”,
Physical Review Research
, 2(1): art.
013057. doi:10.1103/PhysRevResearch.2.013057
Zeilinger, Anton, 2002, “Bell’s Theorem, Information
and Quantum Physics”, in
Quantum (Un)speakables: From Bell
to Quantum Information
, R.A. Bertlmann, A. Zeilinger (eds.),
Springer-Verlag Berlin Heidelberg:
241–254. doi:10.1007/978-3-662-05032-3
Academic Tools
How to cite this entry
.
Preview the PDF version of this entry
at the
Friends of the SEP Society
.
Look up topics and thinkers related to this entry
at the Internet Philosophy Ontology Project (InPhO).
Enhanced bibliography for this entry
at
PhilPapers
, with links to its database.
Other Internet Resources
Adler, Stephen L., 2006,
 “
Notes on the Conway-Kochen Twin Argument
”,
 arXiv:quant-phys/0604122.
Conway, John H. and Simon Kochen, 2006b,
 “
On Adler’s Conway Kochen Twin Argument
”,
 arXiv:quant-ph/0610147
Dove, Chris and Euan J. Squires, 1996,
 “
A local model of explicit wavefunction collapse
”,
 arXiv:quant-ph/9605047.
Pearle, Philip, 2006,
 “
How Stands Collapse II
”,
 arXiv:quant-ph/0611212.
Pontin, A., N.P. Bullier, M. Toroš, and P.F. Barker, 2019,
 “
An ultra-narrow line width levitated nano-oscillator for testing dissipative wavefunction collapse
”,
 arXiv:1907.06046.
Related Entries
Bell’s Theorem
|
quantum mechanics
|
quantum mechanics: Bohmian mechanics