Self-Deception
First published Tue Oct 17, 2006; substantive revision Mon Mar 13, 2023
Virtually every aspect of self-deception, including its definition and
paradigmatic cases, is a matter of controversy among philosophers.
Minimally, self-deception involves a person who (a)  as a
consequence of some motivation or emotion, seems to acquire and
maintain some false belief despite evidence to the contrary and (b)
who may display behavior suggesting some awareness of the truth.
Beyond this, philosophers divide over whether self-deception is
intentional, whether it involves belief or some other sub- or
non-doxastic attitude, whether self-deceivers are morally responsible
for their self-deception, whether self-deception is morally
problematic (and if it is, in what ways and under what circumstances),
whether self-deception is beneficial or harmful, whether and in what
sense collectives can be self-deceived (and how, if they can be
self-deceived, this might affect individuals within such collectives),
and whether our penchant for self-deception might be socially,
psychologically or biologically adaptive or merely an accidental
byproduct of our evolutionary history.
The discussion of self-deception and its associated puzzles sheds
light on the ways motivation affects belief acquisition and retention
and other belief-like cognitive attitudes; it also prompts us to
scrutinize the notions of belief, intention, and the limits of such
folk psychological concepts to adequately explain phenomena of this
sort. Self-deception also requires careful consideration of the
cognitive architecture that might accommodate this apparent
irrationality regarding our beliefs.
Self-deception isn’t merely a philosophically interesting puzzle
but a problem of existential concern. It raises the distinct
possibility that we live with distorted views that may make us
strangers to ourselves and blind to the nature of our morally
significant engagements.
1. Paradoxes, Puzzles, and Problems of Self-Deception
2. Intentionalist Approaches
2.1 Temporal Partitioning
2.2 Psychological Partitioning
3. Revisionist Approaches
3.1 Revision of Intention: Non-Intentionalist and Deflationary Approaches
3.2 Revision of Belief: Adjustment of Attitude or Content
4. Twisted or Negative Self-Deception
5. Morality and Self-Deception
5.1 Moral Responsibility for Self-Deception
5.2 The Morality of Self-Deception
6. Origin of Self-Deception: Adaptation or Spandrel
7. Collective Self-Deception
7.1 Summative Collective Self-Deception: Self-Deception Across a Collective
7.2 Non-Summative Collective Self-Deception: Self-Deception of a Collective Entity
Bibliography
Academic Tools
Other Internet Resources
Related Entries
1. Paradoxes, Puzzles, and Problems of Self-Deception
“What is self-deception?” sounds like a straightforward
question, but the more philosophers have sought to answer it, the more
puzzling it has become. Traditionally, self-deception has been modeled
on interpersonal deception, where
A
intentionally gets
B
to believe some proposition
p
, all the while
knowing or believing truly that ~
p
. Such deception is
intentional and requires the deceiver to know or believe that
~
p
and the deceived to believe that
p
. One reason
for thinking self-deception is analogous to interpersonal deception of
this sort is that it helps us to distinguish self-deception from mere
error since the acquisition and maintenance of the false belief are
intentional, not accidental. It also helps to explain why we think
self-deceivers are responsible for and open to the evaluation of their
self-deception. If self-deception is properly modeled on interpersonal
deception, self-deceivers intentionally get themselves to believe that
p
, all the while knowing or believing truly that ~
p
.
On this traditional model, then, self-deceivers apparently must (1)
hold contradictory beliefs—the dual-belief requirement—and
(2) intentionally get themselves to hold a belief they know or believe
truly to be false.
The traditional model of self-deception, however, has been thought to
raise two paradoxes: One concerns the self-deceiver’s state of
mind—the so-called
static
paradox. How can a person
simultaneously hold contradictory beliefs? The other concerns the
process or dynamics of self-deception—the so-called
dynamic
or
strategic
paradox. How can a person
intend to deceive herself without rendering her intentions
ineffective? (Mele 1987a; 2001)
The dual-belief requirement raises the
static
paradox since
it seems to pose an impossible state of mind, namely, consciously and
simultaneously believing that
p
and ~
p
. As deceiver,
she believes that ~
p
, and, as deceived, she believes that
p
. Accordingly, the self-deceiver consciously believes that
p
and ~
p
. But if believing both a proposition and
its negation in full awareness is an impossible state of mind,
self-deception, as it has traditionally been understood, seems
impossible as well.
Static
paradoxes also arise regarding
motivation, intention, emotion, and the like insofar as self-deceivers
seem to harbor psychological states of these kinds that seem deeply
incompatible (Funkhouser 2019).
The requirement that the self-deceiver intentionally gets herself to
hold a belief she knows to be false raises the
dynamic
or
strategic
paradox since it seems to involve the self-deceiver
in an impossible project, namely, both deploying and being duped by
some deceitful strategy. As deceiver, she must be aware that
she’s deploying a deceitful strategy; but, as deceived, she must
be unaware of this strategy for it to be effective. And yet it’s
difficult to see how the self-deceiver could fail to be aware of her
intention to deceive. A strategy known to be deceitful seems bound to
fail. How could I be taken in by your efforts to get me to believe
something false if I know what you’re up to? But if it’s
impossible to be taken in by a strategy one knows is deceitful, then,
again, self-deception, as it has traditionally been understood, seems
to be impossible as well.
These paradoxes have led a minority of philosophers to be skeptical
that self-deception is conceptually possible or even coherent (Paluch
1967; Haight 1980; Kipp 1980). Borge (2003) contends that accounts of
self-deception inevitably give up central elements of our
folk-psychological notions of “self” or
“deception” to avoid paradox, leaving us to wonder whether
this framework itself is what gets in the way of explaining the
phenomenon. Such skepticism toward the concept may seem warranted,
given the obvious paradoxes involved. Most philosophers, however, have
sought some resolution to these paradoxes instead of giving up on the
notion itself, not only because empirical evidence suggests that
self-deception is not only possible but pervasive (Sahdra and Thagard
2003) but also because the concept does seem to pick out a distinct
kind of motivated irrationality.
Philosophical accounts of self-deception roughly fall into two main
groups: those that maintain that the paradigmatic cases of
self-deception are intentional and those that deny this. Call these
approaches
intentionalist
and
revisionist
,
respectively. Intentionalists find the model of intentional
interpersonal deception apt since it helps to explain the selectivity
of self-deception and the apparent responsibility of self-deceivers,
as well as provide a clear way of distinguishing self-deception from
other sorts of motivated belief, such as wishful thinking. To avoid
paradox, these approaches introduce a variety of divisions that shield
the deceiving from the deceived mind. Revisionists are skeptical of
these divisions and the ‘psychological exotica’ (Mele
2001) apparently needed to avoid the static and dynamic paradoxes.
Instead, they argue that revision of the intention requirement, the
belief requirement, or both offers a simpler account of self-deception
that avoids the paradoxes raised by modeling it on intentional
interpersonal deception.
2. Intentionalist Approaches
The chief problem facing intentional models of self-deception is the
dynamic paradox, namely, that it seems impossible to form an intention
to get oneself to believe what one currently disbelieves or believes
is false. For one to carry out an intention to deceive oneself, one
must know what one is doing; to succeed, one must be ignorant of this
same fact. Intentionalists agree that self-deception is intentional
or, at least, robustly purposive, but divide over whether it requires
holding contradictory beliefs and, thus, over the specific content of
the alleged intention involved (see
§3.2 Revision of Belief
).
 Insofar as even the bare intention to acquire the belief that
p
for reasons having nothing to do with one’s evidence
for
p
seems unlikely to succeed if directly known, most
intentionalists introduce some sort of temporal or psychological
partition to insulate self-deceivers from their deceptive stratagems.
When self-deceivers are not consciously aware of what they truly
believe or intend, it’s easier to see how they can play the role
of the deceiver and the deceived. By dividing the mind into parts,
temporally or psychologically, these approaches seek to show that
self-deception does not involve paradox.
2.1 Temporal Partitioning
Some intentionalists argue that self-deception is a complex,
temporally extended process during which a self-deceiver can
consciously set out to deceive herself that
p
, knowing or
believing that ~
p
, and along the way lose her belief that
~
p
, either forgetting her original deceptive intention
entirely or regarding it as having, albeit accidentally, brought about
the true belief she would have arrived at anyway (Sorensen 1985;
Bermúdez 2000). So, for instance, an official involved in some
illegal behavior might destroy any records of this behavior and create
evidence that would cover it up (diary entries, emails, and the like),
knowing that she will likely forget having done these things over the
next few months. When her activities are investigated a year later,
she has forgotten her tampering efforts and, based upon her falsified
evidence, comes to believe falsely that she was not involved in the
illegal activities of which she is accused. Here, the self-deceiver
need never simultaneously hold contradictory beliefs even though she
intends to bring it about that she believes that
p
, which she
regards as false at the outset of the process of deceiving herself and
true at its completion.
The self-deceiver need not even forget her original intention to
deceive. Take an atheist who sets out to get herself to believe in God
because it seems the best bet if God turns out to exist. She might
well remember such an intention at the end of the process and deem
that by God’s grace even this misguided path led her to the
truth. What enables the intention to succeed in such cases is the
operation of what Johnston (1988) terms ‘autonomous means’
(e.g., the normal degradation of memory, the tendency to believe what
one practices, etc.), not the continued awareness of the intention,
hinting that the process may be subintentional (See
§3.1 Revision of Intention
).
While such temporal partitioning accounts appear to avoid the static
and dynamic paradoxes, many, if not most, cases of self-deception
aren’t of this temporally extended type. Regularly,
self-deception seems to occur instantaneously (Jordan 2022), as when a
philosopher self-deceives that her article is high quality even while
reading the substantive and accurate criticisms in the rejection
letter from the prestigious peer-reviewed journal she submitted it to
(example due to Mele 2001). Additionally, many of these temporally
extended cases lack the distinctive opacity, indirection, and tension
associated with garden-variety cases of self-deception (Levy
2004).
2.2 Psychological Partitioning
Another strategy employed by intentionalists is the division of the
self into psychological parts that play the role of the deceiver and
deceived, respectively. These strategies range from positing strong
division in the self, where the deceiving part is a relatively
autonomous subagency capable of belief, desire, and intention (Rorty
1988), to more moderate division, where the deceiving part still
constitutes a separate center of agency (Pears 1984, 1986; 1991), to
the relatively modest division of Davidson (1982, 1986), where there
need only be a boundary between conflicting attitudes and
intentions.
Such divisions are prompted in large part by the acceptance of the
dual-belief requirement. It isn’t simply that self-deceivers
hold contradictory beliefs, which though strange, isn’t
impossible since one can believe that
p
and believe that
~
p
without believing that
p
& ~
p
. The
problem such theorists face stems from the appearance that the belief
that ~
p
motivates and thus forms a part of the intention to
bring it about that one acquires and maintains the false belief that
p
(Davidson 1986). So, for example, the Nazi official’s
recognition that his actions implicate him in serious evil motivates
him to implement a strategy to deceive himself into believing he is
not so involved; he can’t intend to bring it about that he holds
such a false belief if he doesn’t recognize it is false, and he
wouldn’t want to bring such a belief about if he didn’t
recognize the evidence to the contrary. So long as this is the case,
the deceiving self, whether it constitutes a separate center of agency
or something less robust, must be hidden from the conscious self being
deceived if the self-deceptive intention is to succeed.
While these psychological partitioning approaches seem to resolve the
static and dynamic puzzles, they do so by introducing a picture of the
mind that raises puzzles of its own. On this point, there appears to
be consensus even among intentionalists that self-deception can and
should be accounted for without invoking speculative or stipulative
divisions not already used to explain non-self-deceptive behavior,
what Talbott (1995) calls ‘innocent’ divisions. That said,
recent, if controversial, research (e.g., Bargh and Morsella 2008;
Hassin, Bargh, and Zimmerman 2009; Huang and Bargh 2014) seems to
support the possibility of the sort of robust unconscious but flexible
goal pursuit that could explain the way self-deceivers are able to
pursue their deceptive goal while retaining the beliefs necessary for
navigating the shifting evidential terrain (see Funkhouser and Barrett
2016, 2017 and Doody 2016 for skepticism about the applicability of
this research to self-deception). If this kind of research shows that
no ‘psychological exotica’ are necessary to explain
self-deception, there is less pressure to deflate the phenomenon in
ways that minimize the active, strategic role self-deceivers play in
the process.
3. Revisionist Approaches
A number of philosophers have moved away from modeling self-deception
directly on intentional interpersonal deception, opting instead to
revise either the intention or the belief requirement traditional
intentionalist models assume. Those revising the intention requirement
typically treat self-deception as a species of motivationally biased
belief, thus avoiding the problems involved with intentionally
deceiving oneself. Call these
non-intentionalist
and
deflationary
approaches
.
Those revising the belief requirement do so in a variety of ways. Some
posit other, non-doxastic or quasi-doxastic attitudes toward the
proposition involved (‘misrepresentation’ Jordan 2020,
2022; ‘hope,’ ‘suspicion,’
‘doubt,’ ‘anxiety’ Archer 2013;
‘besires’ Egan 2009; ‘pretense’ Gendler 2007;
‘imagination’ Lazar 1999). Others alter the content of the
proposition believed (Holton 2001; Funkhouser 2005; Fernández
2013), while others suggest the doxastic attitudes involved are
indeterminate, somehow ‘in-between believing’
(Schwitzgebel 2001; Funkhouser 2009) or subject to shifting degrees of
credulity throughout the process of self-deception (Chan and Rowbottom
2019). Call these
revision of belief
approaches.
Deflationary approaches focus primarily on the process of
self-deception, while the revision of belief approaches focus on the
product. A revision of either of these aspects, of course, has
ramifications for the other. For example, if self-deception
doesn’t involve belief, but some other non-doxastic attitude
(product), then one may well be able to intentionally enter that state
without paradox (process). This section considers non-intentional and
deflationary approaches and the worries such approaches raise
 (
§3.1
).
 It also considers revision of belief approaches
 (
§3.2
).
3.1 Revision of Intention: Non-Intentionalist and Deflationary Approaches
Non-intentionalists argue that most ‘garden-variety’ cases
of self-deception can be explained without adverting to subagents, or
unconscious beliefs and intentions, which, even if they resolve the
static and dynamic puzzles of self-deception, raise puzzles of their
own. If such non-exotic explanations are available, intentionalist
explanations seem unwarranted and unnecessary.
Since the central paradoxes of self-deception arise from modeling
self-deception on intentional interpersonal deception,
non-intentionalists suggest this model be jettisoned in favor of one
that takes ‘to be deceived’ to be nothing more than
believing falsely or being mistaken in believing something (Johnston
1988; Mele 2001). For instance, Sam mishears that it will be a sunny
day and relays this misinformation to Joan with the result that she
believes it will be a sunny day. Joan is deceived into believing it
will be sunny, and Sam has deceived her, albeit unintentionally.
Initially, such a model may not appear promising for self-deception
since simply being mistaken about
p
or accidentally causing
oneself to be mistaken about
p
doesn’t seem to be
self-deception at all but some sort of innocent error.
Non-intentionalists, however, argue that in cases of self-deception,
the false belief is not accidental but, rather, motivated by desire
(Mele 2001), emotion (Lazar 1999), anxiety (Johnston 1988; Barnes
1997), or some other attitude regarding
p
or related to
p
. So, for instance, when Allison believes, against the
preponderance of evidence available to her, that her daughter is not
having learning difficulties, non-intentionalists will explain the
various ways she misreads the evidence by pointing to such things as
her desire that her daughter not have learning difficulties, her fear
that she has such difficulties, or anxiety over this possibility. In
such cases, Allison’s self-deceptive belief that her daughter is
not having learning difficulties fulfills her desire, quells her fear,
or reduces her anxiety, and it’s this function—not an
intention—that explains why her belief formation process is
biased. Allison’s false belief is not an innocent mistake but a
consequence of her motivational states.
Non-intentionalists divide over the dual-belief requirement. Some
accept the requirement, seeing the persistent efforts to resist the
conscious recognition of the unwelcome truth or to reduce the anxiety
generated by this recognition as characteristic of self-deception
(Bach 1981; Johnston 1988). So, in Allison’s case, her belief
that her daughter is having learning difficulties, along with her
desire that this not be the case, motivates her to employ means to
avoid this thought and to believe the opposite.
Others, however, argue the needed motivation can as easily be supplied
by uncertainty or ignorance whether
p
, or suspicion that
~
p
(Mele 2001; Barnes 1997). Thus, Allison need not hold any
opinion regarding her daughter’s having learning difficulties
for her false belief to count as self-deception since it’s her
regarding evidence in a motivationally biased way in the face of
evidence to the contrary, not her recognition of this evidence, that
makes her belief self-deceptive. Accordingly, Allison needn’t
intend to deceive herself nor believe at any point that her daughter,
in fact, has learning difficulties. If we think someone like Allison
is self-deceived, then self-deception requires neither contradictory
beliefs nor intentions regarding the acquisition or retention of the
self-deceptive belief. Such approaches are ‘deflationary’
in the sense that they take self-deception to be explicable without
reaching for exotic cognitive architecture since neither intentions
nor dual-beliefs are required to account for self-deception. (For more
on the dual-belief requirement, see
§3.2 Revision of Belief
.)
Mele (2001, 2012) has offered the most fully articulated deflationary
account, and his view has been the target of the most scrutiny, so it
is worth stating what he takes to be the jointly sufficient conditions
for entering self-deception:
The belief that
p
,
which
S
acquires, is
false
S
treats data relevant, or at least seemingly relevant,
to the truth value of
p
in a motivationally biased way
This biased treatment is a nondeviant cause of
S’
s
acquiring the belief that
p
The body of data possessed by
S
at the time provides
greater warrant for ~
p
than for
p
S
consciously believes at the time that there is a
significant chance that ~
p
S
’s acquiring the belief that
p
is a
product of “reflective, critical reasoning,” and
S
is wrong in regarding that reasoning as properly
directed
Mele (2012) added the last two conditions to clarify his account in
view of some of the criticisms of this kind of approach addressed in
the next section.
To support non-intentionalism, some have looked to the purposive
mechanisms of deception operating in non-human organisms as a model
(Smith 2014), while others have focused on neurobiological mechanisms
triggered by affect to explain the peculiarly purposive responses to
evidence involved in self-deception (Lauria
et al
. 2016).
Deflationary Worries and Modifications
Critics contend these deflationary accounts do not adequately
distinguish self-deception from other sorts of motivated believing
(such as wishful thinking), nor can they explain the peculiar
selectivity associated with self-deception, its characteristic
‘tension,’ the way it involves a failure of
self-knowledge, or the agency of the self-deceiver.
Self-Deception and Wishful Thinking
: What distinguishes
wishful thinking from self-deception, according to intentionalists,
just is that the latter is intentional while the former is not
(Bermúdez 2000). Specifically, wishful thinking does not seem
‘deceptive’ in the requisite sense. Non-intentionalists
respond that what distinguishes wishful thinking from self-deception
is that self-deceivers recognize evidence against their self-deceptive
belief whereas wishful thinkers do not (Bach 1981; Johnston 1988) or
that they merely possess, without recognizing it, greater
counterevidence than wishful thinkers (Mele 2001). In either case,
self-deceivers exert more agency than wishful thinkers over their
belief formation. In wishful thinking, motivation triggers a belief
formation process in which the person does not play an active,
conscious role, “while in self-deception the subject is a
willing participant in directing cognition towards the doxastic
embrace of the favored proposition” (Scott-Kakures 2002; see
also Szabados 1973). While the precise relationship between wishful
thinking and self-deception is clearly a matter of debate,
non-intentionalists offer plausible ways of distinguishing the two
that do not invoke the intention to deceive.
Self-Deception and Selectivity
: Another worry—termed
the ‘selectivity problem’—originally raised by
Bermúdez (1997, 2000) is that deflationary accounts don’t
seem to be able to explain the selective nature of self-deception
(i.e., why motivation seems only selectively to produce bias). Why is
it, such intentionalists ask, that we are not rendered biased in favor
of the belief that
p
in many cases where we have a very
strong desire that
p
(or anxiety or some other motivation
related to
p
)? Intentionalists argue that an intention to get
oneself to acquire the belief that
p
offers the most
straightforward answer to this question.
Others, following Mele (2001, 2012, 2020), contend that selectivity
may be explained in terms of the agent’s assessment of the
relative costs of erroneously believing that
p
or ~
p
(see Friedrich (1993) and Trope and Lieberman (1996) on lay hypothesis
testing). Essentially, this approach suggests that the minimization of
costly errors is the central principle guiding hypothesis testing. So,
for example, Josh would be happier believing falsely that the gourmet
chocolate he finds so delicious isn’t produced by exploited
farmers than falsely believing that it is since he desires that it not
be so produced. Because Josh considers the cost of erroneously
believing his favorite chocolate is tainted by exploitation to be very
high—no other chocolate gives him the same pleasure—it
takes a great deal more evidence to convince him that his chocolate is
so tainted than it does to convince him otherwise. It’s the low
subjective cost of falsely believing the chocolate is not tainted that
facilitates Josh’s self-deception. But we can imagine Josh
having the same strong desire that his chocolate not be tainted by
exploitation and yet having a different assessment of the cost of
falsely believing it’s not tainted. Say, for example, he works
for an organization promoting fair trade and non-exploitive labor
practices among chocolate producers and believes he has an obligation
to accurately represent the labor practices of the producer of his
favorite chocolate and would, furthermore, lose credibility if the
chocolate he himself consumes is tainted by exploitation. In these
circumstances, Josh is more sensitive to evidence that his favorite
chocolate is tainted—despite his desire that it not
be—since the subjective cost of being wrong is higher for him
than it was before. It is the relative, subjective costs of falsely
believing
p
and ~
p
that explain why desire or other
motivation biases belief in some circumstances and not others.
While error-cost accounts offer some explanation of selectivity, one
might still complain that even when these conditions are met,
self-deception needn’t follow (Bermúdez 2000, 2017). Some
non-intentionalist respond that these conditions are as complete an
explanation of self-deception as is possible. Given the complexity of
the factors affecting belief formation and the lack of a complete
account of its etiology, we shouldn’t expect a complete
explanation in each case (Funkhouser 2019; Mele 2020). Others argue
that attention to the role of emotion in assessing and filtering
evidence sheds further light on the process. According to such
approaches, affect plays a key role in triggering the conditions under
which motivation leads to self-deception (Galeotti 2016a; Lauria
et al.
2016; Lauria and Preissmann 2018). Our
emotionally-loaded appraisal of evidence, in combination with
evidential ambiguity and our potential to cope with the threatening
reality, helps to explain why motivation tips us toward
self-deception. Research on the role of dopamine regulation and
negative somatic markers provides some empirical support for this sort
of affective model (Lauria
et al.
2016; Lauria and Preissmann
2018).
Non-intentionalists also point out that intentionalists have
selectivity problems of their own since it isn’t clear why
intentions are formed in some cases rather than others (Jurjako 2013)
or why some intentions to acquire a self-deceptive belief succeed
while others do not (Mele 2001, 2020) See Bermúdez (2017) for a
response to these worries.
Self-Deception and Tension
: A number of philosophers have
complained that deflationary accounts fail to explain certain
‘tensions’ or conflicts supposed to be present in cases of
genuine self-deception (Audi 1997; Bach 1997; Nelkin 2002; Funkhouser
2005; Fernández 2013; Jordan 2022). Take Ellen, who says she is
doing well in her biology class but systematically avoids looking at
the results on her quizzes and tests. She says she doesn’t need
to look; she knows she didn’t miss anything. When her teacher
tries to catch her after class to discuss her poor grades, she rushes
off. Similarly, when she sees an email from her teacher with the
subject line “your class performance,” she ignores it. The
prospect of looking at the test results, talking with her teacher, or
reading her email sends a flash of dread through her and a pit to her
stomach, even as she projects calm and confidence. Ellen’s
behavior and affective responses suggest to these critics that she
knows she isn’t doing well in her biology class, despite her
avowals to the contrary. Ellen’s case highlights a variety of
tensions that may arise in the self-deceived. Philosophers have
focused on tensions that arise with respect to evidence (since there
is a mismatch between what the evidence warrants and what is believed
or avowed); to unconscious doxastic attitudes (since they are at
variance with those consciously held); to self-knowledge (since one
has a false second-order belief about what one believes); to the
various components of belief—behavioral, verbal, emotional,
physical—(since what one does, says, feels, or experiences can
come apart in a number of ways) (Funkhouser 2019); and to authorship
(since one may be aware of authoring her self-deception and presenting
her self-deception to herself as not having been authored, i.e., as
the truth) (Jordan 2022). These tensions seem to be rooted in the
self-deceiver’s awareness of the truth. But, since deflationary
accounts deny the dual-belief requirement, specifically, that
self-deceivers must hold the true belief that
~p
, it’s
not clear why self-deceivers would experience tension or display
behaviors in conflict with their self-deceptive belief
p
.
Deflationary theorists counter that suspicion that ~
p
,
thinking there’s a significant possibility that ~
p,
may
suffice to explain these kinds of tensions (Mele 2001, 2009, 2010,
2012). Clearly, a person who self-deceptively believes that
p
and suspects that
~p
may experience tension; moreover, such
attitudes combined with a desire that
p
might account for the
behaviors highlighted by critics.
While these attitudes may explain some of the tension in
self-deception, a number of critics think they are inadequate to
explain deep-conflict cases in which what self-deceivers say about
p
is seriously at odds with non-verbal behavior that
justifies the attribution of the belief that
~p
to them
(Audi, 1997; Patten 2003; Funkhouser 2005; Gendler 2007;
Fernández 2013). While some propose these cases are just a
type
of self-deception that deflationary approaches cannot
explain (Funkhouser 2009, 2019; Fernández 2013), others go
further, suggesting these cases show that deflationary approaches
aren’t accounts of self-deception at all but of
self-delusion
since deflationary self-deceivers seem
single-mindedly to hold the false belief (Audi 2007; Funkhouser 2005;
Gendler 2007).
Some defenders of deflation acknowledge that the significant
difference between what deflationary accounts have in view (namely,
people who do not believe the unwelcome truth that
~p
, having
a motivation-driven, unwarranted skepticism toward it) and what
deep-conflict theorists do (namely, people who know the unwelcome
truth that
~p
and avoid reflecting on it or encountering
evidence for it) warrants questioning whether these phenomena belong
to the same psychological kind, but argue that it’s the
deep-conflict cases that represent something other than
self-deception. Those who unconsciously hold the warranted belief and
merely say or pretend they hold the unwarranted one (Audi 1997;
Gendler 2007) hardly seem deceived (Lynch 2012). They seem more to
resemble what Longeway (1990) calls
escapism
, the avoidance
of thinking about what we believe to escape reality (See Lynch
2012).
Funkhouser (2019) suggests that this dispute over the depth of
conflict and intensity of tension involved in self-deception is, in
part, a dispute over which cases are central, typical, and most
interesting. Whether deep-conflict cases constitute a distinct
psychological kind or whether they reflect people’s
pre-theoretical understanding of self-deception remains unclear, but
deflationary approaches seem to be capable of explaining at least some
of the behavior such theorists insist justifies attributing an
unconscious belief that
~p
. Deep-conflict theorists need to
explain why we should think when one avows that
p
, one does
not also believe it to some degree, and why the behavior in question
cannot be explained by nearby proxies like suspicion or doubt that
p
(Mele 2010, 2012). Some deflationary theorists contend that
a degree of belief model might render deep-conflict cases more
sensible (see
Shifting Degrees of Belief
).
Self-Deception and Self-Knowledge
: Several theorists have
argued that deflationary approaches miss certain failures of
self-knowledge involved in cases of self-deception. Self-deceivers,
these critics argue, must hold false beliefs about their own belief
formation process (Holton 2001; Scott-Kakures 2002), about what
beliefs they actually hold (Funkhouser 2005; Fernández 2013),
or both. Holton (2001), for instance, argues that Mele’s
conditions for being self-deceived are not sufficient because they do
not require self-deceivers to hold false beliefs about themselves. It
seems possible for a person to acquire a false belief that
p
as a consequence of treating data relevant to
p
in a
motivationally biased way when the data available to her provides
greater warrant for
p
and still retain accurate
self-knowledge. Such a person would readily admit to ignoring certain
data because it would undermine a belief she cherishes. She makes no
mistakes about herself, her beliefs, or her belief formation process.
Such a person, Holton argues, would be
willfully ignorant
but
not self-deceived. If, however, her strategy was sufficiently opaque
to her, she would be apt to deny she was ignoring relevant evidence
and even affirm her belief was the result of what Scott-Kakures (2002)
calls “reflective, critical reasoning.” These erroneous
beliefs represent a failure of self-knowledge that seems, according to
these critics, essential to self-deception, and they distinguish it
from wishful thinking (see above), willful blindness, and other nearby
phenomena.
In response to such criticisms, Mele (2009, 2012) has offered the
following sufficient condition:
S
’s acquiring the
belief that
p
is a product of “reflective, critical
reasoning,” and S is wrong in regarding that reasoning as
properly directed. Some worry that meeting this condition requires a
degree of awareness about one’s reasons for believing that would
rule out those who do not engage in reflection on their reasons for
belief (Fernández 2013) and fails to capture errors about what
one believes that seem essential for dealing with deep-conflict cases
(Fernández 2013; Funkhouser 2005). Whether Mele’s (2009)
proposed condition requires too much sophistication from
self-deceivers is debatable but suggests a way of accounting for the
intuition that self-deceivers fail to know themselves without
requiring them to harbor hidden beliefs or intentions.
Self-Deception and Agency:
Some worry that deflationary
explanations render self-deceivers victims of their own motivations;
they don’t seem to be agents with respect to their
self-deception but unwitting patients. But, in denying self-deceivers
engage in intentional activities for the purpose of deceiving
themselves, non-intentionalists needn’t deny self-deceivers
engage in any intentional actions. It’s open to them to accept
what Lynch terms
agentism
: “Self-deceivers end up with
their unwarranted belief as a result of their own actions motivated by
the desire that
p
” (Lynch 2017). According to agentism,
motivation affects belief by means of intentional actions, not simply
by triggering biasing mechanisms. Self-deceivers can act with
intentions like “find any problem with unwelcome evidence”
or “find any
p
-supporting evidence” with a view
of determining whether
p
is true. These kinds of intentions
may explain the agency of self-deceivers and how they could be
responsible for self-deception and not merely victims of their own
motivations. It isn’t perfectly clear whether Mele-style
deflationists are committed to agentism, but even if they are,
questions remain about whether such unwittingly deceptive intentional
actions are enough to render self-deceivers true agents of their
deception since they think that they are engaging in actions to
determine the truth, not to deceive themselves.
3.2 Revision of Belief: Adjustment of Attitude or Content
Approaches that focus on revising the notion that self-deception
requires holding that
p
and
~p
, the dual-belief
requirement implied by traditional intentionalism, either introduce
some “doxastic proxy” (Baghramian and Nicholson 2013) to
replace one or both beliefs or alter the content of the
self-deceiver’s belief in a way that preserves tension without
involving outright conflict. These approaches resolve the doxastic
paradox either by denying that self-deceivers hold the unwelcome but
warranted belief
~p
(Talbott 1995; Barnes 1997;
Burmúdez 2000; Mele 2001), denying they hold the welcome but
unwarranted belief
p
(Audi 1982, 1988; Funkhouser 2005;
Gendler 2007; Fernández 2013; Jordan 2020, 2022), denying they
hold either belief
p
or
~p
(Archer 2013; Porcher
2012), or contending they have shifting degrees of belief regarding
p
(Chan and Rowbottom 2019). Lauria
et al.
(2016)
argue for an integrative approach that accommodates all these products
of self-deception on the basis of empirical research on the role
affect plays in assessments of evidence.
Denying the Unwelcome Belief
: Both intentionalists and
non-intentionalists may question whether self-deceivers must hold the
unwelcome but warranted belief. For intentionalists, what’s
necessary is some intention to form the target belief
p
, and
this is compatible with having no views at all regarding
p
(lacking any evidence for or against p) or believing p is merely
possible (possessing evidence too weak to warrant belief that
p
or
~p
) (Bermúdez 2000). Moreover, rejecting
this requirement relieves the pressure to introduce deep divisions
(Talbott 1995). For non-intentionalists, the focus is on how the false
belief is acquired, not whether a person believes it’s
contradictory. For them, it suffices that self-deceivers acquire the
unwarranted false belief that
p
in a motivated way (Mele
2001). The selectivity and tension typical of self-deception can be
explained without attributing
~p
since nearby proxies like
suspicion that ~
p
can do the same work. Citing Rorty’s
(1988) case of Dr. Androvna, a cancer specialist who believes she does
not have cancer but who draws up a detailed will and writes
uncharacteristically effusive letters suggesting her impending
departure, Mele (2009) points out that Androvna’s behavior might
easily be explained by her holding that there’s a significant
chance I have cancer. And this belief is compatible with
Androvna’s self-deceptive belief that she does not, in fact,
have cancer.
Denying the Welcome Belief
: Another strand of revision of
belief approaches focuses on the welcome belief that
p
,
proposing alternatives to this belief that function in ways that
explain what self-deceivers typically say and do. Self-deceivers
display ambiguous behavior that not only falls short of what one would
expect from a person who believes that
p
but seems to justify
the attribution of the belief that
~p
. For instance,
Androvna’s letter-writing and will-preparation might be taken as
reasons for attributing to her the belief that she won’t
recover, despite her verbal assertions to the contrary. To explain the
special pattern of behavior displayed by self-deceivers, some of these
theorists propose proxies for full belief, such as sincere avowal
(Audi 1982, 1988); pretense (Gendler 2007); an intermediate state
between belief and desire, or ‘besire’ (Egan 2009); some
other less-than-full belief state akin to imaginations or fantasies
(Lazar 1999); or simply ‘misrepresentation’ (Jordan 2020,
2022). Such states may guide and motivate action in many, though not
all, circumstances while being relatively less sensitive to evidence
than beliefs.
Others substitute a higher-order belief to explain the behavior of
self-deceivers as another kind of proxy for the belief that
p
(Funkhouser 2005; Fernández 2013). On such approaches,
self-deceivers don’t believe
p
; they believe that they
believe that
p
, and this false second-order
belief—“I think that I believe that
p
”—underlies and underwrites their sincere avowal
that
p
as well as their ability to entertain
p
as
true. Self-deception, then, is a kind of failure of self-knowledge, a
misapprehension or misattribution of one’s own beliefs. By
shifting the content of the self-deceptive belief to the second-order,
this approach avoids the doxastic paradox and explains the
characteristic ‘tension’ or ‘conflict’
attributed to self-deceivers in terms of the disharmony between the
first-order and second-order beliefs, the latter explaining their
avowed belief and the former their behavior that goes against that
avowed belief (Funkhouser 2005; Fernández 2013).
Denying both the Welcome Belief and the Unwelcome
Belief
:
Given the variety of proxies that have been
offered for both the welcome and the unwelcome belief, it should not
be surprising that some argue that self-deception can be explained
without attributing either belief to self-deceivers, a position Archer
(2013) refers to as ‘nondoxasticism.’ Porcher (2012)
recommends against attributing beliefs to self-deceivers on the
grounds that what they believe is indeterminate since they are, as
Schwitzgebel (2001, 2010) contends,
“in-between-believing,” neither fully believing that
p
nor fully not believing that
p
. For Porcher
(2012), self-deceivers show the limits of the folk psychological
concepts of belief and suggest the need to develop a dispositional
account of self-deception that focuses on the ways that
self-deceivers’ dispositions deviate from those of stereotypical
full belief. Funkhouser (2009) also points to the limits of folk
psychological concepts and suggests that in cases involving deep
conflict between behavior and avowal, “the self-deceived produce
a confused belief-like condition so that it is genuinely indeterminate
what they believe regarding
p
.” Archer (2013), however,
rejects the claim that the belief is indeterminate or that folk
psychological concepts are inadequate, arguing that folk psychology
offers a wide variety of non-doxastic attitudes such as
‘hope,’ ‘suspicion,’ ‘anxiety,’
and the like that are more than sufficient to explain paradigm cases
of self-deception without adverting to belief.
Shifting Degrees of Belief
:
Some contend that
attention to shifting degrees of belief offers a better explanation of
paradigm cases of self-deception—especially the behavioral
tensions—and avoids the static paradox (Chan and Rowbottom
2019). In their view, many so-called non-doxastic attitudes entail
some degree of belief regarding
p.
Shifts in these beliefs
are triggered by and track shifts in information and non-doxastic
propositional attitudes such as desire, fear, anxiety, and anger. For
instance, a husband might initially have a high degree of belief in
his spouse’s fidelity that plummets when he encounters
threatening evidence. His low confidence reveals afresh how much he
wants her fidelity and prompts him to despair. These non-doxastic
attitudes trigger another shift by focusing his attention on evidence
of his spouse’s love and fidelity, leaving him with a higher
degree of confidence than his available evidence warrants. On this
shifting belief account, the self-deceiver holds both
p
and
~p
at varying levels of confidence that are always greater
than zero (example due to Chan and Rowbottom 2019).
While revision of belief approaches suggest a number of
non-paradoxical ways of thinking about self-deception, some worry that
those approaches denying that self-deceivers hold the welcome but
unwarranted belief that
p
eliminate what is central to the
notion of self-deception, namely,
deception
(see, e.g., Lynch
2012; Mele 2010). Whatever the verdict, these revision of belief
approaches suggest that our way of characterizing belief may not be
fine-grained enough to account for the subtle attitudes or
meta-attitudes that self-deceivers bear on the proposition in
question. Taken together, these approaches make it clear that the
question regarding what self-deceivers believe is by no means
resolved.
4. Twisted or Negative Self-Deception
‘Twisted’ or negative self-deception differs from
‘straight’ or positive self-deception because it involves
the acquisition of an
unwelcome
as opposed to a
welcome
belief (Mele 1999, 2001; Funkhouser 2019). Roughly,
the negatively self-deceived have a belief that is neither warranted
nor wanted in consequence of some desire, emotion, or combination of
both. For instance, a jealous husband, uncertain about his
wife’s fidelity, comes to believe she’s having an affair
on scant and ambiguous evidence, something he certainly doesn’t
want to be the case. Intentionalists may see little problem here, at
least in terms of offering a unified account, since both positive and
negative self-deceivers intend to produce the belief in question, and
nothing about intentional deception precludes getting the victim to
believe something unpleasant or undesirable. That said,
intentionalists typically see the intention to believe
p
as
serving a desire to believe
p
(Davidson 1985; Talbott 1995;
Bermúdez 2000, 2017), so they still face the difficult task of
explaining why negative self-deceivers intend to acquire a belief they
don’t want (Lazar 1999; Echano 2017). Non-intentionalists have a
steeper hill to climb since it’s difficult to see how someone
like the anxious husband could be motivated to form a belief that he
doesn’t at all desire. The challenge for the non-intentionalist,
then, is to supply a motivational story that explains the acquisition
of such an unwelcome belief. Ideally, the aim is to provide a unified
explanation for both the positive and negative varieties with a view
to theoretical simplicity. Attempts to provide such an explanation now
constitute a significant and growing body of literature that centers
on the nature of the motivations involved and the precise role affect
plays in the process.
Since the desire for the welcome belief cannot serve as the motive for
acquiring the unwelcome one, non-intentionalists have sought some
ulterior motive (Pears 1984), such as the reduction of anxiety (Barnes
1997), the avoidance of costly errors (Mele 1999, 2001), or denial
that the motivation is oriented toward the state of the world at all
(Nelkin 2002).
The jealous husband might be motivated to believe his wife is
unfaithful because it supports the vigilance needed to eliminate all
rival lovers and preserve the relationship—both of which he
desires (Pears 1984). Similarly, I might be anxious about my house
burning down and come to hold the unwelcome belief that I’ve
left the burner on. Ultimately, acquiring the unwelcome belief reduces
my anxiety because it prompts me to double-check the stove (Barnes
1997). Some are skeptical that identifying such ulterior desires or
anxieties is always possible or necessary (Lazar 1999; Mele 2001).
Many, following Mele (2001, 2003), see a simpler explanation of
negative cases in terms of the way motivation, broadly speaking,
affects the agent’s assessment of the relative costs of error.
The jealous husband—not wanting to be made a fool—sees the
cost of falsely believing his spouse is faithful as high, while the
person anxious about their house burning down sees the cost of falsely
believing the burner is on as low. Factors such as what the agent
cares about and what she can do about the situation affect these error
cost assessments and may explain, in part, the conditions under which
negative self-deception occurs.
Since negative self-deception often involves emotions—fear,
anxiety, jealousy, rage—a good deal of attention has been given
to how this component is connected to the motivation driving negative
self-deception. Some, like Mele (2001, 2003), acknowledge the
possibility that emotion alone or in combination with desire is
fundamental to what motivates bias in these cases but remain reluctant
to say such affective motives are essential or entirely
distinguishable from the desires involved. Others worry that leaving
motivation so ambiguous threatens the claim to provide a unified
explanation of self-deception (Galeotti 2016a). Consequently, some
have sought a more central role for affect, seeing emotion as
triggering or priming motivationally biased cognition (Scott-Kakures
2000, 200; Echano 2017) or as operating as a kind of evidential filter
in a pre-attentive—non-epistemic—appraisal of threatening
evidence (Galeotti 2016a). On this latter affective-filter view, our
emotions may lead us to see evidence regarding a situation we consider
significant to our wellbeing as ambiguous and therefore potentially
distressing, especially when we deem our ability to deal with the
unwelcome situation as limited. Depending on how strong our affective
response to the distressing evidence is, we may end up discounting
evidence for the situation we want, listening instead to our negative
emotions (anxiety, fear, sorrow, etc.), with the result that we become
negatively self-deceived (see Lauria and Preissmann 2018). Research on
the role of dopamine regulation and negative somatic markers provides
some neurobiological evidence in support of this sort of
affective-filter model and its potential to offer a unified account of
positive and negative self-deception (Lauria et al. 2016; Lauria and
Preissmann 2018).
While the philosophers considered so far take the relevant motives to
be about the state of the world, some hold that the relevant motives
have to do with self-deceivers’ states of mind. If this latter
desire-to-believe approach is taken, then there may be just one
general motive for both kinds of self-deception. Nelkin (2002, 2012),
for instance, argues that the motivation for self-deceptive belief
formation should be restricted to a desire to believe that
p
and that this is compatible with not wanting
p
to be true. I
might want to hold the
belief
that I have left the stove
burner on but not want it to be the case that I have actually left it
on. The belief is desirable in this instance because holding it
ensures it won’t be true. What unifies cases of
self-deception—both twisted and straight—is that the
self-deceptive belief is motivated by a desire
to believe that
p
; what distinguishes them is that twisted self-deceivers do not
want
p
to be the case, while straight self-deceivers do.
Some, like Mele (2009), argue that such an approach is unnecessarily
restrictive since a variety of other motives oriented toward the state
of the world might lead one to acquire the unwelcome belief; for
example, even just wanting to not be wrong about the welcome belief
(see Nelkin 2012 for a response). Others, like Galeotti (2016a), worry
that this desire-to-believe account renders self-deceivers’
epistemic confusion into something bordering on incoherence since it
seems to imply self-deceivers want to believe
p
regardless of
the state of the world, and such a desire seems absurd even at an
unconscious level.
Whether the motive for self-deception aims at the state of the world
or the state of the self-deceiver’s mind, the role of affect in
the process remains a significant question that further research in
neurobiology may shed light upon. The role of affect has been
underappreciated but seems to be gathering support and will no doubt
guide future theorizing, especially on negative self-deception.
5. Morality and Self-Deception
Even though much of the contemporary philosophical discussion of
self-deception has focused on epistemology, philosophical psychology,
and philosophy of mind, historically, the morality of self-deception
has been the central focus of discussion. Self-deception has been
thought to be morally wrong or, at least, morally dangerous insofar as
it represents a threat to moral self-knowledge, a cover for immoral
activity, or a violation of authenticity. Some thinkers, what Martin
(1986) calls ‘the vital lie tradition,’ however, have held
that self-deception can, in some instances, be salutary, protecting us
from truths that would make life unlivable (e.g., Rorty 1972, 1994).
There are two major questions regarding the morality of
self-deception: First, can a person be held morally responsible for
self-deception, and if so, under what conditions? Second, is there
anything morally problematic with self-deception, and if so, what and
under what circumstances? The answers to these questions are clearly
intertwined. If self-deceivers cannot be held responsible for
self-deception, then their responsibility for whatever morally
objectionable consequences self-deception might have will be mitigated
if not eliminated. Nevertheless, self-deception might be morally
significant even if one cannot be taxed for entering it. To be
ignorant of one’s moral self, as Socrates saw, may represent a
great obstacle to a life well lived, whether or not one is at fault
for such ignorance.
5.1 Moral Responsibility for Self-Deception
Whether self-deceivers can be held responsible for their
self-deception is largely a question of whether they have the
requisite control over the acquisition and maintenance of their
self-deceptive belief. In general, intentionalists hold that
self-deceivers are responsible since they intend to acquire the
self-deceptive belief, usually recognizing the evidence to the
contrary. Even when the intention is indirect, such as when one
intentionally seeks evidence in favor of
p
or avoids
collecting or examining evidence to the contrary, self-deceivers seem
to intentionally flout their own normal standards for gathering and
evaluating evidence. So, minimally, they are responsible for such
actions and omissions.
Initially, non-intentionalist approaches may seem to remove the agent
from responsibility by rendering the process by which she is
self-deceived subintentional. If my anxiety, fear, or desire triggers
a process that ineluctably leads me to hold the self-deceptive belief,
it seems I cannot be held responsible for holding that belief. How
could I be held responsible for processes that operate without my
knowledge and which are set in motion without my intention? Most
non-intentionalist accounts, however, do allow for the possibility
that self-deceivers are responsible for individual episodes of
self-deception or for the vices of cowardice and lack of self-control
from which they spring. To be morally responsible in the sense of
being an appropriate target for praise or blame requires, at least,
that agents have control over the actions in question. Mele (2001),
for example, argues that many sources of bias are controllable and
that self-deceivers can recognize and resist the influence of emotion
and desire on their belief acquisition and retention, particularly in
matters they deem to be important—morally or otherwise. The
extent of this control, however, is an empirical question. Nelkin
(2012) argues that since Mele’s account leaves the content of
motivation driving the bias unrestricted, the mechanism in question is
so complex that “it seems unreasonable to expect the
self-deceiver to guard against” its operation.
Other non-intentionalists take self-deceivers to be responsible for
certain epistemic vices, such as cowardice in the face of fear or
anxiety and lack of self-control with respect to the biasing
influences of desire and emotion. Thus, Barnes (1997) argues that
self-deceivers “can, with effort, in some circumstances, resist
their biases” (83) and “can be criticized for failing to
take steps to prevent themselves from being biased; they can be
criticized for lacking courage in situations where having courage is
neither superhumanly difficult nor costly” (175). Whether
self-deception is due to a character defect or not, ascriptions of
responsibility depend upon whether the self-deceiver has control over
the biasing effects of her desires and emotions.
Some question whether self-deceivers do have such control. For
instance, Levy (2004) has argued that deflationary accounts of
self-deception that deny the contradictory belief requirement should
not suppose that self-deceivers are typically responsible since it is
rarely the case that self-deceivers possess the requisite awareness of
the biasing mechanisms operating to produce their self-deceptive
belief. Lacking such awareness, self-deceivers do not appear to know
when or on which beliefs such mechanisms operate, rendering them
unable to curb the effects of these mechanisms, even when they operate
to form false beliefs about morally significant matters. Lacking the
control necessary for moral responsibility in individual episodes of
self-deception, self-deceivers seem also to lack control over being
the sort of person disposed to self-deception.
Non-intentionalists may respond by claiming that self-deceivers often
are aware of the potentially biasing effects their desires and
emotions might have and can exercise control over them (DeWeese-Boyd
2007). They might also challenge the idea that self-deceivers must be
aware in the ways Levy suggests. One well-known account of control,
employed by Levy, holds that a person is responsible just in case she
acts on a mechanism that is moderately responsive to reasons
(including moral reasons), such that were she to possess such reasons,
this same mechanism would act upon those reasons in at least one
possible world (Fischer and Ravizza 1999). Guidance control, in this
sense, requires that the mechanism in question be capable of
recognizing and responding to moral and non-moral reasons sufficient
for acting otherwise. Nelkin (2011, 2012), however, argues that
reasons-responsiveness should be seen as applying primarily to the
agent
, not the mechanism, requiring only that the agent has
the capacity to exercise reason in the situation under scrutiny. The
question isn’t whether the biasing mechanism itself is
reasons-responsive but whether the agent governing its operation
is—that is, whether self-deceivers typically could recognize and
respond to moral and non-moral reasons to resist the influence of
their desires and emotions and instead exercise special scrutiny of
the belief in question. According to Nelkin (2012), expecting
self-deceivers to have such a capacity is more likely if we understand
the desire driving their bias as a desire to
believe
that
p
, since awareness of this sort of desire would make it
easier to guard against its influence on the process of determining
whether
p
. Van Loon (2018) points out that discussion of
moral responsibility and reasons-responsiveness have focused on
actions and omissions that indirectly affect belief formation when it
is more appropriate to focus on epistemic reasons-responsiveness.
Attitudinal control, not action control, is what is at issue in
self-deception. Drawing on McHugh’s (2013, 2014, 2017) account
of attitudinal control, Van Loon argues that self-deceivers on
Mele-style deflationary accounts are responsible for their
self-deceptive beliefs because they recognize and react to evidence
against their self-deceptive belief across a wide-range of
counter-factual scenarios even though their recognition of this
evidence does not alter their belief and their reaction to such
evidence leads them viciously to hold the self-deceptive belief.
Galeotti (2016b) rejects the idea that control is the best way to
think about responsibility in cases of self-deception since
self-deceivers on deflationary approaches seem both confused and
relatively powerless over the process. Instead, following a modified
version of Sher’s (2009) account of responsibility, she contends
that self-deceivers typically have, but fail to recognize, evidence
that their acts related to belief formation are wrong or foolish and
so fall below some applicable standard (epistemic, moral, etc.). The
self-deceiver is under motivational pressure, not incapacitated, and
on exiting self-deception, recognizes “the faultiness of her
condition and feels regret and shame at having fooled herself”
(Galeotti 2016b). This
ex-post
reasons-responsiveness
suggests self-deceivers are responsible in Sher’s sense even if
their self-deception is not intentional.
In view of these various ways of cashing out responsibility,
it’s plausible that self-deceivers can be morally responsible
for their self-deception on deflationary approaches and certainly not
obvious that they couldn’t be.
5.2 The Morality of Self-Deception
Insofar as it seems plausible that, in some cases, self-deceivers are
apt targets for censure, what prompts this attitude? Take the case of
a mother who deceives herself into believing her husband is not
abusing their daughter because she can’t bear the thought that
he is a moral monster (Barnes 1997). Why do we blame her? Here we
confront the nexus between moral responsibility for self-deception and
the morality of self-deception. Understanding what obligations may be
involved in cases of this sort will help to clarify the circumstances
in which ascriptions of moral responsibility are appropriate. While
some instances of self-deception seem morally innocuous, and others
may even be thought salutary in various ways (Rorty 1994), most
theorists have thought there to be something morally objectionable
about self-deception or its consequences in many cases. Self-deception
has been considered objectionable because it facilitates harm to
others (Linehan 1982; Gibson 2020; Clifford 1877) and to oneself,
undermines autonomy (Darwall 1988; Baron 1988), corrupts conscience
(Butler 1726), violates authenticity (Sartre 1943), manifests a
vicious lack of courage and self-control that undermines the capacity
for compassionate action (Jenni 2003), violates an epistemic duty to
properly ground self-ascriptions (Fernández 2013), violates a
general duty to form beliefs that “conform to the available
evidence” (Nelkin 2012), or violates a general duty to respect
our own values (MacKenzie 2022).
Linehan (1982) argues that we have an obligation to scrutinize the
beliefs that guide our actions that is proportionate to the harm to
others such actions might involve. When self-deceivers induce
ignorance of moral obligations in connection with the particular
circumstances, likely consequences of actions, or nature of their own
engagements, by means of their self-deceptive beliefs, they may be
culpable for negligence with respect to their obligation to know the
nature, circumstances, likely consequences, and so forth of their
actions (Jenni 2003; Nelkin 2012). Self-deception, accordingly,
undermines or erodes agency by reducing our capacity for self-scrutiny
and change (Baron 1988). If I am self-deceived about actions or
practices that harm others or myself, my abilities to take
responsibility and change are also severely restricted.
Joseph Butler (1726), in his well-known sermon “On
Self-Deceit,” emphasizes the ways in which self-deception about
one’s moral character and
conduct—‘self-ignorance’ driven by inordinate
‘self-love’—not only facilitates vicious actions but
hinders the agent’s ability to change. Such ignorance, claims
Butler, “undermines the whole principle of good … and
corrupts conscience, which is the guide of life” (1726). Holton
(2022) explores the way our motivation to see ourselves as morally
good may play a role in this lack of moral self-knowledge.
Existentialist philosophers such as Kierkegaard and Sartre, in very
different ways, view self-deception as a threat to
‘authenticity’ insofar as self-deceivers fail to take
responsibility for themselves and their engagements in the past,
present, and future. By alienating us from our own principles,
self-deception may also threaten moral integrity (Jenni 2003).
MacKenzie (2022) might be seen as capturing precisely what’s
wrong with this sort of inauthenticity when she contends that we have
a duty to properly respect our values, even non-moral ones. Since
self-deception is always about something we value in some way, it
represents a failure to properly respect ourselves as valuers. Others
note that self-deception also manifests a certain weakness of
character that disposes us to react to fear, anxiety, or the desire
for pleasure in ways that bias our belief acquisition and retention in
ways that serve these emotions and desires rather than accuracy
(Butler 1726; Clifford 1877). Such epistemic cowardice (Barnes 1997;
Jenni 2003) and lack of self-control may inhibit the ability of
self-deceivers to stand by or apply moral principles they hold by
biasing their beliefs regarding particular circumstances,
consequences, or engagements or by obscuring the principles
themselves. Gibson (2020), following Clifford (1877), contends that
self-deception increases the risk of harm to the self and others and
the cultivation of epistemic vices like credulity that may have
devastating social ramifications. In all these ways and a myriad of
others, philosophers have found some self-deception objectionable in
itself or for the consequences it has, not only on our ability to
shape our lives but also for the potential harm it may cause to
ourselves and others.
Evaluating self-deception and its consequences for ourselves and
others is a difficult task. It requires, among other things:
determining the degree of control self-deceivers have; what the
self-deception is about (Is it important morally or otherwise?); what
ends the self-deception serves (Does it serve mental health or as a
cover for moral wrongdoing?); how entrenched it is (Is it episodic or
habitual?); and, whether it is escapable (What means of correction are
available to the self-deceiver?). As Nelkin (2012) contends,
determining whether and to what degree self-deceivers are culpably
negligent will ultimately need to be determined on a case-by-case
basis in light of answers to such questions about the stakes at play
and the difficulty involved. Others like Mackenzie (2022) hold that
every case of self-deception is a violation of a general duty to
respect our own values, though some cases are more egregious than
others.
If self-deception is morally objectionable for any of these reasons,
we
ought
to avoid it. But, one might reasonably ask how that
is possible given the subterranean ways self-deception seems to
operate. Answering this question is tricky since strategies will vary
with the analyses of self-deception and our responsibility for it.
Nevertheless, two broad approaches seem to apply to most accounts,
namely, the cultivation of one’s epistemic virtues and the
cultivation of one’s epistemic community (Galeotti 2016b). One
might avoid the self-deceptive effects of motivation by cultivating
virtues like impartiality, vigilance, conscientiousness, and
resistance to the influence of emotion, desire, and the like.
Additionally, one might cultivate an epistemic community that holds
one accountable and guides one away from self-deception (Rorty 1994;
Galeotti 2016b, 2018). By binding ourselves to communities we have
authorized to referee our belief formation in this way, we protect
ourselves from potential lapses in epistemic virtue. These kinds of
strategies might indirectly affect our susceptibility to
self-deception and offer some hope of avoiding it.
6. Origin of Self-Deception: Adaptation or Spandrel
Quite aside from the doxastic, strategic, and moral puzzles
self-deception raises, there is the evolutionary puzzle of its origin.
Why do human beings have this capacity in the first place? Why would
natural selection allow a capacity to survive that undermines the
accurate representation of reality, especially when inaccuracies about
individual ability or likely risk can lead to catastrophic errors?
Many argue that self-deceptively inflated views of ourselves, our
abilities, our prospects, or our control—so-called
‘positive illusions’—confer direct benefits in terms
of psychological well-being, physical health, and social advancement
that serve fitness (Taylor and Brown 1994; Taylor 1989; McKay and
Dennett 2009). Just because ‘positive illusions’ make us
‘feel good,’ of course, it does not follow that they are
adaptive. From an evolutionary perspective, whether an organism
‘feels good’ or is ‘happy’ is not significant
unless it enhances survival and reproduction. McKay and Dennett (2009)
argue that positive illusions are not only tolerable; evolutionarily
speaking, they contribute to fitness directly. Overly positive beliefs
about our abilities or chances for success appear to make us more apt
to exceed our abilities and achieve success than more accurate beliefs
would (Taylor and Brown 1994; Bandura 1989). According to Johnston and
Fowler (2011), overconfidence is “advantageous, because it
encourages individuals to claim resources they could not otherwise win
if it came to a conflict (stronger but cautious rivals will sometime
fail to make a claim, and it keeps them from walking away from
conflicts they would surely win).” Inflated attitudes regarding
the personal qualities and capacities of one’s partners and
children would also seem to enhance fitness by facilitating the
thriving of offspring (McKay and Dennett 2009).
Alternatively, some argue that self-deception evolved to facilitate
interpersonal deception by eliminating the cues and cognitive load
that consciously lying produces and by mitigating retaliation should
the deceit become evident (von Hippel and Trivers 2011; Trivers 2011,
2000, 1991). On this view, the real gains associated with
‘positive illusions’ and other self-deceptions are
byproducts that serve this greater evolutionary end by enhancing
self-deceivers’ ability to deceive. Von Hippel and Trivers
(2011) contend that “by deceiving themselves about their own
positive qualities and the negative qualities of others, people are
able to display greater confidence than they might otherwise feel,
thereby enabling them to advance socially and materially.”
Critics have pointed to data suggesting high self-deceivers are deemed
less trustworthy than low self-deceivers (McKay and Dennett 2011).
Others have complained that there is little data to support this
hypothesis (Dunning 2011; Van Leeuwen 2007a, 2013a), and what data
there is shows us to be poor lie-detectors (Funkhouser 2019; Vrij
2011). Some challenge this theory by noting that a simple disregard
for the truth would serve as well as self-deception and have the
advantage of retaining true representations (McKay and Prelec 2011) or
that often self-deceivers are the only ones deceived (Van Leeuwen
2007a; Kahlil 2011). Van Leeuwen (2013a) raises the concern that the
wide variety of phenomena identified by this theory as self-deception
render the category so broad that it is difficult to tell whether it
is a unified phenomenon traceable to particular mechanisms that could
plausibly be sensitive to selection pressures. Funkhouser (2019)
worries that the unconscious retention of the truth that von Hippel
and Trivers (2011) propose would generate tells of its own and that
the psychological complexity of this explanation is unnecessary if the
goal is to deceive others (which is itself contentious) since that
goal would be easier to achieve through self-delusion. So, von Hippel
and Trivers’ (2011) theory may explain self-delusion but not
cases of self-deception marked by deep conflict (Funkhouser
2017b).
In view of these shortcomings, Van Leeuwen (2007a) argues the capacity
for self-deception is a
spandrel
—a byproduct of other
aspects of our cognitive architecture—not an adaptation in the
strong sense of being positively selected. While Funkhouser (2017b)
agrees that the basic cognitive architecture that allows motivation to
influence belief formation—as well as the specific tools used to
form or maintain biased belief—were not selected for the sake of
self-deception, it nevertheless makes sense to say, for at least some
contents, that self-deception is adaptive (2017b).
Whether it is an adaptation or a spandrel, it’s possible this
capacity has nevertheless been
retained
as a consequence of
its fitness value. Lopez and Fuxjager (2011) argue that the broad
research on the so-called “winner effect”—the
increased probability of achieving victory in social or physical
conflicts following prior victories—lends support to the idea
that self-deception is at least weakly adaptive since self-deception
in the form of positive illusions, like past wins, confers a fitness
advantage. Lamba and Nityananda (2014) test the theory that
self-deceived are better at deceiving others—specifically,
whether overconfident individuals are overrated by others and
underconfident individuals underrated. In their study, students in
tutorials were asked to predict their own performance on the next
assignment as well as that of each of their peers in the tutorial in
terms of absolute grade and relative rank. Comparing these predictions
and the actual grades given on the assignment suggests a strong
positive relationship between self-deception and deception. Those who
self-deceptively rated themselves higher were rated higher by their
peers as well. These findings lend suggestive support to the claim
self-deception facilitates other deception. While these studies
certainly do not supply all the data necessary to support the theory
that the propensity to self-deception should be viewed as adaptation,
they do suggest ways to test these evolutionary hypotheses by focusing
on specific phenomena.
Whether or not the psychological and social benefits identified by
these theories explain the evolutionary origins of the capacity for
self-deceit, they may well shed light on its prevalence and
persistence, as well as point to ways to identify contexts in which
this tendency presents high collective risk (Lamba and Nityananda
2014).
7. Collective Self-Deception
Collective self-deception has received scant direct philosophical
attention as compared with its individual counterpart. Collective
self-deception might refer simply to a group of similarly
self-deceived individuals or to a group-entity (such as a corporation,
committee, jury, or the like) that is self-deceived. These
alternatives reflect two basic perspectives that social
epistemologists have taken on ascriptions of propositional attitudes
to collectives. On the one hand, such attributions might be taken
summatively
as simply an indirect way of attributing those
states to members of the collective (Quinton 1975/1976). This
summative understanding, then, considers attitudes attributed to
groups to be nothing more than metaphors expressing the sum of the
attitudes held by their members. To say that students think tuition is
too high is just a way of saying that most students think so. On the
other hand, such attributions might be understood
non-summatively
as applying to collective entities,
themselves ontologically distinct from the members upon which they
depend. These so-called ‘plural subjects’ (Gilbert 1989,
1994, 2005) or ‘social integrates’ (Pettit 2003), while
supervening upon the individuals comprising them, may well express
attitudes that diverge from individual members. For instance, saying
NASA believed the O-rings on the space shuttle’s booster rockets
to be safe need not imply that most or all the members of this
organization personally held this belief, only that the institution
itself did. The non-summative understanding, then, considers
collectives to be, like persons, apt targets for attributions of
propositional attitudes and potentially of moral and epistemic censure
as well. Following this distinction, collective self-deception may be
understood in either a summative or non-summative sense.
In the summative sense, collective self-deception refers to a
self-deceptive belief shared by a group of individuals whom each come
to hold the self-deceptive belief for similar reasons and by similar
means, varying according to the account of self-deception followed. We
might call this self-deception
across
a collective. In the
non-summative sense, the subject of collective self-deception is the
collective itself, not simply the individuals comprising it. The
following sections offer an overview of these forms of collective
self-deception, noting the significant challenges posed by each.
7.1 Summative Collective Self-Deception: Self-Deception Across a Collective
Understood summatively, we might define collective self-deception as
the holding of a false belief in the face of evidence to the contrary
by a group of people as a result of shared desires, emotions, or
intentions (depending upon the account of self-deception) favoring
that belief. Collective self-deception is distinct from other forms of
collective false belief—such as might result from deception or
lack of evidence—insofar as the false belief issues from the
agents’ own self-deceptive mechanisms (however these are
construed), not the absence of evidence to the contrary or presence of
misinformation. Accordingly, the individuals constituting the group
would not hold the false belief if their vision weren’t
distorted by their attitudes (desire, anxiety, fear, or the like)
toward the belief. What distinguishes collective self-deception from
solitary self-deception is just its social context; namely, that it
occurs within a group that shares both the attitudes bringing about
the false belief and the false belief itself.
Merely sharing desires, emotions, or intentions favoring a belief with
a group does not entail that the self-deception is properly social
since these individuals may well self-deceive regardless of the fact
that their motivations are shared with others (Dings 2017; Funkhouser
2019); they are just individually self-deceiving in parallel. What
makes collective self-deception
social
,
according to
Dings (2017), is that others are a means used in each
individual’s self-deception. So, when a person situates herself
in a group of like-minded people in response to an encounter with new
and threatening evidence, her self-deception becomes social.
Self-deception also becomes social in Dings’ (2017) view when a
person influences others to make them like-minded with regard to her
preferred belief, using their behavior to reinforce her
self-deception
.
Within highly homogeneous social groups,
however, it may be difficult to tell who is using the group
instrumentally in these ways, especially when that use is unwitting.
Moreover, one may not need to seek out such a group of like-minded
people if they already comprise one’s community. In this case,
those people may become instrumental to one’s self-deception
simply by dint of being there to provide insulation from threatening
evidence and support for one’s preferred belief. In any case,
this sort of self-deception is both easier to foster and more
difficult to escape, being abetted by the self-deceptive efforts of
others within the group.
Virtually all self-deception has a social component, being wittingly
or unwittingly supported by one’s associates (see Ruddick 1988).
In the case of collective self-deception, however, the social
dimension comes to the fore since each member of the collective
unwittingly helps to sustain the self-deceptive belief of the others
in the group. For example, my cancer-stricken friend might
self-deceptively believe her prognosis to be quite good. Faced with
the fearful prospect of death, she does not form accurate beliefs
regarding the probability of her full recovery, attending only to
evidence supporting full recovery and discounting or ignoring
altogether the ample evidence to the contrary. Caring for her as I do,
I share many of the anxieties, fears, and desires that sustain my
friend’s self-deceptive belief, and as a consequence, I form the
same self-deceptive belief via the same mechanisms. In such a case, I
unwittingly support my friend’s self-deceptive belief, and she
mine—our self-deceptions are mutually reinforcing. We are
collectively or mutually self-deceived, albeit on a very small scale.
Ruddick (1988) calls this ‘joint self-deception,’ and it
is properly social just in case each person is instrumental in the
formation of the self-deceptive belief in the other (Dings 2017).
On a larger scale, sharing common attitudes, large segments of a
society might deceive themselves together. For example, we share a
number of self-deceptive beliefs regarding our consumption patterns.
Many of the goods we consume are produced by people enduring labor
conditions we do not find acceptable and in ways that we recognize are
environmentally destructive and likely unsustainable. Despite our
being at least generally aware of these social and environmental
ramifications of our consumptive practices, we hold the overly
optimistic beliefs that the world will be fine, that its peril is
overstated, that the suffering caused by the exploitive and
ecologically degrading practices are overblown, that our own
consumption habits are unconnected to these sufferings, and even that
our minimal efforts at conscientious consumption are an adequate
remedy (see Goleman 1989). When self-deceptive beliefs such as these
are held collectively, they become entrenched, and their consequences,
good or bad, are magnified (Surbey 2004).
The collective entrenches self-deceptive beliefs by providing positive
reinforcement through others sharing the same false belief as well as
by protecting its members from evidence that would destabilize the
target belief. There are, however, limits to how entrenched such
beliefs can become and remain. Social support cannot be the sole or
primary cause of the self-deceptive belief, for then the belief would
simply be the result of unwitting interpersonal deception and not the
deviant belief formation process that characterizes self-deception. If
the environment becomes so epistemically contaminated as to make
counter-evidence inaccessible to the agent, then we have a case of
simple false belief, not self-deception. Thus, even within a
collective, a person is self-deceived just in case her own motivations
skew the belief formation process that results in her holding the
false belief. But, to bar this from being a simple case of solitary
self-deception, others must be instrumental to her belief formation
process such that if they were not part of that process, she would not
be self-deceived (Dings 2017). For instance, I might be motivated to
believe that climate change is not a serious problem and form that
false belief as a consequence. In such a case, I’m not socially
self-deceived, even if virtually everyone I know shares a similar
motivation and belief. But, say I encounter distressing evidence in my
environmental science class that I can’t shake on my own. I may
seek to surround myself with like-minded people, thereby protecting
myself from further distressing evidence and providing myself with
reassuring evidence. Now, my self-deception is social, and this social
component drives and reinforces my own motivations to
self-deceive.
Relative to solitary self-deception, the collective variety presents
greater external obstacles to avoiding or escaping self-deception and
is, for this reason, more entrenched. If the various proposed
psychological mechanisms of self-deception pose an internal challenge
to the self-deceiver’s power to control her belief formation,
then these social factors pose an external challenge to the
self-deceiver’s control. Determining how superable this
challenge is will affect our assessment of individual responsibility
for self-deception as well as the prospects of unassisted escape from
it.
7.2 Non-Summative Collective Self-Deception: Self-Deception of a Collective Entity
Collective self-deception can also be understood from the perspective
of the collective itself in a non-summative sense. Though there are
varying accounts of group belief, generally speaking, a group can be
said to believe, desire, value, or the like just in case its members
“jointly commit” to these things as a body (Gilbert 2005).
A corporate board, for instance, might be jointly committed as a body
to believe, value, and strive for whatever the CEO recommends. Such
commitment need not entail that each individual board member
personally endorses such beliefs, values, or goals, only that they do
so as members of the board (Gilbert 2005). While philosophically
precise accounts of non-summative self-deception remain largely
unarticulated—an exception is Galeotti’s (2018) detailed
analysis of how collective self-deception occurs in the context of
politics—the possibilities mirror those of individual
self-deception. When collectively held attitudes motivate a group to
espouse a false belief despite the group’s possession of
evidence to the contrary, we can say that the group is collectively
self-deceived in a non-summative sense.
For example, Robert Trivers (2000) suggests that ‘organizational
self-deception’ led to NASA’s failure to represent
accurately the risks posed by the space shuttle’s O-ring design,
a failure that eventually led to the Challenger disaster. The
organization as a whole, he argues, had strong incentives to represent
such risks as small. As a consequence, NASA’s Safety Unit
mishandled and misrepresented data it possessed that suggested that
under certain temperature conditions, the shuttle’s O-rings were
not safe. NASA, as an organization, then, self-deceptively believed
the risks posed by O-ring damage were minimal. Within the institution,
however, there were a number of individuals who did not share this
belief, but both they and the evidence supporting their belief were
treated in a biased manner by the decision-makers within the
organization. As Trivers (2000) puts it, this information was
relegated “to portions of … the organization that [were]
inaccessible to consciousness (we can think of the people running NASA
as the conscious part of the organization).” In this case,
collectively held values created a climate within NASA that clouded
its vision of the data and led to its endorsement of a fatally false
belief.
Collective self-deceit may also play a significant role in
facilitating unethical practices by corporate entities. For example, a
collective commitment by members of a corporation to maximizing
profits might lead members to form false beliefs about the ethical
propriety of the corporation’s practices. Gilbert (2005)
suggests that such a commitment might lead executives and other
members to “simply lose sight of moral constraints and values
they previously held.” Similarly, Tenbrunsel and Messick (2004)
argue that self-deceptive mechanisms play a pervasive role in what
they call ‘ethical fading,’ acting as a kind of
‘bleach’ that renders organizations blind to the ethical
dimensions of their decisions. They argue that such self-deceptive
mechanisms must be recognized and actively resisted at the
organizational level if unethical behavior is to be avoided. More
specifically, Gilbert (2005) contends that collectively accepting that
“certain moral constraints must rein in the pursuit of corporate
profits” might shift corporate culture in such a way that
efforts to respect these constraints are recognized as part of being a
good corporate citizen. In view of the ramifications this sort of
collective self-deception has for the way we understand corporate
misconduct and responsibility, understanding its specific nature in
greater detail remains an important task.
Collective self-deception, understood in either the summative or
non-summative sense, raises significant questions, such as whether
individuals within collectives bear responsibility for their
self-deception or the part they play in the collective’s
self-deception and whether collective entities can be held responsible
for their epistemic failures (see Galeotti 2016b, 2018 on these
questions). Finally, collective self-deception prompts us to ask what
means are available to collectives and their members to resist, avoid,
and escape self-deception. Galeotti (2016b, 2018) argues for a variety
of institutional constraints and precommitments to keep groups from
falling prey to self-deception.
Given the capacity of collective self-deception to entrench false
beliefs and to magnify their consequences—sometimes with
disastrous results—collective self-deception is not just a
philosophical puzzle; it is a problem that demands attention.
Bibliography
Ames, R.T., and W. Dissanayake (eds.), 1996,
Self and
Deception
, New York: State University of New York Press.
Archer, Sophie, 2013, “Nondoxasticism about
Self‐Deception,”
Dialectica
, 67(3):
265–282.
–––, 2018, “Why ‘believes’ is
not a vague predicate,”
Philosophical Studies
,175 (12):
3029–3048.
Audi, R., 2007, “Belief, Intention, and Reasons for
Action,” in
Rationality and the Good
, J. Greco, A.
Mele, and M. Timmons (eds.), New York: Oxford University Press.
–––, 1989, “Self-Deception and Practical
Reasoning,”
Canadian Journal of Philosophy
, 19:
247–266.
–––, 1982, “Self-Deception, Action, and
Will,”
Erkenntnis
, 18: 133–158.
–––, 1976, “Epistemic Disavowals and
Self-Deception,”
The Personalist
, 57:
378–385.
Bach, K., 1997, “Thinking and Believing in
Self-Deception,”
Behavioral and Brain Sciences
, 20:
105.
–––, 1981, “An Analysis of
Self-Deception,”
Philosophy and Phenomenological
Research
, 41: 351–370.
Baghramian, M., and A. Nicholson, 2013, “The Puzzle of
Self-Deception,”
Philosophy Compass
, 8(11):
1018–1029.
Bagnoli, C., 2012, “Self-deception and agential
authority,”
Humana Mente
, 20: 99–116
Bargh, John and Morsella, Ezequiel, 2008, “The Unconscious
Mind,”
Perspectives on Psychological Science
, 3:
73–79.
Barnes, A., 1997,
Seeing through Self-Deception
, New
York: Cambridge University Press.
Baron, M., 1988, “What is Wrong with Self-Deception,”
in
Perspectives on Self-Deception
, B. McLaughlin and A. O.
Rorty (eds.), Berkeley: University of California Press.
Bayne, T. & J. Fernandez Eds., 2009,
Delusion and
Self-Deception: Affective and Motivational Influences on Belief
Formation
, New York: Psychology Press.
Bok, S., 1989, “Secrecy and Self-Deception,” in
Secrets: On the Ethics of Concealment and Revelation
, New
York: Vintage.
–––, 1980, “The Self Deceived,”
Social Science Information
, 19: 923–935.
Bermúdez, José Luis, 2017,“Self-deception and
Selectivity: Reply to Jurjako,”
Croatian Journal of
Philosophy
, 17(1): 91–95.
–––, 2000, “Self-Deception, Intentions,
and Contradictory Beliefs,”
Analysis
, 60(4):
309–319.
–––, 1997, “Defending Intentionalist
Accounts of Self-Deception,”
Behavioral and Brain
Sciences
, 20: 107–8.
Bird, A., 1994, “Rationality and the Structure of
Self-Deception,” in S. Gianfranco (ed.),
European Review of
Philosophy
(Volume 1: Philosophy of Mind), Stanford: CSLI
Publications.
Borge, S., 2003, “The Myth of Self-Deception,”
The
Southern Journal of Philosophy
, 41: 1–28.
Borman, David, 2022, “Self-Deception and Moral
Interests,”
European Journal of Philosophy
, first
online 17 January 2022. doi:10.1111/ejop.12756
Brown, R., 2003, “The Emplotted Self: Self-Deception and
Self-Knowledge.,”
Philosophical Papers
, 32:
279–300.
Butler, J., 1726, “Upon Self-Deceit,” in D.E. White
(ed.), 2006,
The Works of Bishop Butler
, Rochester: Rochester
University Press.
 [
Available online
]
Cerovac, I., 2015, “Intentionalism as a theory of
self-deception,”
Balkan Journal of Philosophy
, 7:
145–150.
Chisholm, R. M., and Feehan, T., 1977, “The Intent to
Deceive,”
Journal of Philosophy
, 74:
143–159.
Clifford, W. K., 1877, “The Ethics of Belief,” in
The Ethics of Belief and Other Essays
, Amherst, NY:
Prometheus Books, 70–97.
Cook, J. T., 1987, “Deciding to Belief without
Self-deception,”
Journal of Philosophy
, 84:
441–446.
Correia, Vasco, 2014, “From Self-deception to self-control:
Emotional biases and the virtues of precommitment,”
Croatian
Journal of Philosophy
, 14(3): 309–323.
Dalton, P., 2002, “Three Levels of Self-Deception (Critical
Commentary on Alfred Mele’s Self-Deception Unmasked),”
Florida Philosophical Review
, 2(1): 72–76.
Darwall, S., 1988, “Self-Deception, Autonomy, and Moral
Constitution,” in
Perspectives on Self-Deception
, B.
McLaughlin and A. O. Rorty (eds.), Berkeley: University of California
Press.
Davidson, D., 1986, “Deception and Division,” in J.
Elster (ed.) 1986, 79–92; reprinted in D. Davidson,
Problems
of Rationality
, with introduction by Marcia Cavell and interview
with Ernest Lepore, Oxford: Clarendon Press, 2004, 199–212.
–––, 1982, “Paradoxes of
Irrationality,” in
Philosophical Essays on Freud
, R.
Wollheim and J. Hopkins (eds.), Cambridge: Cambridge University
Press.
Demos, R., 1960, “Lying to Oneself,”
Journal of
Philosophy
, 57: 588–95.
Dennett, D., 1992, “The Self as a Center of Narrative
Gravity,” in
Consciousness and Self: Multiple
Perspectives
, F. Kessel, P. Cole, and D. Johnson (eds.),
Hillsdale, NJ: L. Erlbaum.
de Sosa, R., 1978, “Self-Deceptive Emotions,”
Journal of Philosophy
, 75: 684–697.
–––, 1970, “Self-Deception,”
Inquiry
, 13: 308–321.
DeWeese-Boyd, I., 2014, “Self-Deceptive Religion and the
Prophetic Voice,”
Journal for Religionsphilosophie
, 3:
26–37.
–––, 2007, “Taking Care: Self-Deception,
Culpability and Control,”
teorema
, 26(3):
161–176.
Dings, Roy, 2017, “Social Strategies in
Self-deception,”
New Ideas in Psychology
, 47:
16–23.
Doody, P., 2017, “Is There Evidence of Robust, Unconscious
Self- Deception? A Reply to Funkhouser and Barrett,”
Philosophical Psychology
, 30(5): 657–676.
Dunn, R., 1995, “Motivated Irrationality and Divided
Attention,”
Australasian Journal of Philosophy
, 73:
325–336.
Dunning, D., 2011, “Get Thee to a Laboratory,”
Commentary
on target article, “The Evolution and
Psychology of Self-Deception,” by W. von Hippel and R. Trivers,
Behavioral and Brain Sciences
, 34(1): 18–19.
–––, 1995, “Attitudes, Agency and
First-Personality,”
Philosophia
, 24:
295–319.
–––, 1994, “Two Theories of Mental
Division,”
Australasian Journal of Philosophy
, 72:
302–316.
Dupuy, J-P. (ed.), 1998,
Self-Deception and Paradoxes of
Rationality
(Lecture Notes 69), Stanford: CSLI Publications.
Dyke, D., 1633,
The Mystery of Selfe-Deceiving
, London:
William Standby.
Echano, M., 2017, “The Motivating Influence of Emotion on
Twisted Self-Deception,”
Kritike
, 11(2):
104–120.
Edwards, S., 2013, “Nondoxasticism about
Self-Deception,”
Dialectica
, 67(3): 265–282.
Egan, Andy, 2009, “Imagination, Delusion, and
Self-Deception,” in
Delusions, Self-Deception, and Affective
Influences on Belief-formation
, T. Bayne and J. Fernandez (eds.),
New York: Psychology Press.
Elster, J. (ed.), 1986,
The Multiple Self
, Cambridge:
Cambridge University Press.
Fairbanks, R., 1995, “Knowing More Than We Can Tell,”
The Southern Journal of Philosophy
, 33: 431–459.
Fernández, Jordi, 2013, “Self-deception and
self-knowledge,”
Philosophical Studies
162(2):
379–400.
Fingarette, H., 1998, “Self-Deception Needs No
Explaining,”
The Philosophical Quarterly
, 48:
289–301.
–––, 1969,
Self-Deception
, Berkeley:
University of California Press; reprinted, 2000.
Friedrich, James, 1993, “Primary error detection and
minimization PEDMIN strategies in social cognition: A reinterpretation
of confirmation bias phenomena,”
Psychological Review
,
100, 298–319.
Fischer, J. and Ravizza, M., 1998,
Responsibility and
Control
. Cambridge: Cambridge University Press.
Funkhouser, Eric, 2019,
Self-Deception
, New York:
Routledge.
–––, 2017a, “Beliefs as Signals: A New
Function for Belief,”
Philosophical Psychology
, 30(6):
809–831.
–––, 2017b, “Is Self-Deception an
Effective Non-Cooperative Strategy?,”
Biology and
Philosophy
, 32: 221–242.
–––, 2009, “Self-Deception and the Limits
of Folk Psychology,”
Social Theory and Practice
, 35(1):
1–13.
–––, 2005, “Do the Self-Deceived Get What
They Want?,”
Pacific Philosophical Quarterly
, 86(3):
295–312.
Funkhouser, Eric, and David Barrett, 2017, “Reply to
Doody,”
Philosophical Psychology
, 30(5):
677–681.
–––, 2016, “Robust, unconscious
self-deception: Strategic and flexible,”
Philosophical
Psychology
, 29(5): 1–15.
Funkhouser, Eric, and Kyle Hallam, 2022, “Self-Handicapping
and Self-Deception: A Two-Way Street,”
Philosophical
Psychology
,
Galeotti, Anna Elisabetta, 2018,
Political
Self-Deception
, Cambridge: Cambridge University Press.
–––, 2016a, Straight and Twisted
Self-Deception,”
Phenomenology and Mind
, 11:
90–99.
–––, 2016b, “The Attribution of
Responsibility to Self-Deceivers,”
Journal of Social
Philosophy
, 47(4): 420–438.
–––, 2012, “Self-Deception: Intentional
Plan or Mental Event?”
Humana Mente
, 20:
41–66.
Gendler, T. S., 2007, “Self-Deception as Pretense,”
Philosophical Perspectives
, 21: 231–258.
Gibson, Quinn Hiroshi, 2020, “Self-Deception as
Omission,”
Philosophical Psychology
, 33(5):
657–678.
Gilbert, Margaret, 2005, “Corporate Misbehavior and
Collective Values,”
Brooklyn Law Review
, 70(4):
1369–80.
–––, 1994, “Remarks on Collective
Belief,” in
Socializing Epistemology
, F. Schmitt (ed.),
Lanham, MD: Rowman and Littlefield.
–––, 1989,
On Social Facts
, London:
Routledge.
Goleman, Daniel, 1989, “What is negative about positive
illusions?: When benefits for the individual harm the
collective,”
Journal of Social and Clinical Psychology
,
8: 190–197.
Graham, G., 1986. “Russell’s Deceptive Desires,”
The Philosophical Quarterly
, 36: 223–229.
Haight, R. M., 1980,
A Study of Self-Deception
, Sussex:
Harvester Wheatsheaf.
Hales, S. D., 1994, “Self-Deception and Belief
Attribution,”
Synthese
, 101: 273–289.
Hassin, Ran, John Bargh, & Shira Cohen-Zimerman, 2009,
“Automatic and Flexible: The Case of Nonconscious Goal
Pursuit,”
Social Cognition
, 27: 20–36.
Hernes, C., 2007, “Cognitive Peers and
Self-Deception,”
teorema
, 26(3): 123–130.
Hauerwas, S. and Burrell, D., 1977, “Self-Deception and
Autobiography: Reflections on Speer’s Inside the Third
Reich,” in
Truthfulness and Tragedy
, S. Hauerwas with
R. Bondi and D. Burrell, Notre Dame: University of Notre Dame
Press.
Holton, Richard, 2022, “Self-Deception and the Moral
Self,” in Manuel Vargas, and John M. Doris (eds.),
The
Oxford Handbook of Moral Psychology
, Oxford University Press,
262–284.
–––, 2001, “What is the Role of the Self
in Self-Deception?,”
Proceedings of the Aristotelian
Society
, 101(1): 53–69.
Jenni, K., 2003, “Vices of Inattention,”
Journal
of Applied Philosophy
, 20(3): 279–95.
Johnson, D., and Fowler, J. 201, “The Evolution of
Overconfidence,”
Nature
, 477: 317–320.
Johnston, M., 1988, “Self-Deception and the Nature of
Mind,” in
Perspectives on Self-Deception
, B. McLaughlin
and A. O. Rorty (eds.), Berkeley: University of California Press.
Jordan, Maiya, 2022, “Instantaneous Self-Deception,”
Inquiry
, 65(2): 176–201.
–––, 2020, “Literal Self-Deception,”
Analysis
, 80(2): 248–256.
–––, 2019, “Secondary
Self-Deception,”
Ratio
, 32(2): 122–130.
Jurjako, Mark, 2013, “Self-deception and the selectivity
problem,”
Balkan Journal of Philosophy
, 5:
151–162.
Kahlil, E., 2011, “The Weightless Hat,”
Commentary
on target article, “The Evolution and
Psychology of Self-Deception,” by W. von Hippel and R. Trivers,
Behavioral and Brain Sciences
, 34(1): 30–31.
Kirsch, J., 2005, “What’s So Great about
Reality?,”
Canadian Journal of Philosophy
, 35(3):
407–428.
Lauria, Federico and Delphine Preissmann, 2018, “What Does
Emotion Teach Us about Self-Deception? Affective Neuroscience in
Support of Non-Intentionalism,”
Les Ateliers de
l’Éthique / The Ethics Forum
, 13(2):
70–94.
Lauria, F., Preissmann, D., and Cle menta, F., 2016,
"Self-deception as Affective Coping: An Empirical Perspective on
Philosophical Issues."
Consciousness and Cognition
, 41:
119–134.
Lazar, A., 1999, “Deceiving Oneself Or
Self-Deceived?,”
Mind
, 108: 263–290.
–––, 1997, “Self-Deception and the Desire
to Believe,”
Behavioral and Brain Sciences
, 20:
119–120.
Lamba, S and Nityananda, V., 2014, “Self-Deceived
Individuals are Better at Deceiving Others,”
PLOS One
,
9/8: 1–6.
Levy, N., 2004, “Self-Deception and Moral
Responsibility,”
Ratio (new series)
, 17:
294–311.
Linehan, E. A. 1982, “Ignorance, Self-deception, and Moral
Accountability,”
Journal of Value Inquiry
, 16:
101–115.
Lockhard, J. and Paulhus, D. (eds.), 1988,
Self-Deception: An
Adaptive Mechanism?
, Englewood Cliffs: Prentice-Hall.
Longeway, J., 1990, “The Rationality of Self-deception and
Escapism,”
Behavior and Philosophy
, 18:
1–19.
Lopez, J., and M. Fuxjager, 2012, “Self-deception’s
adaptive value: Effects of positive thinking and the winner
effect,”
Consciousness and Cognition
, 21(1):
315–324.
Lynch, Kevin, 2022, “Being Self-Deceived about One’s
Own Mental State,”
Philosophical Quarterly
, 72(3):
652–672.
–––, 2017, “An Agentive Non-Intentionalist
Theory of Self-Deception,”
Canadian Journal of
Philosophy
, 47(6): 779–798.
–––, 2014, “Self-deception and shifts of
attention,”
Philosophical Explorations
, 17(1):
63–75.
–––, 2013, “Self-Deception and Stubborn
Belief,”
Erkenntnis
, 78(6): 1337–1345.
–––, 2012, “On the ‘tension’
inherent in Self-Deception,”
Philosophical Psychology
,
25(3): 433–450.
–––, 2010, “Self-deception, religious
belief, and the false belief condition,”
Heythrop
Journal
, 51(6): 1073–1074.
–––, 2009, “Prospects for an
Intentionalist Theory of Self-Deception,”
Abstracta
,
5(2): 126–138.
MacKenzie, J., 2022, “Self-Deception as a Moral
Failure,”
The Philosophical Quarterly
, 72(2):
402-421.
Martin, M., 1986,
Self-Deception and Morality
, Lawrence:
University Press of Kansas.
––– (ed.), 1985,
Self-Deception and
Self-Understanding
, Lawrence: University Press of Kansas.
Martínez Manrique, F., 2007, “Attributions of
Self-Deception,”
teorema
, 26(3): 131–143.
McHugh, Conor, 2017, “Attitudinal Control,”
Synthese
, 194(8): 2745–2762.
–––, 2014, “Exercising Doxastic
Freedom,”
Philosophy and Phenomenological Research
,
88(1): 1–37.
–––, 2013, “Epistemic Responsibility and
Doxastic Agency,”
Philosophical Issues
, 23(1):
132–157.
McLaughlin, B. and Rorty, A. O. (eds.), 1988,
Perspectives on
Self-Deception
, Berkeley: University of California Press.
McKay, R. and Dennett, D., 2009, “The Evolution of
Misbelief,”
Behavioral and Brain Sciences
, 32(6):
493–561.
McKay, R., Prelec, D., “Protesting Too Much: Self-Deception
and Self-Signaling,”
Commentary
on target article,
“The Evolution and Psychology of Self-Deception,” by W.
von Hippel and R. Trivers,
Behavioral and Brain Sciences
,
34(1): 34–35.
Mele, Alfred, 2020, “Self-Deception and Selectivity,”
Philosophical Studies
, 177: 2697–2711.
–––, 2012, “When Are We
Self-Deceived?”
Humana Mente Journal of Philosophical
Studies
, 20: 1–15.
–––, 2010, “Approaching Self-Deception:
How Robert Audi and I Part Company,”
Consciousness and
Cognition
, 19: 745–750.
–––, 2009, “Delusional Confabulations and
Self-Deception,” in W. Hirstein (ed.),
Confabulation: Views
from Neuroscience, Psychiatry, Psychology, and Philosophy
,
Oxford: Oxford University Press, pp. 139–157.
–––, 2009, “Have I Unmasked Self-Deception
or Am I Self-Deceived?” in C. Martin (ed.),
The Philosophy
of Deception
, Oxford: Oxford University Press, pp.
260–276.
–––, 2007, “Self-Deception and Three
Psychiatric Delusions: On Robert Audi’s Transition from
Self-Deception to Delusion,” in M. Timmons, J. Greco, and A.
Mele (eds.),
Rationality and the Good
, Oxford: Oxford
University Press, pp. 163–175.
–––, 2007, “Self-Deception and Hypothesis
Testing,” in M. Marraffa, M. De Caro, and F. Feretti (eds.),
Cartographies of the Mind
, Dordrecht: Kluwer, pp.
159–167.
–––, 2006, “Self-Deception and
Delusions,”
European Journal of Analytic Philosophy
, 2:
109–124.
–––, 2003, “Emotion and Desire in
Self-Deception,” in A. Hatzimoysis (ed.),
Philosophy and the
Emotions
, Cambridge: Cambridge University Press, pp.
163–179.
–––, 2001,
Self-Deception Unmasked
,
Princeton: Princeton University Press.
–––, 2000, “Self-Deception and
Emotion,”
Consciousness and Emotion
, 1:
115–137.
–––, 2000, “Self-Deception and
Emotion,”
Consciousness and Emotion
, 1:
115–139.
–––, 1999, “Twisted Self-Deception,”
Philosophical Psychology
, 12: 117–137.
–––, 1997, “Real Self-Deception,”
Behavioral and Brain Sciences
, 20: 91–102.
–––, 1987a,
Irrationality: An Essay on
Akrasia, Self-Deception, Self-Control
, Oxford: Oxford University
Press.
–––, 1987b, “Recent Work on
Self-deception,”
American Philosophical Quarterly
, 24:
1–17.
–––, 1983, “Self-Deception,”
Philosophical Quarterly
, 33: 365–377.
Mijović-Prelec, D., and Prelec, D., 2010,
“Self-deception as Self-Signaling: A Model and Experimental
Evidence,”
Philosophical Transactions of the Royal Society
B
, 365: 227–240.
Moran, R., 1988, “Making Up Your Mind: Self-Interpretation
and Self-constitution,”
Ratio (new series)
, 1:
135–151.
Nelkin, D., 2012, “Responsibility and Self-Deception: A
Framework,”
Humana Mente Journal of Philosophical
Studies
, 20: 117–139.
–––, 2002, “Self-Deception, Motivation,
and the Desire to Believe,”
Pacific Philosophical
Quarterly
, 83: 384–406.
Nicholson, A., 2007.“Cognitive Bias, Intentionality and
Self-Deception,”
teorema
, 26(3): 45–58.
Noordhof, P., 2009, “The Essential Instability of
Self-Deception,”
Social Theory and Practice
, 35(1):
45–71.
–––, 2003, “Self-Deception, Interpretation
and Consciousness,”
Philosophy and Phenomenological
Research
, 67: 75–100.
Paluch, S., 1967, “Self-Deception,”
Inquiry
,
10: 268–78.
Patten, D., 2003, “How do we deceive ourselves?,”
Philosophical Psychology
, 16(2): 229–46.
Pears, D., 1991, “Self-Deceptive Belief Formation,”
Synthese
, 89: 393–405.
–––, 1984,
Motivated Irrationality
, New
York: Oxford University Press.
Pettit, Philip, 2006, “When to Defer to Majority Testimony
— and When Not,”
Analysis
, 66(3):
179–187.
–––, 2003, “Groups with Minds of Their
Own,” in
Socializing Metaphysics
, F. Schmitt (ed.),
Lanham, MD: Rowman and Littlefield.
Philström, S., 2007, “Transcendental
Self-Deception,”
teorema
, 26(3): 177–189.
Porcher, J., 2012, “Against the Deflationary Account of
Self-Deception,”
Humana Mente
, 20: 67–84.
Quinton, Anthony, 1975/1976, “Social Objects,”
Proceedings of the Aristotelian Society
, 75: 1–27.
Räikkä, J. 2007, “Self-Deception and Religious
Beliefs,”
Heythrop Journal
, 48: 513–526.
Rorty, A. O., 1994, “User-Friendly Self-Deception,”
Philosophy
, 69: 211–228.
–––, 1983, “Akratic Believers,”
American Philosophical Quarterly
, 20: 175–183.
–––, 1980, “Self-Deception, Akrasia and
Irrationality,”
Social Science Information
, 19:
905–922.
–––, 1972, “Belief and
Self-Deception,”
Inquiry
, 15: 387–410.
Rowbottom, D. & Chan, C., 2019, “Self-Deception and
Shifting Degrees of Belief,”
Philosophical Psychology
,
32: 1204–1220.
Sahdra, B. and Thagard, P., 2003, “Self-Deception and
Emotional Coherence,”
Minds and Machines
, 13:
213–231.
Sanford, D,1988, “Self-Deception as Rationalization,”
in
Perspectives on Self-Deception
, B. McLaughlin and A. O.
Rorty (eds.), Berkeley: University of California Press.
Sartre, J-P., 1946,
L’etre et le néant
,
Paris: Gallimard; trans. H. E. Barnes, 1956,
Being and
Nothingness
, New York, Washington Square Press.
Scott-Kakures, Dion, 2021, “Self-Deceptive Inquiry:
Disorientation, Doubt, Dissonance,”
Midwest Studies in
Philosophy
, 45: 457–482.
–––, 2002, “At Permanent Risk: Reasoning
and Self-Knowledge in Self-Deception,”
Philosophy and
Phenomenological Research
, 65: 576–603.
–––, 2001, “High anxiety: Barnes on What
Moves the Unwelcome Believer,”
Philosophical
Psychology
, 14: 348–375.
–––, 2000, “Motivated Believing: Wishful
and Unwelcome,”
Noûs
, 34: 348–375.
Sher, George, 2009,
Who Knew? Responsibility without
Awareness
, Oxford: Oxford University Press.
Smith, D. L., 2014, "Self-Deception: A Teleofunctional Approach,"
Philosophia,
42: 181–199.
–––, 2013, "The Form and Function of
Self-Deception: A Biological Model,"
Sistemi intelligenti
, 3:
565–580.
Sorensen, R., 1985, “Self-Deception and Scattered
Events,”
Mind
, 94: 64–69.
Surbey, M., 2004, “Self-deception: Helping and hindering
personal and public decision making,” in
Evolutionary
Psychology, Public Policy and Personal Decisions
, C. Crawford and
C. Salmon (eds.), Mahwah, NJ: Lawrence Earlbaum Associates.
Schwitzgebel, E., 2001, “In-Between Believing,”
Philosophical Quarterly
, 51: 76–82.
Szabados, B., 1973, “Wishful Thinking and
Self-Deception,”
Analysis
, 33(6): 201–205.
Talbott, W. J., 1997, “Does Self-Deception Involve
Intentional Biasing,”
Behavior and Brain Sciences
, 20:
127.
–––, 1995, “Intentional Self-Deception in
a Single Coherent Self,”
Philosophy and Phenomenological
Research
, 55: 27–74.
Taylor, S. and Brown, J., 1994, “Positive Illusion and
Well-Being Revisited: Separating Fact from Fiction,”
Psychological Bulletin
, 116: 21–27.
Taylor, S. and Brown, J., 1988, “Illusion and Well-Being: A
Social Psychological Perspective on Mental Health,”
Psychological Bulletin
, 103(2): 193–210.
Tenbrusel, A.E. and D. M Messick, 2004, “Ethical Fading: The
Role of Self-Deception in Unethical Behavior,”
Social
Justice Research
, 7(2): 223–236.
Trivers, R., 2011,
The Folly of Fools: The Logic of Deceit and
Self-Deception in Human life
, New York: Basic Books.
Trivers, R., 2000, “The Elements of a Scientific Theory of
Self-Deception,” in
Evolutionary Perspectives on Human
Reproductive Behavior
, Dori LeCroy and Peter Moller (eds.),
Annals of the New York Academy of Sciences
, 907:
114–131.
Trivers, R., 1991, “Deceit and Self-Deception: The
relationship between Communication and Consciousness,”
Man
and Beast Revisited
, 907: 175–191.
Van Fraassen, B., 1995, “Belief and the Problem of Ulysses
and the Sirens,”
Philosophical Studies
, 77:
7–37.
–––, 1984, “Belief and Will,”
Journal of Philosophy
, 81: 235–256.
Van Leeuwen, N., 2013a, “Review of Robert Trivers’ The
Folly of Fools: The Logic of Deceit and Self-Deception in Human
Life,”
Cognitive Neuropsychiatry
, 18(1-2):
146–151.
–––, 2013b, “Self-Deception,” in
International Encyclopedia of Ethics
, H. LaFollette (ed.),
New York: Wiley-Blackwell.
–––, 2009, “Self-Deception Won’t
Make You Happy,”
Social Theory and Practice
, 35(1):
107–132.
–––, 2007a, “The Spandrels of
Self-deception: Prospects for a biological theory of a mental
phenomenon,”
Philosophical Psychology
, 20(3):
329–348.
–––, 2007b, “The Product of
Self-Deception,”
Erkenntnis
, 67(3): 419–437.
Van Loon, Marie, 2018, “Responsibility for
self-deception,”
Les Ateliers de l’Éthique /
the Ethics Forum
, 13(2): 119–134.
Von Hippel, W. & Trivers, R., 2011, “The Evolution and
Psychology of Self-Deception,”
Behavioral and Brain
Sciences
, 34(1): 1–56.
Vrij, A., 2011, “Self-deception, lying, and the ability to
deceive,”
Behavioral and Brain Sciences
, 34(1):
40–41.
Wei, Xintong, 2020, “The role of pretense in the process of
self-deception,”
Philosophical Explorations
, 23(1):
1–14.
Whisner, W., 1993, “Self-Deception and Other-Person
Deception,”
Philosophia
, 22: 223–240.
–––, 1989, “Self-Deception, Human Emotion,
and Moral Responsibility: Toward a Pluralistic Conceptual
Scheme,”
Journal for the Theory of Social Behaviour
,
19: 389–410.
Academic Tools
How to cite this entry
.
Preview the PDF version of this entry
at the
Friends of the SEP Society
.
Look up topics and thinkers related to this entry
at the Internet Philosophy Ontology Project (InPhO).
Enhanced bibliography for this entry
at
PhilPapers
, with links to its database.
Other Internet Resources
[Please contact the author with suggestions.]
Related Entries
action
|
belief
|
Davidson, Donald
|
delusion
|
lying and deception: definition of
|
moral responsibility
|
Sartre, Jean-Paul
|
self-knowledge
|
weakness of will
Acknowledgments
The author would like to thank Margaret DeWeese-Boyd, Douglas Young,
and the editors for their help in constructing and revising this
entry.